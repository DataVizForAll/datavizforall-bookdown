# Find and Know Your Data {#find}
In the early stages of a visualization project, you will likely ask two important and related questions: *Where can I find data?* and when I do, *How do I know what it really means?* If you skip over these questions and leap too quickly into constructing charts and maps, you run the risk of creating meaningless, or perhaps worse, misleading visualizations. This chapter breaks down both of these broad questions in greater detail, and provides concrete strategies to [recognize bad data](bad.html), [source your data](source.html), navigate [public versus private data](public.html), and search a growing number of [open data repositories](opendata.html).

When searching for data, your newest best friend may be a librarian. Sometimes a data-smart librarian happens to know exactly where to locate a dataset that you've been seeking for day. But their more valuable skill is guiding us on *how to search* by reflecting on the types of questions librarians commonly ask:

1. What types of organizations may have collected or published the data you seek? If a governmental organization may have been involved, then at what level (national, state/provincial, regional, or municipal), and which branch or agency? Or might data have been compiled by a non-governmental organization, such as academic institutions, journalists, for-profit corporations, or non-profit groups? Figuring out which organizations might have collected the data can help point you to the digital or print materials they typically publish, and most appropriate tools to focus your search in that particular area.

2. Have any prior publications drawn on similar datasets, and if so, how can we trace their sources? Some of our best data visualization ideas began while reading textual evidence or noticing a table in a print publication or outdated web page, which convinced us that the data existed *somewhere*. With these valuable leads, librarians can help you track down source notes on where the data originated, or sometimes find more up-to-date versions of the data.  

3. What level(s) of data are available? Is information disaggregated by individual cases or aggregated into larger groups? Librarians can help us to decipher how and why different organizations publish data in different formats. For example, US Census seeks to collect data every ten years about each person residing in the nation, but under the law, this individual-level data is confidential and not released to the public for 72 years. You can look up individual census data for 1940 and earlier decades at the [US National Archives](https://www.archives.gov/research/genealogy/census/about) and other websites. But the US Census publishes current data for larger areas, such as neighborhood-level block groups, census tracts, cities, and states, by aggregating individual records into data tables, and suppressing small-numbered cells to protect people's privacy. Librarians can help us understand organization's guidelines on when and how they make data available at different levels.

If your search has produced some results, the next step is to get to know your data. Closely examine your files and ask questions about their origin, meaning, and limitations:

4. Who collected and published this data, and for what purpose? Since individuals and organizations require time and resources to do this work, seek to clarify their motivations and assumptions, both explicit and implicit ones.
Who was the intended audience of the work? Whose perspectives does the data privilege? Whose stories remain untold? As practitioners of data visualization, we strongly favor evidence-based reasoning over its less-informed alternatives. But we also caution against embracing so-called data objectivity. Numbers are *not* neutral, and we always need to consider the broader contexts in which people created them.

5. What do the data labels *really* mean? Most spreadsheets contain abbreviated column headers, particularly due to software character limits, but some questions of data interpretation run much deeper. For example, socially-constructed labels such as "race" or "gender" may not clarify how the creators defined their terms, or what role respondents played in the collection process. Even seemingly objective labels such as "income" or "population" or "elevation" may not adequately describe exactly what was counted, how it was measured, and the margins of error. Better-quality datasets include detailed definitions of the collection process to help you to understand the decisions made by its creators. If not, then your next best option may be to go out into the field, if feasible, and directly observe how the data is measured and collected.

To be clear, you may never *truly know* your data if it was collected by someone else, particularly a different person in a distant place or time. But don't let that philosophical obstacles stop you from asking good questions about the origins and limitations of your data. Only by clarifying what we know---and what we don't know---can we create meaningful data visualizations that bring their inner-stories to life.

## Recognize Bad Data {- #bad}
A vital skill needed by all data visualization creators is the ability to recognize bad data. If you fail to catch a problem in your data at an early stage, someone else may discover it later, which could diminish the credibility of all of your work. Fortunately, members of the data visualization community have shared multiple examples of issues we've encountered in our work, and newer members will benefit from our embarrassing mistakes. One popular crowd-sourced compilation by data journalists was [The Quartz Guide to Bad Data](https://github.com/Quartz/bad-data-guide), last updated in 2018, which includes several of these helpful warning signs:

Watch out for spreadsheets with "bad data":

- Missing values: If you see blank or "null" entries, does that mean data was not collected? Or maybe a respondent did not answer? If you're unsure, find out from the data creator. Also beware when humans enter a `0` or `-1` to represent a missing value, without thinking about the consequences of running calculations.
- Missing leading zeros: The US Census Bureau lists every place using a FIPS code, and some spreadsheet users may accidentally convert text to numbers and strip out the leading zeroes. For example, the FIPS code for Los Angeles County is `037`, but someone might accidentally strip out the leading zero and convert it to `37`, which represents North Carolina.
- 65536 rows or 255 columns: These are the maximum number of rows supported by older-style Excel spreadsheets, or columns supported by Apple Numbers spreadsheet, respectively. If your spreadsheet stops exactly at either of these limits, you probably have only partial data.
- Inconsistent date formats: For example, November 3rd, 2020 is commonly entered in spreadsheets by Americans as `11/3/2020` (month-date-year), while many others around the globe type `3/11/2020` (date-month-year). Check your source.
- Dates such as January 1st 1900, 1904, or 1970: These are default timestamps in Excel spreadsheets and Unix operating systems, which may indicate the actual date was blank or overwritten.
- Dates similar to `43891`: When you type `March 1` during the year 2020 into Microsoft Excel, it automatically displays as `1-Mar`, but is saved using Excel's internal date system as `43891`. If someone converts this column from date to text format, you'll see Excel's 5-digit number, not the dates you're expecting. According to a [2016 report in the Washington Post](https://www.washingtonpost.com/news/wonk/wp/2016/08/26/an-alarming-number-of-scientific-papers-contain-excel-errors/), a team of geneticists detected a surprisingly high number of related Excel errors in papers published in leading scientific journals.

## Source Your Data {- #source}
Another way to reduce "bad data" issues is to clarify the source every time you download or create a new spreadsheet file. Add details about where the data came from, so that someone other than you, several years in the future, has sufficient information to understand its origin and limitations.

The first step is to label every data file that you download or create. All of us have experienced bad file names like these:

  - data.csv
  - file.xls
  - download.xlsx

Write a short but meaningful file name. While there's no perfect system, a good strategy is to abbreviate the source (such as `census` or `worldbank` or `eurostat`), with topic keywords, and a date or range. If you or co-workers will be working on different versions of a downloaded file, include the current date in YYYY-MM-DD (year-month-date) format. If you plan to upload files to the web, type names in all lower-case and replace blank spaces with dashes (`-`) or underscores (`_`). Better file names look like this:

  - town-demographics-2019-12-02.csv
  - census2010_population_by_county.xls
  - eurostat-1999-2019-CO2-emissions.xlsx

The second step is to save more detailed source notes about the data on a separate tab inside the spreadsheet (which works for multi-tab spreadsheet tools such as Google Sheets, LibreOffice, and Excel). Add a new tab named *notes* that describes the origins of the data, a longer description for any abbreviated labels, and when it was last updated, as shown in Figure \@ref(fig:sheets-with-tabs). Add your own name and give credit to collaborators who worked with you. For CSV files, which do not support multi-tabs sheets, create a text file using a parallel file name.

(ref:sheets-with-tabs) Create separate spreadsheet tabs for data, notes, and backup.

```{r sheets-with-tabs, fig.cap="(ref:sheets-with-tabs)"}
 knitr::include_graphics("images/03-find/sheets-with-tabs.png")
```

A third step is to make a backup of the original data before cleaning or editing it. For a simple one-sheet file in a multi-tab spreadsheet tool, right-click on the tab containing the data to make a duplicate copy in another tab, also shown in the preceding figure. Clearly label the new tab as a backup and leave it alone! For CSV files or more complex spreadsheets, create a separate backup file.

Make a habit of using these three sourcing strategies---filenames, notes, and backups---to reduce your chances of making "bad data" errors and to increase the credibility of your data visualizations. In the next section, we'll address a related set of questions you should ask yourself regarding public versus private data.

## Public versus Private Data {- #public}
In addition to asking questions about the origins and limitations of your data, it's also important for you to be aware of important distinctions between public versus private data, and their implications for designing your visualizations. This section offers some general observations about data privacy based on our context in the United States. Since we are not lawyers (thank goodness!), please consult with legal experts for advice about your specific case.

Here's what's most important---and confusing---about access to data in the US. Individual-level data is often considered private, except in certain areas where our governmental process has determined that broader interests are served by making it public. First, here are two examples where individual-level data generally remains private:

- Patient-level health data is generally protected under the [Privacy Rule of the Health Insurance Portability and Accountability Act](https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act#Privacy_Rule), commonly known as HIPAA. But public health officials regularly aggregate individual patient records into larger anonymized public datasets to track progress about various illnesses.
- Student-level education data is generally protected under the [Family Educational Rights and Privacy Act](https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act), commonly known as FERPA. But education officials regularly aggregate individual student records into larger anonymized public datasets to track the progress of schools, districts, and states.  

But here are other examples where our government has determined that a broader interest is served by making individual-level data available to the public:

- Individual contributions to political candidates are public. You can search donors by name and address in this [US Federal Election Commission public database](https://www.fec.gov/data/receipts/individual-contributions/), as well as other state-level sites.
- Individual salaries for officers of tax-exempt organizations are public. You can search by name across a digitized database of Internal Revenue Service (IRS) 990 forms that tax-exempt organizations are required to submit on several platforms, such as ProPublica's [Nonprofit Explorer](https://projects.propublica.org/nonprofits).
- Individual property ownership records are public, and increasingly online in many locations. For example, one company provides a [US public records directory](https://publicrecords.netronline.com/) with links to local government property records, where available. Follow the links to search the value of the home owned by the first author in West Hartford, Connecticut, how much he and his spouse paid for it, the number of bathrooms, and so forth.
- Individual police officer reports regarding "use of force" are public by New Jersey state law. But no one could easily search these local police department records until a team of journalists from NJ Advance Media created a public database, [The Force Report](https://force.nj.com/), where anyone can look up individual officers and investigate patterns of violence.

Also, the US federal government is subject to the [Freedom of Information Act](https://en.wikipedia.org/wiki/Freedom_of_Information_Act), which enables people to submit a "FOIA" request to obtain certain types of public records to improve government transparency. Individual states and their municipalities are subject to their own Freedom of Information laws, which are summarized in the [Open Government Guide](https://www.rcfp.org/open-government-guide/) by the Reporters Committee for Freedom of the Press, and also by the [National Freedom of Information Coalition](https://www.nfoic.org/). While some government agencies delay or reject FOIA requests, which can result in expensive litigation, others have begun to pro-actively share more public information on open data repositories.

## Open Data Repositories {- #opendata}
Over the past decade, an increasing number of governmental and non-governmental organizations have begun to publicly share data through open data repositories. While some of these datasets were previously available as individual files on isolated websites, these growing networks have made open data easier to find, enabled more frequent updates, and sometimes have allowed live interaction. Open data repositories often include these features:

- View and Export: At minimum, open data repositories allow users to view and export data in common spreadsheet formats, such as CSV, ODS, and XLSX. Some repositories also provide geographical boundary files for creating maps.
- Built-in Visualization Tools: Several repositories offer built-in tools for users to create interactive charts or maps on the platform site. Some also provide code snippets for users to embed these built-in visualizations into their own websites, which you'll learn more about in [Chapter 7: Embed on Your Web](embed.html).
- Application Programming Interface (APIs): Some repositories provide endpoints with code instructions that allow users to pull data directly from the platform into an external site or online visualization. When repositories continuously update data and publish an API endpoint, it can be an ideal way to display "nearly live" data in your visualization, which you'll learn more about in [Chapter 10: Leaflet Map Templates](leaflet.html).

Due to the recent growth of open data repositories, especially in governmental policy and scientific research, there is no single website that lists all of them. Instead, we briefly mention just a few of the sites we turn to when hunting for types of data that may interest our readers, while acknowledging that we could have added many others:

TODO: Decide which links to include, remove, or others to add below....

United States open data:

- [Data.gov](https://www.data.gov/), the official repository for US federal government agencies.
- [Data.census.gov](https://data.census.gov), the main platform to access US Census Bureau data. The Decennial Census is a full count of the population every ten years, while the American Community Survey (ACS) is an annual sample count that produces one-year, three-year, or five-year estimates for different census geographies, with margins of error.
- [Open Data Network](https://www.opendatanetwork.com/) directory of primarily US state and municipal open data platforms by Socrata

International open data:

- [Eurostat](https://ec.europa.eu/eurostat), the statistical office of the European Union
- [Global Open Data Index](https://index.okfn.org/dataset/) by the Open Knowledge Foundation
- [Google Public Data](https://www.google.com/publicdata/directory)
- [openAfrica](https://africaopendata.org/) by Code for Africa
- [Open Data Inception](https://opendatainception.io/) a map-oriented global directory
- [World Bank Open Data](https://data.worldbank.org/)

In addition, students, staff, and faculty at better-resourced institutions of higher education also may have access to a paid library subscription to "closed" data repositories:

- [Social Explorer](https://www.socialexplorer.com/) includes decades of demographic, economic, health, education, religion, and crime data for local and national geographies, primarily for the US, Canada, and Europe. Previously, some access was public, but now requires paid subscription or 14-day free trial.
- IPUMS NHGIS?
- more?

### Summary {- #summary3}

This chapter reviewed two broad questions that everyone should ask during the early stages of their visualization project: *Where can I find data?* and *How do I know what it really means?* We broke down both questions into more specific parts to develop your knowledge and skills in recognizing bad data, sourcing the origins of your data, distinguishing between public versus private data, and navigating the growing number of open data repositories. As you leap into the next few chapters on cleaning data and creating interactive charts and maps, remember these lessons as you strive to create meaningful visualizations.
