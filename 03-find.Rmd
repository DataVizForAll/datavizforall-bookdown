# Find and Know Your Data {#find}
In the early stages of a visualization project, we often ask these two important and related questions: *Where can I find data?* and *What do I really know about it?* If you skip over these questions and leap too quickly into constructing charts and maps, you run the risk of creating meaningless, or perhaps worse, misleading visualizations. This chapter breaks down both of these broad questions, and provides concrete strategies to [guide your search](guide.html), [recognize bad data](bad.html), [source your data origins](source.html), understand debates about [public versus private data](public.html), and navigate a growing number of [open data repositories](opendata.html).

Once you've found some data, we offer specific ways to [reflect on what you *really* know about it](know.html). Data does not magically appear out of thin air. Instead, people collect and publish information, with explicit or implicit purposes, wrapped up inside the social contexts and power structures of their times. As data visualization advocates, we strongly favor evidence-based reasoning over less-informed alternatives. But we caution against embracing so-called data objectivity, since numbers (and other forms of data) are *not* neutral. Therefore, when working with data, we must pause to ask questions such as: *Whose stories are told? Whose perspectives remain unspoken?* Only by asking these and related types of questions will we "start to see how privilege is baked into our data practices and our data products," argue Catherine D'Ignazio and Lauren Klein in their insightful book, *[Data Feminism](https://data-feminism.mitpress.mit.edu/)*.[@dignazioDataFeminism2020]

## Guiding Questions for your Data Search {- #guiding}
For many people, a data search is simply "Googling" some keywords on the web. Sometimes it works, and sometimes not. When that approach fails, we reflect on the many lessons we've learned about data-hunting while working alongside talented librarians, journalists, and researchers. Collectively, they taught us a set of guiding questions that outline a more thoughtful process about *how to search* for data:

- What exactly is the question you're seeking to answer with data? Literally write it down---in the form of a question, punctuated with a question mark at the end---to clarify your own thinking, and also so that you can clearly communicate it to others who can assist you. All too often, our brains automatically leap ahead to try to identify the *answer*, without reflecting on the best way frame the *question* in a way that does not limit the range of possible outcomes.

Look back at data visualization projects that made a lasting impression on you to identify the underlying question that motivated them. In their coverage of the US opioid epidemic, the *Washington Post* and the West Virginia *Charleston Gazette-Mail* successfully fought a legal battle to obtain a US Drug Enforcement Agency database that the federal government and the drug industry sought to keep secret. A team of data journalists published the database with interactive maps to help readers answer one of their central questions: *How many prescription opioid pills were sent to each US county, per capita, and which companies and distributors were responsible?* Their [maps revealed](https://www.washingtonpost.com/graphics/2019/investigations/dea-pain-pill-database/) high clusters in several rural Appalachian counties that received over 150 opioid pills per resident, on average, each year from 2006 to 2014. Moreover, only six companies distributed over three-quarters of the 100 billion oxycodone and hydrocodone pills across the US during this period: McKesson Corp., Walgreens, Cardinal Health, AmerisourceBergen, CVS and Walmart. Even if you're not working with data as large or as controversial as this one, the broader lesson is to clearly identify the question you're seeking to answer.

Furthermore, it's perfectly normal to revise your question as your research evolves. For example, we once began a data project by naively asking *What were Connecticut public school test scores in the 1960s?* Soon we discovered that standardized state-level school testing as we know it today did not appear in states like Connecticut until the mid-1980s school accountability movement. Even then, results were not widely visible to the public until newspapers began to publish them once a year in print in the 1990s. Later, real estate firms, school-ratings companies, and government agencies began to publish data continuously on the web as the Internet expanded in the late 1990s and early 2000s. Based on what we learned, we revised our research question to *When and how did Connecticut homebuyers start to become aware of school test scores, and how did these influence the prices they were willing to pay for access to selected public school attendance areas?*[@doughertySchoolChoiceSuburbia2009] Be prepared to refine your question when the evidence leads you in a better direction.

- What types of organizations may have collected or published the data you seek? If a governmental organization may have been involved, then at what level: local, regional, state/provincial, national, or international? Which branch of government: executive, legislative, judicial? Or which particular governmental agency might have been responsible for compiling or distributing this information? Since all of these different structures can be overwhelming, reach out to librarians who are trained to work with government documents and databases, often at [state government libraries](https://libguides.ala.org/mailing-lists), or at local institutions participating in the [US Federal Depository Library Program](https://www.doi.gov/library/collections/federal-documents). Or might the data you seek have been compiled by a non-governmental organization, such as academic institutions, journalists, non-profit groups, or for-profit corporations? Figuring out *which organizations* might have collected and published the data can help point you to the digital or print materials they typically publish, and most appropriate tools to focus your search in that particular area.

- Have prior publications drawn on similar data, and if so, how can we trace their sources? Some of our best ideas began when reading an article or book that described its source of evidence, and we imagined new ways to visualize that data. Several times we have stumbled across a data table in a print publication, or perhaps an old web page, which sparked our interest in tracking down a newer version to explore. Even *outdated* data helps by demonstrating how someone or some organization collected it at one point in time. Follow the footnotes to track down its origins. Use [Google Scholar](https://google.com/scholar) and more specialized research databases (ask librarians for assistance if needed) to track down the source of previously-published data. One bonus is that if you can locate more current data, you may be able to design a visualization that compares change over time.

- What level(s) of data are available? Is information disaggregated by individual cases or aggregated into larger groups? Librarians can help us to decipher how and why different organizations publish data in different formats. For example, US Census seeks to collect data every ten years about each person residing in the nation, but under the law, this individual-level data is confidential and not released to the public for 72 years. You can look up individual census data for 1940 and earlier decades at the [US National Archives](https://www.archives.gov/research/genealogy/census/about) and other websites. But the US Census publishes current data for larger areas, such as neighborhood-level block groups, census tracts, cities, and states, by aggregating individual records into data tables, and suppressing small-numbered cells to protect people's privacy. Librarians can help us understand organization's guidelines on when and how they make data available at different levels

- What if no one has collected the data you're looking for? In their book *Data Feminism*, Catherine D'Ignazio and Lauren Klein underscore how issues of data collection "are directly connected to larger issues of power and privilege" by recounting a story about tennis star Serena Williams. When Williams experienced life-threatening complications while giving birth to her daughter in 2017, she called public attention to the way that she, a Black woman, needed to advocate for herself in the hospital. After her experience, she wrote on social media that "Black women are over 3 times more likely than white women to die from pregnancy- or childbirth-related causes," citing the US Centers for Disease Control and Prevention (CDC). When journalists followed up to investigate further, they discovered the absence of detailed data on maternal mortality, and what a 2014 United Nations report described as a "particularly weak" aspect of data collection in the US healthcare system. Journalists reported that "there was still no national system for tracking complications sustained in pregnancy and childbirth," despite comparable systems for other health issues such as heart attacks or hip replacements. Power structures are designed to count people whose lives either are highly valued, or under a high degree of surveillance. D'Ignazio and Klein call on us critically examine these power systems, collect data to counter their effects, and make everyone's labor in this process more visible.[@dignazioDataFeminism2020, chapter 1] If no one has collected the data you're looking for, perhaps you can make a valuable first step toward recognizing and addressing that issue.


## Recognize Bad Data {- #bad}
A vital skill needed by all data visualization creators is the ability to recognize bad data. If you fail to catch a problem in your data at an early stage, someone else may discover it later, which could lead to false conclusions and diminish the credibility of all of your work. Fortunately, members of the data visualization community have shared multiple examples of issues we've encountered in our work, and newer members will benefit from our embarrassing mistakes. One popular crowd-sourced compilation by data journalists was [The Quartz Guide to Bad Data](https://github.com/Quartz/bad-data-guide), last updated in 2018, which includes several of these helpful warning signs:

Watch out for spreadsheets with "bad data":

- Missing values: If you see blank or "null" entries, does that mean data was not collected? Or maybe a respondent did not answer? If you're unsure, find out from the data creator. Also beware when humans enter a `0` or `-1` to represent a missing value, without thinking about the consequences of running calculations.
- Missing leading zeros: The US Census Bureau lists every place using a FIPS code, and some spreadsheet users may accidentally convert text to numbers and strip out the leading zeroes. For example, the FIPS code for Los Angeles County is `037`, but someone might accidentally strip out the leading zero and convert it to `37`, which represents North Carolina.
- 65536 rows or 255 columns: These are the maximum number of rows supported by older-style Excel spreadsheets, or columns supported by Apple Numbers spreadsheet, respectively. If your spreadsheet stops exactly at either of these limits, you probably have only partial data.
- Inconsistent date formats: For example, November 3rd, 2020 is commonly entered in spreadsheets by Americans as `11/3/2020` (month-date-year), while many others around the globe type `3/11/2020` (date-month-year). Check your source.
- Dates such as January 1st 1900, 1904, or 1970: These are default timestamps in Excel spreadsheets and Unix operating systems, which may indicate the actual date was blank or overwritten.
- Dates similar to `43891`: When you type `March 1` during the year 2020 into Microsoft Excel, it automatically displays as `1-Mar`, but is saved using Excel's internal date system as `43891`. If someone converts this column from date to text format, you'll see Excel's 5-digit number, not the dates you're expecting.

What should you do when you discover bad data in your project? Sometimes small issues are relatively straightforward, do not call into question the integrity of the entire dataset, and you can fix them using methods to [clean up messy data](clean.html) that we describe in chapter 4. But larger issues are more problematic. Follow the source of your data stream to try to identify where the issue began. If you cannot find and fix the issue on your own, contact the data provider to ask for their input, since they should have a strong interest in improving the quality of the data. If they cannot resolve an important data issue, then you need to pause and think carefully. In this case, is it wiser to continue working with problematic data and add a cautionary note to readers, or should you stop using the dataset entirely and call attention to its underlying problem? These are not easy decisions, and you should ask for opinions from colleagues. In any case, never ignore the warning signs of bad data.

## Source Your Data {- #source}
Another way to reduce "bad data" issues is to clarify the source every time you download or create a new spreadsheet file. Add details about where the data came from, so that someone other than you, several years in the future, has sufficient information to understand its origin and limitations.

The first step is to label every data file that you download or create. All of us have experienced bad file names like these:

  - data.csv
  - file.xls
  - download.xlsx

Write a short but meaningful file name. While there's no perfect system, a good strategy is to abbreviate the source (such as `census` or `worldbank` or `eurostat`), with topic keywords, and a date or range. If you or co-workers will be working on different versions of a downloaded file, include the current date in YYYY-MM-DD (year-month-date) format. If you plan to upload files to the web, type names in all lower-case and replace blank spaces with dashes (`-`) or underscores (`_`). Better file names look like this:

  - town-demographics-2019-12-02.csv
  - census2010_population_by_county.xls
  - eurostat-1999-2019-co2-emissions.xlsx

The second step is to save more detailed source notes about the data on a separate tab inside the spreadsheet (which works for multi-tab spreadsheet tools such as Google Sheets, LibreOffice, and Excel). Add a new tab named *notes* that describes the origins of the data, a longer description for any abbreviated labels, and when it was last updated, as shown in Figure \@ref(fig:sheets-with-tabs). Add your own name and give credit to collaborators who worked with you. For CSV files, which do not support multi-tabs sheets, create a text file using a parallel file name.

(ref:sheets-with-tabs) Create separate spreadsheet tabs for data, notes, and backup.

```{r sheets-with-tabs, fig.cap="(ref:sheets-with-tabs)"}
 knitr::include_graphics("images/03-find/sheets-with-tabs.png")
```

A third step is to make a backup of the original data before cleaning or editing it. For a simple one-sheet file in a multi-tab spreadsheet tool, right-click on the tab containing the data to make a duplicate copy in another tab, also shown in Figure \@ref(fig:sheets-with-tabs). Clearly label the new tab as a backup and leave it alone! For CSV files or more complex spreadsheets, create a separate backup file.

Make a habit of using these three sourcing strategies---filenames, notes, and backups---to reduce your chances of making "bad data" errors and to increase the credibility of your data visualizations. In the next section, we'll address a related set of questions you should ask yourself regarding public versus private data.

## Public and Private Data {- #public}
In addition to asking questions about the origins and limitations of your data, it's also important for you to become informed and engaged with evolving debates over public and private data. At stake are two different types of issues. The first question is: *To what extent should organizations be allowed to collect data about private individuals?* The second question is: *When our government collects data, to what extent should it be publicly available?* This section offers our general observations about these debates based on our context, primarily in the United States. Since we are not lawyers (thank goodness!), please consult with legal experts for advice about your specific case.

Several critics of "big data" worry that governments are becoming more like a totalitarian "Big Brother" as they collect more data about individual citizens in the digital age. In the United States, concerns mounted in 2013 when whistleblower Eric Snowden disclosed how the National Security Agency conducted global surveillance using US citizen email and phone records provided by telecommunications companies. Shoshana Zuboff, Harvard Business School professor and author of *The Age of Surveillance Capitalism*, warns of an equal threat posed by corporations that collect and commodify massive amounts of individually-identifiable data for profit.[@zuboffAgeSurveillanceCapitalism2019] Due to the rise of digital commerce, powerful technology companies own data that you and others consider to be private:

- Google knows what words you typed into their search engine, as shown in aggregated form in [Google Trends](https://trends.google.com/trends/). Also, Google's Chrome browser tracks your web activity through cookies, as described by technology reporter [Geoffrey Fowler](https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/).
- Amazon eavesdrops and records your conversations around its Alexa home assistants, as [Fowler describes](https://www.washingtonpost.com/technology/2019/05/06/alexa-has-been-eavesdropping-you-this-whole-time/).
- Facebook follows which friends and political causes you favor, but also [tracks your off-Facebook activity](https://www.washingtonpost.com/technology/2020/01/28/off-facebook-activity-page/), such as purchases made at other businesses, to improve its targeted advertising.

Some point out that "big data" collected by large corporations can offer public benefits. For example, [Apple shared its aggregated mobility data](https://www.apple.com/covid19/mobility) collected from iPhone users to help public health officials compare which populations stayed home rather than travel during the Covid pandemic. But corporations are still setting their own terms for how they collect data and what they can do with it. Although California has begun to [implement its Consumer Privacy Act in 2020](https://www.washingtonpost.com/technology/2020/01/21/ccpa-transparency/), which promises to allow individuals the right to review and delete the data that companies collect about them, US state and federal government has not fully entered this policy arena. If you work with data that was collected from individuals by public or private organizations, learn about these controversies to help you make wise and ethical choices in your visualizations.

The second area of debate asks: When our government collects data, to what extent should it be publicly available? In the United States, the 1966 [Freedom of Information Act](https://en.wikipedia.org/wiki/Freedom_of_Information_Act) and its subsequent amendments have sought to open access to information in the federal government, with the view that increased transparency would promote public scrutiny and pressure on officials to make positive changes. In addition, state governments operate under their own freedom of information laws, sometimes called "open records" or "sunshine laws." When people say they've submitted a "FOIA," it means they've sent a written request to a government agency for information that they believe should be public under the law. But federal and state FOIA laws are complex, and courts have interpreted cases in different ways over time, as summarized in the [Open Government Guide](https://www.rcfp.org/open-government-guide/) by the Reporters Committee for Freedom of the Press, and also by the [National Freedom of Information Coalition](https://www.nfoic.org/). Sometimes government agencies quickly agree and comply with a FOIA request, while other times they may delay or reject it, which may pressure the requester to attempt to resolve the issue through time-consuming litigation. Around the world, [over 100 nations have their own version of freedom of information laws](https://en.wikipedia.org/wiki/Freedom_of_information_laws_by_country), with the oldest being Sweden's 1766 Freedom of the Press Act, but these laws vary widely.

In most cases, individual-level data collected by US federal and state governments is considered private, except in cases where our governmental process has determined that a broader interest is served by making it public. To illustrate this distinction, let's begin with two cases where US federal law protects the privacy of individual-level data:

- Patient-level health data is generally protected under the [Privacy Rule of the Health Insurance Portability and Accountability Act](https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act#Privacy_Rule), commonly known as HIPAA. In order for public health officials to track broad trends about illness in the population, individual patient data must be aggregated into larger anonymized datasets in ways that protect specific people's confidentiality.

- Similarly, student-level education data is generally protected under the [Family Educational Rights and Privacy Act](https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act), commonly known as FERPA. Public education officials regularly aggregate individual student records into larger anonymized public datasets to track the broad progress of schools, districts, and states, without revealing individually-identifiable data.

On the other hand, here are three cases where government has ruled that the public interest is served by making individual-level data widely available:

- Individual contributions to political candidates are public information in the [US Federal Election Commission database](https://www.fec.gov/data/receipts/individual-contributions/), and related databases by non-profit organizations, such as [Follow The Money](https://www.followthemoney.org/) by the National Institute on Money in Politics and [Open Secrets](http://www.opensecrets.org/) by the Center for Responsive Politics. The latter two sites describe more details about donations submitted through political action committees and controversial exceptions to campaign finance laws. Across the US, state-level political contribution laws vary widely, and these public records are stored in separate databases. For example, anyone can search the [Connecticut Campaign Reporting Information System](https://seec.ct.gov/Portal/eCRIS/eCrisSearch) to find donations made by the first author to state-level political campaigns.

- Individual property ownership records are public, and increasingly hosted online by many local governments. A privately-funded company compiled this [US public records directory](https://publicrecords.netronline.com/) with links to county and municipal property records, where available. For example, anyone can search the [property assessment database for the Town of West Hartford, Connecticut](http://gis.vgsi.com/westhartfordct/) to find property owned by the first author, its square footage, and purchase price.

- Individual salaries for officers of tax-exempt organizations are public, which they are required to file on Internal Revenue Service (IRS) 990 forms each year. For example, anyone can search 990 forms on ProPublica's [Nonprofit Explorer](https://projects.propublica.org/nonprofits), and view the salary and other compensation of the top officers of the first author's employer, Trinity College in Hartford, Connecticut.

Social and political pressures are continually changing the boundary over what types of individual-level data collected by government should be made publicly available. For example, the Black Lives Matter movement has gradually made more individual-level data about violence by police officers more widely available. For example, in 2001 the State of New Jersey required local police departments to document any "use of force" by officers, whether minor or major, such as firing their gun. But no one could easily search these paper forms until a team of journalists from NJ Advance Media submitted over 500 public records requests and compiled [The Force Report digital database](https://force.nj.com/), where anyone can look up individual officers and investigate patterns of violent behavior. Similarly, a team of ProPublica journalists created [The NYPD Files database](https://projects.propublica.org/nypd-ccrb/), which now allows anyone to search closed cases of civilian complaints against New York City police officers, by name or precinct, for patterns of substantiated allegations.

If you work with data, get informed about debates over what should be public or private, and become active in policy discussions about whose interests are being served, and what should change.


## Open Data Repositories {- #opendata}
Over the past decade, an increasing number of governmental and non-governmental organizations in the US and around the globe have begun to pro-actively share public data through open data repositories. While some of these datasets were previously available as individual files on isolated websites, these growing networks have made open data easier to find, enabled more frequent agency updates, and sometimes support live interaction with other computers. Open data repositories often include these features:

- View and Export: At minimum, open data repositories allow users to view and export data in common spreadsheet formats, such as CSV, ODS, and XLSX. Some repositories also provide geographical boundary files for creating maps.
- Built-in Visualization Tools: Several repositories offer built-in tools for users to create interactive charts or maps on the platform site. Some also provide code snippets for users to embed these built-in visualizations into their own websites, which you'll learn more about in [Chapter 7: Embed on Your Web](embed.html).
- Application Program Interface (APIs): Some repositories provide endpoints with code instructions that allow other computers to pull data directly from the platform into an external site or online visualization. When repositories continuously update data and publish an API endpoint, it can be an ideal way to display live or "almost live" data in your visualization, which you'll learn more about in [Chapter 10: Leaflet Map Templates](leaflet.html).

Due to the recent growth of open data repositories, especially in governmental policy and scientific research, there is no single website that lists all of them. Instead, we list just a few sites from the US and around the globe to spark readers' curiosity:

- [Data.gov](https://www.data.gov/), the official repository for US federal government agencies.
- [Data.census.gov](https://data.census.gov), the main platform to access US Census Bureau data. The Decennial Census is a full count of the population every ten years, while the American Community Survey (ACS) is an annual sample count that produces one-year, three-year, or five-year estimates for different census geographies, with margins of error.
- [Eurostat](https://ec.europa.eu/eurostat), the statistical office of the European Union
- [Global Open Data Index](https://index.okfn.org/dataset/) by the Open Knowledge Foundation
- [Google Public Data](https://www.google.com/publicdata/directory)
- [IPUMS](https://www.ipums.org), the Integrated Public Use Microdata Series, the world's largest individual-level population database, with microdata samples from US and international census records and surveys, hosted by the University of Minnesota
- [openAfrica](https://africaopendata.org/) by Code for Africa
- [Open Data Inception](https://opendatainception.io/) a map-oriented global directory
- [Open Data Network](https://www.opendatanetwork.com/) directory of primarily US state and municipal open data platforms by Socrata
- [World Bank Open Data](https://data.worldbank.org/)

In addition, students, staff, and faculty at better-funded institutions of higher education also may have access to a paid library subscription to "closed" data repositories. For example, [Social Explorer](https://www.socialexplorer.com/) includes decades of demographic, economic, health, education, religion, and crime data for local and national geographies, primarily for the US, Canada, and Europe. Previously, Social Explorer made many files available to the public, but it now requires a paid subscription or 14-day free trial.

## Know Your Data {- #know}
TODO: explain more about expectations about “knowing what you data means” in the scope of this chapter….

If your search has produced some results, the next step is to get to know your data. Closely examine your files and ask questions about their origin, meaning, and limitations:

- Who collected and published this data, and for what purpose? Since individuals and organizations require time and resources to do this work, seek to clarify their motivations and assumptions, both explicit and implicit ones.
Who was the intended audience of the work? Whose perspectives does the data privilege? Whose stories remain untold? As practitioners of data visualization, we strongly favor evidence-based reasoning over its less-informed alternatives. But we also caution against embracing so-called data objectivity. Numbers are *not* neutral, and we always need to consider the broader contexts in which people created them.

- What do the data labels *really* mean? Most spreadsheets contain abbreviated column headers, particularly due to software character limits, but some questions of data interpretation run much deeper. For example, socially-constructed labels such as "race" or "gender" may not clarify how the creators defined their terms, or what role respondents played in the collection process. Even seemingly objective labels such as "income" or "population" or "elevation" may not adequately describe exactly what was counted, how it was measured, and the margins of error. Better-quality datasets include detailed definitions of the collection process to help you to understand the decisions made by its creators. If not, then your next best option may be to go out into the field, if feasible, and directly observe how the data is measured and collected.

TODO: Add examples above on how US census race and ethnicity categories changed over time? And how ACS measurements about income in small areas are subject to high margins of error?

To be clear, you may never *truly know* your data if it was collected by someone else, particularly a different person in a distant place or time. But don't let that philosophical obstacles stop you from asking good questions about the origins and limitations of your data. Only by clarifying what we know---and what we don't know---can we create meaningful data visualizations that bring their inner-stories to life.

### Summary {- #summary3}

This chapter reviewed two broad questions that everyone should ask during the early stages of their visualization project: *Where can I find data?* and *What do I really know about it?* We broke down both questions into more specific parts to develop your knowledge and skills in recognizing bad data, sourcing the origins of your data, distinguishing between public versus private data, and navigating the growing number of open data repositories. As you leap into the next few chapters on cleaning data and creating interactive charts and maps, remember these lessons as you strive to create meaningful visualizations.
