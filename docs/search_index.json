[
["index.html", "Hands-On Data Visualization Interactive Storytelling from Spreadsheets to Code Introduction", " Hands-On Data Visualization Interactive Storytelling from Spreadsheets to Code Jack Dougherty Ilya Ilyankou 2020-09-01 Introduction This open-access book-in-progress, by Jack Dougherty and Ilya Ilyankou, is under contract with O’Reilly Media, Inc., and was last updated on: 01 Sep 2020 Tell your story and show it with data, using free and easy-to-learn tools on the web. This introductory book teaches you how to design interactive charts and customized maps for your website, beginning with easy drag-and-drop tools, such as Google Sheets, Datawrapper, and Tableau Public. You’ll also gradually learn how to edit open-source code templates like Chart.js, Highcharts, and Leaflet on GitHub. Follow along with the step-by-step tutorials, real-world examples, and online resources. This book is ideal for students, non-profit organizations, small business owners, local governments, journalists, academics, or anyone who wants to tell their story and show the data. No coding experience is required. Read for free online at https://HandsOnDataViz.org or purchase print/eBook editions, to come from the publisher. Please send corrections or suggestions for this book-in-progress to handsondataviz@gmail.com, or open an issue or submit a pull request on its GitHub repository. If you submit a GitHub pull request, in your commit message, please add the sentence “I assign the copyright of this contribution to Jack Dougherty and Ilya Ilyankou,” so that we can maintain the option of publishing this book in other forms. View open-source code for source text and templates at https://github.com/handsondataviz. Hands-On Data Visualization is copyrighted by Jack Dougherty and Ilya Ilyankou and distributed under a Creative Commons BY-NC-ND 4.0 International License. You may freely share this content for non-commercial purposes, with a source credit to http://HandsOnDataViz.org. Trademarks Any use of a trademarked name without a trademark symbol is for readability purposes only. We have no intention of infringing on the trademark. GitHub and the GitHub logo are registered trademarks of GitHub, Inc. Google and the Google logo are registered trademarks of Google Inc. WordPress is a registered trademark of the WordPress Foundation Disclaimer The information is this book is provided without warranty. The lead author, contributors, and publisher have neither liability nor responsibility to any person or entity related to any loss or damages arising from the information contained in this book. "],
["authors.html", "Authors", " Authors Authors About Us Jack Dougherty is Professor of Educational Studies at Trinity College in Hartford, Connecticut, where he and his students partner with community organizations to help tell their data stories on the web. Follow him on Twitter and on GitHub. Ilya Ilyankou is a Civic Technologist at Connecticut Data Collaborative. He has completed a double major in Computer Science and Studio Arts in the Class of 2018 at Trinity College. Visit his website or follow him on GitHub. "],
["acknowledgements.html", "Acknowledgements", " Acknowledgements An earlier draft of this book was titled Data Visualization For All and designed to accompany a free online edX course by the same name at Trinity College. Two co-instructors for this edX course contributed valuable ideas and co-created videos: Stacy Lam, Trinity Class of 2019, and David Tatem, Instructional Technologist at Trinity College. Veronica X. Armendariz, Trinity Class of 2016, also made valuable contributions to an earlier version of the book while she was a Teaching Assistant for the DataViz internship seminar. Videos for the edX course were produced with Trinity College Information Technology staff and friends: Angie Wolf, Sean Donnelly, Ron Perkins, Samuel Oyebefun, Phil Duffy, and Christopher Brown. Funding for students who worked on the earlier draft was generously provided by the Community Learning Initiative and Information Technology Services at Trinity College in Hartford, Connecticut. Thanks to many individuals and organizations for generously making time to help us learn many of the skills that we teach in this book: Alvin Chang and Andrew Ba Tran, who tutored and shared their Leaflet map templates while at The Connecticut Mirror; Patrick Murray-John, formerly at the Roy Rosenzweig Center for History and New Media, who clued us into being code-curious, and many others at The Humanities and Technology Camp (THATCamp) conference series… We appreciate everyone at O’Reilly who helped us to create this book, especially our outstanding developmental editor, Amelia Blevins, and other members of the team, including Nick Adams, Jonathan Hassel, Andy Kwan, Katie Tozer, etc. We also thank O’Reilly’s support for technical reviewers who provided feedback to help us improve the manuscript, including Carl Allchin, Derek Eder, Erica Hayes, etc…. We also appreciate feedback from other readers, including Gared Bard, ….. "],
["what.html", "What is Data Visualization?", " What is Data Visualization? Data visualization is broadly defined as a method of encoding quantitative, relational, or spatial information into images. Classic examples include Charles Menard’s figurative map of Napoleon’s defeat and retreat during the Russian campaign of 1812, and John Snow’s dot map of cholera cases during the London epidemic of 1854. Images: Menard’s figurative map (left) and Snow’s dot map (right), from Wikimedia This free online introductory book focuses on selected topics in data visualization: Charts and maps Despite the growing variety of visualization types, this book features chapters on creating charts and maps, and a wide range of ways to communicate with these classic models. Reusable tools and templates: Unlike infographics created for one-time use, all of the tools and templates in this book are recyclable, and allow you to upload a new dataset to display your story. Free and easy-to-learn: We have selected data visualization tools that are free to use (or work on a freemium model, where advanced features or higher usage requires payment), and searched for those that we believe are easy-to-learn, based on our teaching experience with undergraduate students and non-profit community organizations. Interactive on the open web: Many books assume that you will deliver your data visualizations to in-person audiences on printed paper or presentation slides. But in this book, we show how to embed interactive charts and maps on your website, to share with the wider public. Storytelling: Data visualization is more than pretty pictures. In this book, the best visualizations are those that tell your data story – and pull readers’ attention to what really matters – by combining images and text, and offering exploration with explanation. Michael Friendly and Daniel J. Denis, “Milestones in the History of Thematic Cartography, Statistical Graphics, and Data Visualization,” 2001, http://www.datavis.ca/milestones/ Isabel Meirelles, Design for Information: An Introduction to the Histories, Theories, and Best Practices Behind Effective Information Visualizations (Rockport Publishers, 2013), http://isabelmeirelles.com/book-design-for-information/ Edward Tufte, The Visual Display of Quantitative Information (Graphics Press, 1983), and subsequent works at https://www.edwardtufte.com "],
["why.html", "Why this book?", " Why this book? Hands-On Data Visualization, an open-access online textbook, seeks to help you tell your story—and show your data—through the power of the public web. This open-access book reflects what I’ve learned while teaching data visualization to undergraduate students at Trinity College, and now to a global online class on the Trinity edX platform. Over the past few years, Trinity students and I have built interactive charts and maps in partnership with non-profit organizations in Hartford, Connecticut, to help them share their stories with data on the public web. Also, my students and colleagues have used these tools to create On The Line: How Schooling, Housing, and Civil Rights Shaped Hartford and its Suburbs, an open-access book-in-progress that features interactive historical maps of urban-suburban change. Students and colleagues who wrote tutorials, designed learning exercises, or developed code templates for Hands-On Data Visualization are listed as authors and contributors. Although my outstanding colleagues have professional training, do not confuse them with me, the proverbial “Jack of all trades, master of none.” I do not consider myself an expert in data visualization, nor should anyone mistake me for a computer scientist or data scientist. Inspect my higher education transcripts and you’ll see only one computer science class (something called FORTRAN77 back in 1982), and not a single course in statistics, sadly. Instead, my desire to learn data visualization was driven by my need as an historian to tell stories about urban-suburban places and change over time. If you’ve ever watched me teach a class or deliver a presentation on these topics – always talking with my hands in the air – you’ll understand my primal need to create charts and maps. Stories become more persuasive when supported with data, especially well-crafted images that convey data relationships more clearly than words. Furthermore, these data stories become more powerful when we share them online, where they reach broader audiences who can interact with and evaluate our evidence. In the early 2000s, when I began to dabble in data visualization, our tools were expensive, not easy to learn, and not designed to share our stories on the public web. (One of my well-worn jokes is point to the bald spot on my head, and claim that it was caused while tearing out my hair in frustration while using ArcGIS.) But everything began to change around 2005 when Google Maps publicly released its application programming interface (API) that allowed people with some coding skills to show data points on an interactive web map. Gradually, between 2008-11, I began learning what was possible by working on map projects with talented programmers and geographers, such as Jean-Pierre Haeberly at Trinity, and Michael Howser at the University of Connecticut Libraries Map and Geographic Information Center (MAGIC, my favorite acronym), thanks to a grant from the National Endowment for the Humanities. Free and low-cost workshops sponsored by The Humanities and Technology Camp (THATCamp) at the Center for History and New Media at George Mason University, and Transparency Camp by the Sunlight Foundation, introduced me to many people (especially Mano Marks and Derek Eder) who demonstrated easier-to-use tools and templates, such as Google Fusion Tables and GitHub. Closer to home, Alvin Chang and other data journalists at the Connecticut Mirror showed me how to tell stories on the web with more flexible open-source tools, such as Leaflet and Highcharts. All of these data visualization lessons I learned have been so valuable—to me, my students, our community partners, and thousands of readers on the web—that my co-authors and I have agreed to share our knowledge with everyone for free. This open-access book is guided by the principle of democratization of knowledge for the public good, hence the book’s title: Hands-On Data Visualization. Not everyone can afford to make this choice, I realize. But the mission of Trinity College is to engage, connect, and transform, with both our local city of Hartford and the world at large. Since Trinity already pays my salary as a tenured professor, the right thing to do with the knowledge my students and I have gained is to pay it forward. That’s why we created Hands-On Data Visualization. If this free book is valuable for your education, then join us by sharing and supporting it for future readers: Tell your friends about the book and share the link via social media, text, or email Improve the book by adding comments or suggesting new chapters on our GitBook platform Try out the tutorials, explore the online examples, share what you’ve learned with others, and dream about better ways to tell your data stories. Warning: To follow the steps in this book, we recommend either a desktop or laptop computer, running either the Mac or Windows or Linux operating system, with an internet connection and a modern web browser such as Chrome, Firefox, Safari, or Edge. Another good option is a Chromebook laptop, which enables you to complete most of the steps in this book, and we’ll point out any limitations in specific chapters. While it’s possible to use a tablet or smartphone device, we do not recommend it because you cannot follow all of the steps, and you’ll also get frustrated with the small screen and perhaps throw your device (or this book) across the room, and possibly hit someone else in the head. Ouch! We are not responsible for injuries caused by flying objects. Tip: If you’re working on a laptop, consider buying or borrowing an external mouse that can plug into your machine. We’ve met several people who found it much easier to click, hover, and scroll with a mouse rather than a laptop’s built-in trackpad. Tip: If you’re new to working with computers—or teaching new users with this book—consider starting with mouse exercises. All of the tools in this book assume that users already know how to click tiny buttons, hover over links, and scroll web pages, but rarely are these skills taught, and everyone needs to learn them at some point in our lives. "],
["how-to-read.html", "How to Read on the Web", " How to Read on the Web TODO: use conditional formatting to make this section appear only in the HTML edition; may need to convert to a free-standing chapter This open-access book-in-progress is free to read on the web at http://HandsOnDataViz.org to fully experience the interactive charts, maps, and video clips. Any modern web browser will display the book, but readers may prefer larger screens (laptops or desktops) over smaller screens (such as smartphones or tablets). In your web browser, try these toolbar features near the top of the page: Menu Search Font to adjust text size and display View source code on GitHub Shortcuts (arrow keys to navigate; s to toggle sidebar; f to toggle search) Social Media Share Screenshot: How to read Open links in new tabs Keep your place when reading online and moving between pages. Two-finger trackpad click or Control + click (Mac) or Alt + click (Chromebook) or right-click (Windows and others) Screenshot: Open link in new tab (on Mac) Use a second monitor If you have a small screen, consider connecting a second monitor, or work next to a second computer or tablet. This allows you to view tutorials in one screen and build visualizations in the other screen. Image: Laptop with second monitor, and with tablet Refresh browser To view the most up-to-date content in your web browser, do a “hard refresh” to bypass any saved content in your browser cache. Ctrl + F5 (most Windows-Linux browsers) Command + Shift + R (Chrome or Firefox for Mac) Shift + Reload button toolbar (Safari for Mac) "],
["choose.html", "Chapter 1 Choose Tools to Tell Your Data Story", " Chapter 1 Choose Tools to Tell Your Data Story TODO: Reorganize and rewrite chapter Revise title? – Choose Tools to Draw Your Data Story Push away the computer and pick up some old-school tools: colored markers or pencils lots of blank paper your imagination Once you have a clearer mental (and physical) picture of what you seek to create, then choose digital tools… Do you feel overwhelmed by the enormous range of data visualization tools? There’s been so many different tools released in recent years that anyone would have a hard time deciding which ones to use. Even if you limit your choices to the dozen or so tools specifically mentioned in this book, how do you make wise decisions? Draw and Write Your Data Story reminds us to start with the most important item in your toolkit: your story. Begin by drawing pictures and writing questions or sentences to capture your ideas on paper, and then choose the most appropriate tools to create your vision. Ask Questions When Choosing Tools lists several criteria to consider when making software decisions. Many of us look for free or affordable tools in the perfect sweet spot—easy-to-learn, yet powerful—and that’s the focus of this book. Rate Three Simple Map Tools invites readers to create a basic interactive point map using three different online tools, and to evaluate each one using selected criteria from the chapter above. TODO: add password manager tutorial to keep track of your accounts for the online tools you’ll use in this book. The free and open-source BitWarden.com tool nicely integrates with most browsers and even smartphones. Enroll in our free online course TO DO add link, which introduces these topics in the brief video below, and offers more exercises and opportunities to interact with instructors and other learners. Watch the YouTube Video "],
["draw.html", "Draw and Write Your Data Story", " Draw and Write Your Data Story Before you dive deeply into software, think about the most important item in your toolkit: your story. The primary reason we’re designing visualizations is to improve how we communicate our data story to other people, so let’s begin there. Push away the computer and pick up some old-school tools: colored markers or pencils lots of blank paper your imagination First, at the top of the page, write down your data story. Is it in the form of a question? If so, figure out how to pose the question. [Use some of this from ch 3? – Start the process by writing down your question—literally in the form of a question, punctuated with a question mark—to clarify your own thinking, and also so that you can clearly communicate it to others who may be assisting you. All too often, our brains automatically jump ahead to try to identify the answer, without reflecting on the best way frame the question in a way that does not limit the range of possible results.] Or maybe it’s in the form of an answer to that question? If so, spell out your clearest statement. If you’re lucky, perhaps you already can envision a full story, with a beginning, middle, and end. Whatever form it takes in your head, write out the words that come to mind. Further down the page (or on a separate sheet), draw quick pictures of the visualizations that comes to your mind, even if you don’t yet have any data. No artistic skills are required. Just use your imagination. - Do you envision some type of chart? Sketch a picture. - Or do you imagine some type of map? Show what it might look like. - Will your visualization be interactive? Insert arrows, buttons, whatever. Finally, share your data story with someone else and talk through your preliminary ideas. Does your sketch and sentences help to convey the broader idea that you’re trying to communicate? If so, this is one good sign that your data story is worth pursuing, with the visualization tools, templates, and techniques in other chapters of this book. "],
["ask.html", "Ask Questions When Choosing Tools", " Ask Questions When Choosing Tools When each of us decides which digital tools best fit our needs, we often face trade-offs. On one hand, many of us prefer easy-to-learn tools, especially those with a drag-and-drop interface, but they often force us to settle for limited options. On the other hand, we also favor powerful tools that allow us to control and customize our work, yet most of these require higher-level coding skills. The goal of this book is to find the best of both worlds: that “sweet spot” where tools are both friendly and flexible. Diagram: the ‘sweet spot’ for easy-to-learn and powerful tools Before testing out new tools, try listing the criteria that guide your decision-making process. What are the most important factors that influence whether or not you add another item to your digital toolkit? Here’s the list that came to our minds: Price: Is the tool free, or is there a “freemium” model to pay for more features or higher usage? Easy-to-learn: Is the tool relatively simple for new users without coding skills? Power: Does the tool support large amounts of data, and various types of visualizations? Customization: Can I modify details about how my work appears? Data Migration: Can I easily move my data in and out, in case I switch to a different tool? Hint for historians: Future-proof your digital history projects! Choose tools that allow you to easily export and migrate data to other platforms. Design projects to keep your data separate from its digital presentation. Hosting: Can I decide exactly where my data and visualizations will be stored online? Support: Is the tool actively maintained by its creators, and do they answer questions? Open Source: Is the tool’s software visible, can it be modified, and redistributed? Security: Is the tool and my data protected from malicious hackers and malware? Collaborative: Does the tool allow several people to work together on one shared product? Privacy: Under the terms of service, is my data and work private or public? Error-friendly: When something fails, does the tool point out possible problems and solutions? Cross-platform: Does this tool work across different computer operating systems? Mobile-friendly: Will it correctly display my work on various mobile devices and browsers? That’s a long list! It’s even longer than the number of tools we’ll mention in this book. But don’t let it overwhelm you. The diagram at the top of the page illustrates the two most important criteria for the many free tools that are currently available: easy-to-learn and powerful features. TODO: expand on privacy to review sample “terms of service” to use free tools such as Google Drive - https://support.google.com/drive/answer/2450387?hl=en#:~:text=As%20our%20Terms%20of%20Service,store%20in%20your%20Drive%20account. - See alimSpyingStudentsSchool2017 - Many of the free web-based tools in this book require that your publicly share your data. Check each tool and decide whether it is appropriate for your data, which may have some privacy restrictions. Learn more about choosing tools Carl V. Lewis, Dataviz.tools: A curated guide to the best tools, resources and technologies for data visualization, http://dataviz.tools Lincoln Mullen, “How to Make Prudent Choices About Your Tools,” ProfHacker blog, Chronicle of Higher Education, August 14, 2013, http://www.chronicle.com/blogs/profhacker/how-to-make-prudent-choices-about-your-tools Lisa Charlotte Rost, “What I Learned Recreating One Chart Using 24 Tools,” Source, December 8, 2016, https://source.opennews.org/en-US/articles/what-i-learned-recreating-one-chart-using-24-tools/ Lisa Spiro and colleagues, DiRT: Digital Research Tools Directory (formerly Bamboo), http://dirtdirectory.org Audrey Watters, “‘The Audrey Test’: Or, What Should Every Techie Know About Education?,” Hack Education, March 17, 2012, http://hackeducation.com/2012/03/17/what-every-techie-should-know-about-education "],
["rate.html", "Rate Three Simple Map Tools", " Rate Three Simple Map Tools Let’s explore criteria from the previous chapter by comparing three different tools, and reflecting on which factors you feel are most important when making decisions about your toolkit. We’ll test three drag-and-drop tools to transform sample address data into a simple interactive point map. Each tool can geocode address data by looking up a location (such as 500 Main Street, Hartford CT) in a large database, deciding on the best match, and converting this data into latitude and longitude coordinates (such as 41.762, -72.674). For our sample data, we’ll use this table of 9 locations in North America, with 3 intentional mistakes to test for geocoding errors. Image: Sample address data screenshot First, click this link and Save to download the sample file to your computer: sample-address-data in CSV format. CSV means comma-separated-values, a generic spreadsheet format that many tools can easily open. If you need help with downloading, see this short video tutorial. Next, build a point map with the sample data, by following the tutorials for the three tools below. Tool Step-by-step tutorial in this book Google My Maps My Maps tutorial Carto Builder Carto tutorial Finally, rate your experience using each tool with these selected criteria: Easy-to-learn: Which tool was the simplest for creating a basic point map? Price: Which of these free tools provided the most services at no cost? Customization: Which tool enabled you to modify the most details about your map? Data Migration: Which tool most easily allowed you to import and export your data? Error-friendly: Which tool geocoded most accurately or signaled possible errors? Recommended: Enroll in our free online course LINK TO DO to compare your ratings to other students. Summary TODO "],
["spreadsheet.html", "Chapter 2 Strengthen Your Spreadsheet Skills", " Chapter 2 Strengthen Your Spreadsheet Skills Before we begin to design data visualizations, it’s important to make sure our spreadsheet skills are up to speed. While teaching this topic, we’ve heard many people describe how they “never really learned” how to use spreadsheet tools as part of their official schooling or workplace training. But spreadsheet skills are vital to learn, not only as incredible time-savers for tedious tasks, but more importantly, to help us discover the stories buried inside our data. The interactive charts and maps that we’ll construct later this book are built on data tables, which we typically open with spreadsheet tools, such as Google Sheets, LibreOffice, or Microsoft Excel. Spreadsheets typically contain columns and rows of numerical or textual data, as shown in Figure 2.1. The first row often contains headers, meaning labels describing the data in each column. Also, columns are automatically labeled with letters, and rows with numbers, so that every cell or box in the grid can be referenced, such C2. When you click on a cell, it may display a formula that automatically runs a calculation with references other cells. Formulas always begin with an equal sign, and may simply add up other cells (such as =C2+C3+C4), or may contain a function that performs a specific operation (such as calculating the average of a range of cells: =average(C2:C7)). Some spreadsheet files contain multiple sheets (sometimes called workbooks), where each tab across the bottom opens a specific sheet. Figure 2.1: Screenshot of a typical spreadsheet, with headers, tabs, and the active cell displaying a formula. In this chapter, we’ll start by reviewing basic steps, such as sharing, uploading, geocoding with add-on tools, and collecting data with online forms. Then we’ll move on to ways of organizing and analyzing your data, such as sorting and filtering, calculating with formulas, and summarizing with pivot tables. Finally, we’ll examine ways to connect different sheets, such as matching columns with lookup tables, and relational databases. We illustrate all of these methods with beginner-level users in mind, meaning they do not require any prior background. If you want to learn ways to make your computer do more of the tedious data preparation work for you, this chapter is definitely for you. Or if you already feel very familiar with spreadsheets, you should at least skim this chapter, and perhaps you’ll learn a trick or two that will help you to create charts and maps more efficiently later in the book. "],
["spreadsheet-tools.html", "Select your Spreadsheet Tools", " Select your Spreadsheet Tools Which spreadsheet tools should you use? As we describe in more detail in Chapter 1: Choose Tools to Tell Your Data Story, the answer depends on how you respond to different questions about your work. First, is your data public or private? If private, consider using a downloadable spreadsheet tool that runs on your computer, to reduce the risk of an accidental data breach that might happen when using an online spreadsheet tool that automatically stores your data in the cloud. Second, will you be working solo or with other people? For collaborative projects, consider using an online spreadsheet tool that’s designed to allow other team members to simultaneously view or edit data. Third, do you need to import or export data in any specific format (which we’ll describe in the next section), such as Comma Separated Values (CSV)? If yes, then choose a spreadsheet tool that supports that format. Finally, do you prefer a free tool, or are you willing to pay for it, or donate funds to support open-source development? Here’s how three common spreadsheet tools compare on these questions: Google Sheets is a free online spreadsheet tool that works in any modern web browser, and automatically stores your data in the cloud. While data you upload is private by default, you can choose to share it with specific individuals or anyone on the internet, and allow them to view or edit for real-time collaboration, similar to Google Documents. Google Sheets also imports and exports data in CSV, ODS, Excel, and other formats. You can sign up for a free personal Google Drive account with the same username as your Google Mail account, or create a separate account under a new username to reduce Google’s invasion into your private life. Another option is to pay for a Google Suite business account subscription, which offers nearly identical tools, but with sharing settings designed for larger organizations or educational institutions. LibreOffice is a free downloadable suite of tools, including its Calc spreadsheet, available for Mac, Windows, and Linux computers, and is an increasingly popular alternative to Microsoft Office. When you download LibreOffice, its sponsor organization, The Document Foundation, requests a donation to continue its open-source software development. The Calc spreadsheet tool imports and exports data in its native ODS format, as well as CSV, Excel, and others. While an online collaborative platform is under development, it is not yet available for broad usage. Microsoft Excel is the spreadsheet tool in the Microsoft Office suite, which is available in different versions, though commonly confused as the company has changed its product names over time. A paid subscription to Microsoft 365 provides you with two versions: the full-featured downloadable version of Excel (which is what most people mean when they simply say “Excel”) for Windows or Mac computers and other devices, and access to a simpler online Excel through your browser, including file sharing with collaborators through Microsoft’s online hosting service. If you do not wish to pay for a subscription, anyone can sign up for a free version of online Excel at Microsoft’s Office on the Web, but this does not include the full-featured downloadable version. The online Excel tool has limitations. For example, neither the paid nor the free version of online Excel allows you to save files in the single-sheet generic Comma Separated Values (.csv) format, an important featured required by some data visualization tools in later chapters of this book. You can only export to CSV format using the downloadable Excel tool, which is now available only with a paid Microsoft 365 subscription. Deciding which spreadsheet tools to use is not a simple choice. Sometimes our decisions change from project to project, depending on costs, data formats, privacy concerns, and the personal preferences of any collaborators. Occasionally we’ve also had co-workers or clients specifically request that we send them non-sensitive spreadsheet data attached to an email, rather than sharing it through a spreadsheet tool platform that was designed for collaboration. So it’s best to be familiar with all three commonly-used spreadsheet tools above, and to understand their respective strengths and weaknesses. In this book, we primarily use Google Sheets for most of our examples. All of the data we distribute through this book is public. Also, we wanted a spreadsheet tool designed for collaboration, so that we can share links to data files with readers like you, so that you can view our original version, and either make a copy to edit in your own Google Drive, or download in a different format to use in LibreOffice or Excel. Most of the spreadsheet methods we teach look the same across all spreadsheet tools, and we point out exceptions when relevant. Sidebar: Common data formats Spreadsheet tools organize data in different formats. When you download spreadsheet data to your computer, you typically see its filename, followed by a period and a 3- or 4-character abbreviated extension, which represents the data format, as shown in Figure 2.2. The most common data formats we use in this book are: .csv means Comma Separated Values, a generic format for a single sheet of simple data, which saves no formulas nor styling. .ods means OpenDocument Spreadsheet, a standardized open format that saves multi-tabbed sheets, formulas, styling, etc. .xlsx or the older .xls means Excel, a Microsoft format that supports multi-tabbed sheets, formulas, styling, etc. .gsheet means Google Sheets, which also supports multi-tabbed sheets, formulas, styling, etc., but you don’t normally see these on your computer because they are primarily designed to exist online. Figure 2.2: Three data formats commonly seen on your computer—csv, ods, and xlsx—when displayed properly in the Mac Finder. Warning: Several tools in this book may not work properly on a Mac computer that does not display the filename extensions, meaning the abbreviated file format after the period, such as data.csv or map.geojson. The Mac operating system hides these by default, so you need to turn them on by going to Finder &gt; Preferences &gt; Advanced, and check the box to Show all filename extensions, as shown in Figure 2.3. Figure 2.3: On a Mac, go to Finder-Preferences-Advanced and check the box to Show all filename extensions. "],
["csv.html", "Download to CSV or ODS Format", " Download to CSV or ODS Format In Chapter 1: Choose Tools to Tell Your Data Story, we learned the advantages of selecting software tools that support data migration, so that you can export your work to other platforms. Since digital technology is always changing, it’s a good rule of thumb to never upload important data into a tool if you can’t easily get it back out. Ideally, spreadsheet tools should allow you to export your work in generic or open-data file formats, such as Comma Separated Values (CSV) and OpenDocument Spreadsheet (ODS), to maximize your options to migrate to other platforms. Warning: If you’re working in any spreadsheet with multiple tabs and formulas, a CSV export will save only the active sheet (meaning the one you’re currently viewing), and only the data in that sheet (meaning that if you inserted formulas to run calculations, only the results would appear, not the formulas). Later in this book you may need to create a CSV file to import into a data visualization tool, so if the source was a multi-tabbed spreadsheet with formulas, keep track of the original. One reason we feature Google Sheets in this book is because it exports data in several common formats. To try it, open this Google Sheets sample data file in a new tab, and go to File &gt; Download to export in CSV format (for only the data in the active sheet) or ODS format (which keeps data and most formulas in multi-tab spreadsheets), or other formats such as Excel, as shown in Figure 2.4. Similarly, in the downloadable LibreOffice and its Calc spreadsheet tool, select File &gt; Save As to save data in its native ODS format, or to export to CSV, Excel, or other formats. Figure 2.4: In Google Sheets, go to File - Download As to export data in several common formats. But exporting data can be trickier in Microsoft Excel. Using the online Excel tool in your browser (either the free or paid version), you cannot save files in the generic single-sheet CSV format, a step required by some data visualization tools in later chapters of this book. Only the downloadable Excel tool (which now requires a paid subscription) will export in CSV format, a step required by some data visualization tools in later chapters of this book. And when using the downloadable Excel tool to save in CSV format, the steps sometimes confuse people. First, if you see multiple CSV options, choose CSV UTF-8, which should work best across different computer platforms. Second, if your Excel workbook contains multiple sheets or formulas, you may see a warning that it cannot be saved in CSV format, which only saves data (not formulas) contained in the active sheet (not all sheets). If you understand this, click OK to continue. Third, on the next screen, Excel may warn you about “Possible data loss” when saving an Excel file in CSV format, for reasons described above. Overall, when working with the downloadable Excel tool, first save the full-version of your Excel file in XLSX format before exporting a single sheet in CSV format. Once you’ve learned how to export your spreadsheet data into an open format, you’re ready to migrate it into other data visualization tools or platforms that we’ll introduce in later chapters of this book. Data portability is key for ensuring that your charts and maps will last well into the future. "],
["copy.html", "Make a Copy of a Google Sheet", " Make a Copy of a Google Sheet In this book we provide several data files using Google Sheets. Our links point to the online files, and we set the sharing settings to allow anyone to view—but not edit—the original version. This allows everyone to have access to the data, but no one can accidentally modify the contents. In order for you to complete several exercises in this chapter, you need to learn how to make your own copy of our Google Sheets—which you can edit—without changing our originals. Let’s begin by making a copy of a real dataset that may interest you, because it includes people like you. So far about 3,000 readers of this book have responded to a quick public survey about their general location, prior level of experience and education, and goals for learning data visualization. If you haven’t already done so, fill out the quick survey form to contribute your own response, and also to give you a better sense of how the questions were posed. Later in this chapter you’ll learn how to create your own online form with a link to spreadsheet results. Open this Google Sheet of Hands-On Data Visualization reader public survey responses in a new tab in your browser. We set it to “View only” so that anyone on the internet can see the contents, but not edit the original file. Sign in to your Google account by clicking the blue button in the upper-right corner. Go to File &gt; Make a Copy to create a duplicate of this Google Sheet in your Google Drive, as shown in Figure 2.5. You can rename the file to remove “Copy of…”. Figure 2.5: Go to File - Make a Copy to create your own version of this Google Sheet. To keep your Google Drive files organized, save them in folders with relevant names to make them easier to find. For example, you can click the My Drive button and the New folder button to create a folder for your data, before clicking OK, as shown in Figure 2.6. Figure 2.6: Click the My Drive and New folder buttons to save your work in a folder. Your copy of the Google Sheet will be private to you only, by default. In the next section we’ll learn about different options for sharing your Google Sheet data with others. "],
["share.html", "Share Your Google Sheets", " Share Your Google Sheets If you’re working on a collaborative project with other people, Google Sheets offers several ways to share your data online, even with people who do not own a Google account. When you create a new Sheet, its default setting is private, meaning only you can view or edit its contents. In this section, you’ll learn how to expand those options using the Share button. Log into your Google Drive account, click the New button, select Google Sheets, and create a blank spreadsheet. You will need to name your file to proceed with next steps. Click the Share button in the upper-right corner, and your options will appear on the Share with people and groups screen, as shown in Figure 2.7. In the top half of the screen, you can share access with specific individuals by typing their Google usernames into the Add people and groups field. For each person or group you add, on the next screen select the drop-down menu to assign them to be Viewer, Commenter, or Editor of the file. Decide if you wish to notify them with a link to the file and optional message. In the lower half of the screen, you can share access more widely by clicking on Change to anyone with the link. On the next screen, the default option is to allow anyone who has the link to View the file, but you can change this to allow anyone to Comment on or Edit it. Also, you can click Copy link to paste the web address to your data in an email or public website. Figure 2.7: Click the Share button to grant access to individuals (top half) or anyone with the link (bottom half). Tip: If you don’t want to send people a really long and ugly Google Sheet web address such as: https://docs.google.com/spreadsheets/d/1egX_akJccnCSzdk1aaDdtrEGe5HcaTrlOW-Yf6mJ3Uo then use a free link-shortening service. For example, by using our free Bitly.com account and its handy Chrome browser extension or Firefox browser extension, we can paste in a long URL and customize the back-end to something shorter, such as bit.ly/reader-survey, as shown in Figure 2.8. If someone else has already claimed your preferred custom name, you’ll need to think up a different one. Beware that bit.ly links are case-sensitive, so we prefer to customize the back-end in all lower-case to match the front-end. Figure 2.8: Use a free link-shortening service, such as Bitly.com, and customize its back-end. Now that you have different options for sharing a Google Sheet, let’s learn how to upload and convert data from different formats. "],
["upload.html", "Upload and Convert to Google Sheets", " Upload and Convert to Google Sheets We feature Google Sheets in this book partly because it supports data migration, meaning the ability to import and export files in many common formats. But imports work best when you check the Convert uploads box, which is hidden inside the Google Drive Settings gear symbol as shown in Figure 2.9. Checking this box automatically transforms Microsoft Excel sheets into Google Sheets format (and also Microsoft Word and PowerPoint files into Google Documents and Slides formats), which allows easier editing. If you don’t check this box, then Google will keep your files in their original format, which makes them harder to edit. Google turns off this conversion setting by default on new accounts, but we’ll teach you how to turn it on, and the benefits of doing so. Find a sample Excel file you can use on your computer. If you don’t have one, open and save to download to your computer this Excel file of a subset of the Hands-On Data Visualization reader public survey responses Log into your Google Drive account, and click the Gear symbol in the upper-right corner, as shown in Figure 2.9, to open the Settings screen. Note that this global Gear symbol &gt; Settings appears at Google Drive level, not inside each Google Sheet. Figure 2.9: Click your Google Drive Gear Symbol - Settings in the upper-right corner. On the Settings screen, check the box to Convert uploaded files to Google Docs editor format, as shown in Figure 2.10, and click Done. This turns on the conversion setting globally, meaning it will convert all possible files that you upload in the future—including Microsoft Excel, Word, PowerPoint, and more—unless you turn it off. Figure 2.10: Inside your Google Drive Settings, check the box to automatically convert all uploads. Upload a sample Excel file from your computer to your Google Drive. Either drag-and-drop it to the desired folder, as shown in Figure 2.11, or use the New button and select File upload. Figure 2.11: Drag-and-drop your sample Excel file into your Google Drive to upload it. If you forget to check the Convert uploads box, Google Drive will keep uploaded files in their original format, and display their icons and file name extensions such as .xlsx or .csv, as shown in Figure 2.12. Figure 2.12: If you forget to convert uploads, Google Drive will keep files in their original format with these icons. Tip: Google Drive now allows you to edit Microsoft Office file formats, but not all features are guaranteed to work across platforms. Also, Google Drive now allows you to convert a specific uploaded Excel file into its Google format by using the File &gt; Save as Google Sheets menu. Finally, to convert individual files to your Google Drive, while keeping the global conversion setting off, from inside any Google Sheet you can select File &gt; Import &gt; Upload. But we recommend that most people turn on the global conversion setting as described above, except in cases where you intentionally use Google Drive to edit an Excel-formatted file, and understand that some features may not work. Now that you know how to upload and convert an existing dataset, in the next section you’ll learn how to install and use a Google Sheets add-on tool to geocode address data into latitude and longitude coordinates. "],
["geocode.html", "Geocode Addresses with Google Sheets Add-On", " Geocode Addresses with Google Sheets Add-On In this section, you’ll learn how to geocode data by installing a free Google Sheets add-on tool. This allows you to geocode addresses directly inside your spreadsheet, which will be very useful when using Leaflet map code templates in chapter 11. Geocoding means converting addresses or location names into geographic coordinates (or x- and y-coordinates) that can be plotted on a map, as shown in Figure 2.13. For example, the Statue of Liberty in the New York City area is located at 40.69, -74.04. The first number is the latitude and the second is the longitude. Since the equator is 0 degrees latitude, positive latitude is the northern hemisphere, and negative latitude is in the southern hemisphere. Similarly, the prime meridian is 0 degrees longitude, which passes through Greenwich, England. So positive longitude is east of the meridian, and negative longitude is west, until you reach the opposite side of the globe, roughly near the International Date Line in the Pacific Ocean. Figure 2.13: To map addresses, you first need to geocode them. If you have just one or two addresses, you can quickly geocode them with Google Maps. Search for an address, right-click on that point, and select What’s here? to reveal a popup window with its latitude and longitude, as shown in Figure 2.14. But what if you need to geocode a dozen or a hundred addresses? Figure 2.14: To geocode one address, search in Google Maps and right-click What’s here? to show coordinates. To geocode multiple addresses inside your spreadsheet, install a free Google Sheets Add-on called Geocoding by SmartMonkey, created by Xavier Ruiz, the CEO of SmartMonkey, a geographic route-planning company in Barcelona, Spain. Add-ons are created by third-party companies to expand features for Google Sheets, Google Documents, and related tools. Add-ons are verified to meet Google’s requirements and distributed through its G Suite Marketplace. First, sign into your Google Drive account, go to the Geocoding by SmartMonkey Add-on page, and click the blue button to install it in your Google Sheets. The Add-on will ask for your permission before installing, and if you agree, press Continue. In the next window, choose your Google Drive account, and if you agree with the terms, click Allow to complete the installation. Google will email you to confirm that you have installed this third-party app with access to your account. You can always review permissions and revoke access in the future, if desired. Second, go to your Google Drive and create a new Google Sheet. Select the Add-ons menu to see the new Geocoding by SmartMonkey options, and select Create Template. The Add-on will create a new tab, named Geocoding, and automatically insert 3 sample addresses, as shown in Figure 2.15. Figure 2.15: In the Google Sheets Add-On menu, select Geocoding by SmartMonkey – Create Template. Third, select the Geocoding by SmartMonkey &gt; Geocode Details menu. The Add-on will create another spreadsheet tab, called Geocoding Details, and display the results from Google services for three new columns—latitude, longitude, and address found—as shown in Figure 2.16. Always review the quality of geocoded results by comparing the Address found column to the original Address entered. Figure 2.16: Select Geocode Details to view latitude, longitude, and address found for each entry. Finally, paste your own address data into the spreadsheet to geocode it, and follow these guidelines: Each cell requires a full address. If your original data splits street, city, state, and zip code into different columns, see how to Combine Data into One Column in Chapter 4: Clean Up Messy Data. The address should follow the format of the national postal service of the country where it is located. Separate terms with spaces. Do not skip any rows in the Address column. You can leave the Country column blank, but its default value is the United States. To specify other nations, use their top-level Internet domain code, such as es for Spain. Give the tool time to work. For example, if you enter 50 addresses, expect to wait at least 15 seconds for your geocoded results. Always inspect the quality of your results, and never assume that geocoding services from any provider are accurate. If you need a faster geocoding service for US addresses, which can handle up to 10,000 requests in one upload, see bulk geocoding with the US Census in Chapter 12: Transform Your Map Data. Now that you know how to use a Google Sheets Add-on to geocode addresses, in the next section you will learn how to collect data using an online form, and access it as a spreadsheet. "],
["forms.html", "Collect Data with Google Forms", " Collect Data with Google Forms As you saw in prior sections, we invite readers of this book to fill out a quick online form so that we can learn more about people like you, and to continue to make revisions to match your expectations. So far about 3,000 readers have responded, and you can view this public spreadsheet of survey responses about their generation location, prior level of experience and education, and goals for learning data visualization. In this section, you’ll learn how to create an online form and link the results to a live Google Sheet. Inside your Google Drive account, one tool that’s often overlooked is Google Forms, which is partially hidden under New &gt; More &gt; Google Forms, as shown in Figure 2.17. Figure 2.17: The Google Forms tool is partially hidden in the Google Drive New - More menu. The Google Forms Questions tab allows you to design questions with different types of responses: short- and paragraph-length answers, multiple choice, checkboxes, file uploads, etc., as shown in Figure 2.18. Furthermore, Google Forms attempts to interpret questions you enter in order to predictively assign them to a type. Figure 2.18: The Google Forms Questions tab allows you to designate different types of responses. Give each question a very short title, since these will appear as column headers in the linked spreadsheet you’ll create further below. If a question needs more explanation or examples, click the three-dot kebob menu in the bottom-right corner to Show &gt; Description, which opens a text box where you can type in more details, as shown in Figure 2.19. Also, you can Show &gt; Response validation, which requires users to follow a particular format, such as an email address or phone number. Furthermore, you can select the Required field to require users to respond to a question before proceeding. See additional options on the Google Forms support page. Figure 2.19: Click the three-dot kebab menu to Show - Description to add details for any question. To preview how your online will appear to recipients, click the Eyeball symbol near the top of the page, as shown in Figure 2.20. When your form is complete, click the Send button to distribute it via email, a link, or to embed the live form as an iframe on a web page. Learn more about the latter option in Chapter 8: Embed On Your Web. Figure 2.20: Click the Eyeball symbol to preview your form. The Google Forms Responses tab will show individual results you receive, and also includes a powerful button to open the data in a linked Google Sheet, as shown in Figure 2.21. Figure 2.21: The Google Forms Responses tab includes a button to open results in a linked Google Sheet. Now that you’ve learned how to collect data with an online form and linked spreadsheet, the next two sections will teach you how to sort, filter, and pivot tables to begin analyzing their contents and the stories they reveal. "],
["sort.html", "Sort and Filter Data", " Sort and Filter Data Spreadsheet tools help you to dig deeper into your data and raise the stories you find to the surface. A basic step in organizing your data is to sort a table by a particular column, to quickly view its minimum and maximum values, and the range that lies in between. A related method is to filter an entire table to display only rows that contain certain values, to help them stand out for further study among all of the other entries. Both of these methods become more powerful when your spreadsheets contain hundreds or thousands of rows of data. To learn how to sort and filter, let’s explore a large dataset of around 3,000 readers of this book who responded to a quick public survey about their general location, prior level of experience and education, and goals for learning data visualization. If you haven’t already done so, fill out the quick survey form to contribute your own response, and also to give you a better sense of how the questions were posed. Open this Google Sheet of Hands-On Data Visualization reader public survey responses in a new tab in your browser. Login to your Google Sheets account, and go to File &gt; Make a Copy to create your own version that you can edit. Before sorting, click the upper-left corner of the sheet to select all cells, as shown in Figure 2.22. When the entire sheet becomes light blue, and all of the alphabetical column and numerical row headers become dark grey, this confirms you’ve selected all cells. Figure 2.22: Click the upper-left corner to select all cells before sorting. Warning: If you forget to select all cells, you might accidentally sort one column independently of the others, which will scramble your dataset and make it meaningless. Always select all cells before sorting! In the top menu, go to Data &gt; Sort Range to review all of your sort options. In the next screen, check the Data has header row box to view the column headers in your data. Let’s sort the Experience with data visualization column in ascending order (from A-Z), as shown in Figure 2.23, to display the minimum at the top, the maximum at the bottom, and the range in between. Figure 2.23: Go to Data - Sort Range, check the header row box, and sort by Experience with dataviz in ascending order. Scroll through your sorted data and you’ll see that over 1,000 readers rated themselves as beginners (level 1) with data visualization. Tip: When working with large spreadsheets, you can “freeze” the first row so that column headers will still appear as you scroll downward. In Google Sheets, go to View &gt; Freeze and select 1 row, as shown in Figure 2.24. You can also freeze one or more columns to continuously display when scrolling sideways. LibreOffice has a same option to View &gt; Freeze Rows and Columns, but Excel has a different option called Window &gt; Split. Figure 2.24: In Google Sheets, go to View - Freeze to select the number of rows to continuously display when scrolling downward. Now let’s try filtering your sheet. Go to Data &gt; Create a Filter, which inserts downward arrows in each column header. Click on the downward arrow-shaped toggle in the Occupation column, and see options to display or hide rows of data. For example, look under Filter by values, then click the “Clear” button to undo all options, then click only educator to display only rows with that response, as shown in Figure 2.25. Click “OK”. Figure 2.25: Go to Data - Create a Filter, click the downward arrow in the Occupation column, select only educator. Now your view of reader responses is sorted by experience, and filtered to show only educators. Scroll through their one-sentence goals for learning about data visualization. How to do they compare to your own goals? In the next section, we’ll learn how to start analyzing your data with simple formulas and functions. "],
["calculate.html", "Calculate with Formulas", " Calculate with Formulas Spreadsheet tools can save you lots of time when you insert simple formulas and functions to automatically perform calculations across entire rows and columns of data. Formulas always begin with an equal sign, and may simply add up other cells (such as =C2+C3+C4), or may contain a function that performs a specific operation (such as calculating the sum of a range of cells: =SUM(C2:C100)). In this section you’ll learn how to write two formulas with functions: one to calculate an average numeric value, and another to count the frequency of a specific text response. Let’s explore a large dataset of around 3,000 readers of this book who responded to a quick public survey about their general location, prior level of experience and education, and goals for learning data visualization. If you haven’t already done so, fill out the quick survey form to contribute your own response, and also to give you a better sense of how the questions were posed. Open this Google Sheet of Hands-On Data Visualization reader public survey responses in a new tab in your browser. Log into your Google Drive account, and go to File &gt; Make a Copy to edit your own version. Add a blank row immediately below the header to make space for our calculations. Right-click on row number 1 and select Insert 1 below to add a new row, as shown in Figure 2.26. Figure 2.26: Right-click on row number 1 and select Insert 1 below. Let’s calculate the average level of reader experience with data visualization. Click on cell E2 in the new blank row you just created, and type an equal symbol (=) to start a formula. Google Sheets will automatically suggest possible formulas based on the context, and you can select one that displays the average for current values in the column, such as =AVERAGE(E3:E2894), then press Return or Enter on your keyboard, as shown in Figure 2.27. Figure 2.27: Type = to start a formula and select the suggestion for average, or type it directly in with the correct range. Since our live spreadsheet has a growing number of survey responses, you will have a larger number in the last cell reference to include all of the entries in your version. Currently, the average level of reader experience with data visualization is around 2 on a scale from 1 (beginner) to 5 (professional), but this may change as more readers fill out the survey. Note that if any readers leave this question blank, spreadsheet tools ignore empty cells when performing calculations. Tip: In Google Sheets, another way to write the formula above is =AVERAGE(E3:E), which averages all values in column E, beginning with cell E3, without specifying the last cell reference. Using this syntax will keep your calculations up-to-date if more rows are added, but it does not work with LibreOffice or Excel. Part of the magic of spreadsheets is that you can use the built-in hold-and-drag feature to copy and paste a formula across other columns or rows, and it will automatically update its cell references. Click in cell E2, and then press and hold down on the blue dot in the bottom-right corner of that cell, which transforms your cursor into a crosshair symbol. Drag your cursor to cell F2 and let go, and show in Figure 2.28. The formula will be automatically pasted and updated for the new column to =AVERAGE(F3:F2894) or AVERAGE(F3:F), depending on which way you entered it above. Once again, since this is a live spreadsheet with a growing number of responses, your sheet will have a larger number in the last cell reference. Figure 2.28: Click on the blue bottom-right dot in cell E2, then hold-and-drag your crosshair cursor in cell F2, and let go to automatically paste and update the formula. Since the Occupation column contains a defined set of text responses, let’s use a different function to count them using an if statement, such as the number of responses if a reader listed “educator”. Click in cell G2 and type the equal symbol (=) to start a new formula. Google Sheets will automatically suggest possible formulas based on the context, and you can select one that displays the count if the response is educator for current values in the entire column. You can directly type in the formula =COUNTIF(G3:G2894,\"=educator\"), where your last cell reference will be a larger number to reflect all of the rows in your version, or type in the Google Sheets syntax =COUNTIF(G3:G,\"=educator\") that runs the calculation on the entire column without naming a specific endpoint, as shown in Figure 2.29. Figure 2.29: Select or enter a formula that counts responses if the entry is educator. Spreadsheet tools contain many more functions to perform numerical calculations and also to modify text. Read more about functions in this support pages for Google Sheets, LibreOffice, or Microsoft Excel support page. See additional spreadsheet skills in later chapters of the book, such as how to find and replace with blank, split data into separate columns, and combine data into one column in Chapter 4: Clean Up Messy Data. See also how to pivot address points into polygons and how to normalize data in Chapter 12: Transform Your Map Data. Now that you’ve learned how to count one type of survey response, the next section will teach you how to regroup data with pivot tables that summarize all responses by different categories. "],
["pivot.html", "Summarize Data with Pivot Tables", " Summarize Data with Pivot Tables Pivot tables are another powerful feature built into spreadsheet tools to help you reorganize your data and summarize it in a new way, hence the name “pivot.” Yet pivot tables are often overlooked by people who were never taught about them, or have not yet discovered how to use them. In this section, we’ll start with a large dataset of around 3,000 readers of this book who responded to a quick public survey. Each row represents an individual reader, including their occupation and prior level of experience with data visualization. You’ll learn how to “pivot” this individual-level data into a new table that displays the total number of reader responses by two categories: occupation and experience level. Open this Google Sheet of Hands-On Data Visualization reader public survey responses in a new tab in your browser. Log into your Google Drive account, and go to File &gt; Make a Copy to edit your own version. Or, if you have already created your own copy for the prior section on Formulas and Functions, delete row 2 that contains our calculations, because we don’t want those getting mixed into our pivot table. Go to Data &gt; Pivot Table, and on the next screen, select Create in a new sheet, as shown in Figure 2.30. The new sheet will include a Pivot Table tab at the bottom. Figure 2.30: Go to Data - Pivot Table, and create in a new sheet. In the Pivot table editor screen, you can regroup data from the first sheet by adding rows, columns, and values. First, click the Rows Add button and select Occupation, which displays the unique entries in that column, as shown in Figure 2.31. Figure 2.31: In the Pivot table editor, click the Rows Add button and select Occupation. Next, to count the number of responses for each entry, click the Values Add button and select Occupation again. Google Sheets will automatically summarize the values by COUNTA, meaning it displays the frequency of each textual response, as shown in Figure 2.32. Figure 2.32: In the Pivot table editor, click the Values Add button and select Occupation. Currently, the top three occupations listed by readers are information technology, for-profit business, and student. Since this is a live spreadsheet, these rankings may change as more readers respond to the survey. Furthermore, you can create a more advanced pivot cross-tabulation of occupation and experience among reader responses. Click on the Columns button to add Experience with data visualization, as shown in Figure 2.33. Figure 2.33: In the Pivot table editor, click the Columns Add button and select Experience with data visualization. To go one step further, Filter the data to limit the pivot table results by another category. For example, in the drop-down menu, you can click the Filters Add button, select Years of school, then under Filter by values select Clear, then check 20 to display only readers who listed 20 or more years. Deciding how to add Values in the Pivot table editor can be challenging, because there are multiple options to summarize the data, as shown in Figure 2.34. Google Sheets will offer its automated guess based on the context, but you may need to manually select the best option to represent your data as desired. Three of the most common options to summarize values are: SUM: the total value of numeric responses (What is the total years of schooling for readers?) COUNT: frequency of numeric responses (How many readers listed 20 years of schooling?) COUNTA: frequency of text responses (How many readers listed occupation as “educator”) Although Google Sheets pivot tables display raw numbers by default, under the Show as drop-down menu you can choose to display them as percentages of the row, of the column, or of the grand total. Figure 2.34: In the Pivot table editor, see multiple options to summarize Values. While designing pivot tables may look differently across other spreadsheet tools, the concept is the same. Learn more about how pivot tables work in the support pages for Google Sheets or LibreOffice or Microsoft Excel. Remember that you can download the Google Sheets data and export to ODS or Excel format to experiment with pivot tables in other tools. Now that you’ve learned how to regroup and summarize data with pivot tables, in the next section you’ll learn a related method to connect matching data columns across different spreadsheets using VLOOKUP. "],
["vlookup.html", "Match Columns with VLOOKUP", " Match Columns with VLOOKUP Spreadsheet tools also allow you to “look up” data in one sheet and automatically find and paste matching data from another sheet. This section introduces the VLOOKUP function, where the “V” stands for “vertical,” meaning matches across columns, which is the most common way to look up data. You’ll learn how to write a function in one sheet that looks for matching cells in select columns in a second sheet, and pastes the relevant data into a new column in the first sheet. If you’ve ever faced the tedious task of manually looking up and matching data between two different spreadsheets, this automated method will save you lots of time. Here’s a scenario that illustrates why and how to use the VLOOKUP function. Figure 2.35 shows two different sheets with sample data about food banks that help feed hungry people in different parts of the US, drawn from Feeding America: Find Your Local Food Bank. The first sheet lists individual people at each food bank, the second sheet lists the address for each food bank, and the two share a common column named organization. Your goal is to produce one sheet that serves as a mailing list, where each row contains one individual’s name, organization, and full mailing address. Since we’re using a small data sample to simplify this tutorial, it may be tempting to manually copy and paste in the data. But imagine an actual case that includes over 200 US food banks and many more individuals, where using an automated method to match and paste data is essential. Figure 2.35: Your goal is to create one mailing list that matches individual names and organizations on the left sheet with their addresses on the right sheet. Open this Google Sheet of Food Bank sample names and addresses in a new browser tab. Log into your Google Drive, and go to File &gt; Make a Copy to create your own version that you can edit. We simplified this two-sheet problem by placing both tables in the same Google Sheet. Click on the first tab, called names, and the second tab, called addresses. In the future, if you need to move two separate Google Sheets into the same file, go to the tab of one sheet, right-click the tab to Copy to &gt; Existing spreadsheet, and select the name of the other sheet. In your editable copy of the Google Sheet, the names tab will be our destination for the mailing list we will create. Go to the addresses sheet, copy the column headers for street - city - state - zip, and paste them into cells C1 through F1 on the names sheet, as shown in Figure 2.36. This creates new column headers where our lookup results will be automatically pasted. Figure 2.36: Paste the last four column headers from the addresses sheet into the names sheet. In the names sheet, click in cell C2 and type =VLOOKUP, and Google Sheets will suggest that you complete the full formula in this format: VLOOKUP(search_key, range, index, [is_sorted]) Here’s what each part means: search_key = The cell in 1st sheet you wish to match. range = At least two columns in the 2nd sheet to search for your match and desired result. index = The column in the 2nd sheet range that contains your desired result, where 1 = first column, 2 = second column, etc. [is_sorted] = Enter false to find exact matches only, which makes sense in this case. Otherwise, enter true if the first column of the 2nd sheet range is sorted and you will accept the closest match, even if not an exact one. One option is to directly type this formula into cell C2, using comma separators: =VLOOKUP(B2,'addresses'!A:E,2,false). Another option is to click on the VLOOKUP Vertical lookup grey box that Google Sheets suggests, and click on the relevant cells, columns, and sheets for the formula to be automatically entered for you, as shown in Figure 2.37. What’s new here is that this formula in the names sheet refers to a range of columns A to E in the addresses sheet. Press Return or Enter on your keyboard. Figure 2.37: The VLOOKUP formula in cell C2 of the names sheet (top) searches for matches across columns A to E in the addresses sheet (bottom). Let’s break down each part of the formula you entered in cell C2 of the names sheet: B2 = The search_key: the cell in the organization column you wish to match in the names sheet 'addresses'!A:E = The range where you are searching for your match and results across columns A to E in the addresses sheet. 2 = The index, meaning your desired result appears in the 2nd column (street) of the range above. false = Find exact matches only. After you enter the full VLOOKUP formula, it will display the exact match for the first organization, the Central Texas Food Bank, whose address is 6500 Metropolis Dr. Click and hold down on the blue dot in the bottom-right corner of cell C2, and drag your crosshair cursor across columns D to F and let go, which will automatically paste and update the formula for the city, state, and zip columns, as shown in Figure 2.38. Figure 2.38: Click on cell C2, then hold-and-drag the bottom-right blue dot across columns D to F, which automatically pastes and updates the formula. Finally, use the same hold-and-drag method to paste and update the formula downward to fill in all rows, as shown in Figure 2.39. Figure 2.39: Click on cell F2, then hold-and-drag the bottom-right blue dot down to row 11, which automatically pastes and updates the formula. Warning: If you save this spreadsheet in CSV format, your calculated results will appear in the CSV sheet, but any formulas you created to produce those results will disappear. Always keep track of your original spreadsheet to remind yourself how you constructed formulas. You’ve successfully created a mailing list—including each person’s name, organization, and full mailing address—using the VLOOKUP function to match and paste data from two sheets. Now that you understand how to use formulas to connect different spreadsheets, the next section will teach you how to manage multiple relationships between spreadsheets with the help of a relational database. "],
["database.html", "Connect Sheets with a Relational Database", " Connect Sheets with a Relational Database In the previous section, you learned how the VLOOKUP function can search for matching data in columns across spreadsheets and automatically paste results. Building on that concept, let’s distinguish between a spreadsheet and a relational database, and under what circumstances it might be wiser to use the latter. A spreadsheet is sometimes called a “flat-file database” because all of the records are stored in rows and columns in a single table. For example, if you kept a single spreadsheet of US food bank staff, every row would list an individual person, organization, and addresses, just like the mailing list we created in Figure 2.39 in the prior section on VLOOKUP. But keeping all of your data in a single spreadsheet can raise problems. For example, it contains lots of duplicated entries. For people who all work at the same food bank, each row contains a duplicate of that organization’s address. If an organization moves to a new location, you need to update all of the rows that contain those addresses. Or if two organizations merge together under a new name, you need to update all of the rows for individuals affected by that change. While keeping all of your information organized in a single spreadsheet initially sounds like a good idea, when your dataset grows in size and internal relationships (such as tracking people who are connected to organizations, etc.), continually updating every row becomes a lot of extra work. Instead of a single spreadsheet, consider using a relational database, which organizes information into separate sheets (also known as tables), but continually maintains the relevant connections between them. Look back at the two-sheet problem we presented in Figure 2.35 at the beginning of the VLOOKUP section. The first sheet lists individual people at each food bank, the second sheet lists the address for each food bank, and the two sheets share a column named organization that shows how they are related. Relational databases can save you time. For example, if you update an organization’s address in one sheet, the linked sheet will automatically reflect this change in every row for staff who work at that organization. Although Google Sheets is a great spreadsheet, it’s not a relational database. Instead, consider a better tool such as Airtable, which allows you to create relational databases in your web browser with up to 1,200 free records (or more with the paid version), using existing templates or your own designs. Airtable enables data migration by importing or exporting all records in CSV format, and it also supports real-time editor collaboration with co-workers. To demonstrate, we imported both of the Google Sheets above into this live Airtable database called Food Banks sample, which anyone with the link can view, but only we can edit. At the top are tabs to view each sheet, named people and food banks. To transform this into a relational database, we used Airtable settings to link the organization column in the people sheet to the food banks sheet, where the addresses are stored, as shown in Figure 2.40. In our editable version, we double-clicked on the column name, then selected Link to another record in the drop-down menu, to connect it to another tab. Figure 2.40: In this Airtable sample, we linked the organization column in the people sheet to the food banks sheet. In our Airtable sample, click on a linked row to expand it and view related data. For example, if you click and expand on the first row the people sheet, their organization’s full address appears from the food banks sheet, as shown in Figure 2.41. In our editable version, if we update the address for one organization in the food banks sheet, it’s automatically changed for all employees linked to that organization in the people sheet. In addition, Airtable allows you to sort, filter, and create different views of your data that you can share with others, a topic we’ll cover in Chapter 8: Embed on your Web. See more about its features in the Airtable Support page. Figure 2.41: In this Airtable demo, click on a row in one sheet to expand and view its linked data in another sheet. It’s important to understand the conceptual differences between a “flat-file” spreadsheet and a relational database to help you determine when to use one tool versus another. As you’ve learned in the sections above, spreadsheets are your best choice to begin organizing and analyzing your data, using methods such as sorting, filtering, pivoting, and lookup, to help reveal the underlying stories that you may wish to visualize. But relational databases are your best choice when maintaining large amounts of data with internal links, like one-to-many relationships, such as an organization with several employees. Summary If you’re one of the many people who “never really learned” about spreadsheets in school or on the job, or if you’ve taught yourself bits and pieces along the way, we hope that this chapter has successfully strengthened your skills. All of the subsequent chapters in this book, especially those on designing interactive charts in Chapter 5 and interactive maps in Chapter 6, require a basic level of familiarity with spreadsheets. In addition to serving as incredible time-savers when it comes to tedious data tasks, the spreadsheet tools and methods featured above are designed to help you share, sort, calculate, pivot, and lookup matching data, with the broader goal of visualizing your data stories. The next chapter describes strategies for finding and questioning your data, particularly on open data sites operated by governmental and non-profit organizations, where you’ll also need spreadsheet skills to download and organize public information. "],
["find.html", "Chapter 3 Find and Question Your Data", " Chapter 3 Find and Question Your Data In the early stages of a visualization project, we often start with two interrelated issues: Where can I find reliable data?, and after you find something, What does this data truly represent? If you leap too quickly into constructing charts and maps without thinking deeply about these dual issues, you run the risk of creating meaningless, or perhaps worse, misleading visualizations. This chapter breaks down both of these broad issues by providing concrete strategies to guide your search, understand debates about public and private data, navigate a growing number of open data repositories, source your data origins, and recognize bad data. Finally, once you’ve found some files, we propose some ways to question and acknowledge the limitations of your data. Information does not magically appear out of thin air. Instead, people collect and publish data, with explicit or implicit purposes, within the social contexts and power structures of their times. As data visualization advocates, we strongly favor evidence-based reasoning over less-informed alternatives. But we caution against embracing so-called data objectivity, since numbers and other forms of data are not neutral. Therefore, when working with data, pause to inquire more deeply about Whose stories are told? and Whose perspectives remain unspoken? Only by asking these types of questions, according to Data Feminism authors Catherine D’Ignazio and Lauren Klein, will we “start to see how privilege is baked into our data practices and our data products.”1 Catherine D’Ignazio and Lauren F. Klein, Data Feminism (MIT Press, 2020), https://data-feminism.mitpress.mit.edu/.↩︎ "],
["guiding.html", "Guiding Questions for your Data Search", " Guiding Questions for your Data Search For many people, a data search is simply “Googling” some keywords on the web. Sometimes that works, sometimes not. When that approach flounders, we reflect on the many lessons we’ve learned about data-hunting while working alongside talented librarians, journalists, and researchers. Collectively, they taught us a set of guiding questions that outline a more thoughtful process about how to search for data: What exactly is the question you’re seeking to answer with data? Literally write it down—in the form of a question, punctuated with a question mark at the end—to clarify your own thinking, and also so that you can clearly communicate it to others who can assist you. All too often, our brains automatically leap ahead to try to identify the answer, without reflecting on the best way frame the question in a way that does not limit the range of possible outcomes. Look back at data visualization projects that made a lasting impression on you to identify the underlying question that motivated them. In their coverage of the US opioid epidemic, the Washington Post and the West Virginia Charleston Gazette-Mail successfully fought a legal battle to obtain a US Drug Enforcement Agency database that the federal government and the drug industry sought to keep secret. In 2019, a team of data journalists published the database with interactive maps to answer one of their central questions: How many prescription opioid pills were sent to each US county, per capita, and which companies and distributors were responsible? Their maps revealed high clusters in several rural Appalachian counties that received over 150 opioid pills per resident, on average, each year from 2006 to 2014. Moreover, only six companies distributed over three-quarters of the 100 billion oxycodone and hydrocodone pills across the US during this period: McKesson Corp., Walgreens, Cardinal Health, AmerisourceBergen, CVS and Walmart. Even if you’re not working with data as large or as controversial as this one, the broader lesson is to clearly identify the question you’re seeking to answer. Also, it’s perfectly normal to revise your question as your research evolves. For example, we once began a data project by naively asking What were Connecticut public school test scores in the 1960s? Soon we discovered that standardized state-level school testing as we know it today did not appear in states like Connecticut until the mid-1980s school accountability movement. Even then, results were not widely visible to the public until newspapers began to publish them once a year in print in the 1990s. Later, real estate firms, school-ratings companies, and government agencies began to publish data continuously on the web as the Internet expanded in the late 1990s and early 2000s. Based on what we learned, we revised our research question to When and how did Connecticut homebuyers start to become aware of school test scores, and how did these influence the prices they were willing to pay for access to selected public school attendance areas?2 Be prepared to refine your question when the evidence leads you in a better direction. What types of organizations may have collected or published the data you seek? If a governmental organization may have been involved, then at what level: local, regional, state/provincial, national, or international? Which branch of government: executive, legislative, judicial? Or which particular governmental agency might have been responsible for compiling or distributing this information? Since all of these different structures can be overwhelming, reach out to librarians who are trained to work with government documents and databases, often at state government libraries, or at local institutions participating in the US Federal Depository Library Program. Or might the data you seek have been compiled by a non-governmental organization, such as academic institutions, journalists, non-profit groups, or for-profit corporations? Figuring out which organizations might have collected and published the data can help point you to the digital or print materials they typically publish, and most appropriate tools to focus your search in that particular area. What level(s) of data are available? Is information disaggregated by individual cases or aggregated into larger groups? Librarians can help us to decipher how and why different organizations publish data in different formats. For example, US Census seeks to collect data every ten years about each person residing in the nation, but under the law, this individual-level data is confidential and not released to the public for 72 years. You can look up individual census data for 1940 and earlier decades at the US National Archives and other websites. But the US Census publishes current data for larger areas, such as neighborhood-level block groups, census tracts, cities, and states, by aggregating individual records into data tables, and suppressing small-numbered cells to protect people’s privacy. Librarians can help us understand organization’s guidelines on when and how they make data available at different levels Have prior publications drawn on similar data, and if so, how can we trace their sources? Some of our best ideas began when reading an article or book that described its source of evidence, and we imagined new ways to visualize that data. Several times we have stumbled across a data table in a print publication, or perhaps an old web page, which sparked our interest in tracking down a newer version to explore. Even outdated data helps by demonstrating how someone or some organization collected it at one point in time. Follow the footnotes to track down its origins. Use Google Scholar and more specialized research databases (ask librarians for assistance if needed) to track down the source of previously-published data. One bonus is that if you can locate more current data, you may be able to design a visualization that compares change over time. What if no one has collected the data you’re looking for? Sometimes this happens due to more than a simple oversight. In Data Feminism, Catherine D’Ignazio and Lauren Klein underscore how issues of data collection “are directly connected to larger issues of power and privilege” by recounting a story about tennis star Serena Williams. When Williams experienced life-threatening complications while giving birth to her daughter in 2017, she called public attention to the way that she, a Black woman, needed to advocate for herself in the hospital. After her experience, she wrote on social media that “Black women are over 3 times more likely than white women to die from pregnancy- or childbirth-related causes,” citing the US Centers for Disease Control and Prevention (CDC). When journalists followed up to investigate further, they discovered the absence of detailed data on maternal mortality, and what a 2014 United Nations report described as a “particularly weak” aspect of data collection in the US healthcare system. Journalists reported that “there was still no national system for tracking complications sustained in pregnancy and childbirth,” despite comparable systems for other health issues such as heart attacks or hip replacements. Power structures are designed to count people whose lives either are highly valued, or under a high degree of surveillance. D’Ignazio and Klein call on us critically examine these power systems, collect data to counter their effects, and make everyone’s labor in this process more visible.3 If no one has collected the data you’re looking for, perhaps you can make valuable steps to publicly recognize the issue and contribute to positive change. Hunting for data involves much more than Googling keywords. Deepen your search by reflecting on the types of questions that librarians, journalists, and other researchers have taught us to ask: What types of organizations might—or might not—have collected the data? At what levels? At any prior point in time? And under what social and political contexts? In the next section, you’ll learn more about related issues to consider over public and private data. Jack Dougherty et al., “School Choice in Suburbia: Test Scores, Race, and Housing Markets,” American Journal of Education 115, no. 4 (August 2009): 523–48, http://digitalrepository.trincoll.edu/cssp_papers/1.↩︎ D’Ignazio and Klein, Data Feminism, chap. 1.↩︎ "],
["public.html", "Public and Private Data", " Public and Private Data When searching for data, you also need to be informed about debates regarding public and private data. Not only do these debates influence the kinds of data you might be able to legally use in your visualizations, but they also raise deeper ethical issues about the extent to which anyone should be able to collect or circulate private information about individuals. This section offers our general observations on these debates, based primarily on our context in the United States. Since we are not lawyers (thank goodness!), please consult with legal experts for advice about your specific case if needed. The first debate asks: To what extent should anyone be allowed to collect data about private individuals? Several critics of “big data” worry that governments are becoming more like a totalitarian “Big Brother” as they collect more data about individual citizens in the digital age. In the United States, concerns mounted in 2013 when whistleblower Eric Snowden disclosed how the National Security Agency conducted global surveillance using US citizen email and phone records provided by telecommunications companies. Shoshana Zuboff, a Harvard Business School professor and author of The Age of Surveillance Capitalism, warns of an equal threat posed by corporations that collect and commodify massive amounts of individually-identifiable data for profit.4 Due to the rise of digital commerce, powerful technology companies own data that you and others consider to be private: Google knows what words you typed into their search engine, as shown in aggregated form in Google Trends. Also, Google’s Chrome browser tracks your web activity through cookies, as described by technology reporter Geoffrey Fowler. Amazon eavesdrops and records your conversations around its Alexa home assistants, as Fowler describes. Facebook follows which friends and political causes you favor, but also tracks your off-Facebook activity, such as purchases made at other businesses, to improve its targeted advertising. Some point out that “big data” collected by large corporations can offer public benefits. For example, Apple shared its aggregated mobility data collected from iPhone users to help public health officials compare which populations stayed home rather than travel during the Covid pandemic. But others point out that corporations are largely setting their own terms for how they collect data and what they can do with it. Although California has begun to implement its Consumer Privacy Act in 2020, which promises to allow individuals the right to review and delete the data that companies collect about them, US state and federal government has not fully entered this policy arena. If you work with data that was collected from individuals by public or private organizations, learn about these controversies to help you make wise and ethical choices on what to include in your visualizations. The second question is: When our government collects data, to what extent should it be publicly available? In the United States, the 1966 Freedom of Information Act and its subsequent amendments have sought to open access to information in the federal government, with the view that increased transparency would promote public scrutiny and pressure on officials to make positive changes. In addition, state governments operate under their own freedom of information laws, sometimes called “open records” or “sunshine laws.” When people say they’ve submitted a “FOIA,” it means they’ve sent a written request to a government agency for information that they believe should be public under the law. But federal and state FOIA laws are complex, and courts have interpreted cases in different ways over time, as summarized in the Open Government Guide by the Reporters Committee for Freedom of the Press, and also by the National Freedom of Information Coalition. Sometimes government agencies quickly agree and comply with a FOIA request, while other times they may delay or reject it, which may pressure the requester to attempt to resolve the issue through time-consuming litigation. Around the world, over 100 nations have their own version of freedom of information laws, with the oldest being Sweden’s 1766 Freedom of the Press Act, but these laws vary widely. In most cases, individual-level data collected by US federal and state governments is considered private, except in cases where our governmental process has determined that a broader interest is served by making it public. To illustrate this distinction, let’s begin with two cases where US federal law protects the privacy of individual-level data: Patient-level health data is generally protected under the Privacy Rule of the Health Insurance Portability and Accountability Act, commonly known as HIPAA. In order for public health officials to track broad trends about illness in the population, individual patient data must be aggregated into larger anonymized datasets in ways that protect specific people’s confidentiality. Similarly, student-level education data is generally protected under the Family Educational Rights and Privacy Act, commonly known as FERPA. Public education officials regularly aggregate individual student records into larger anonymized public datasets to track the broad progress of schools, districts, and states, without revealing individually-identifiable data. On the other hand, here are three cases where government has ruled that the public interest is served by making individual-level data widely available: Individual contributions to political candidates are public information in the US Federal Election Commission database, and related databases by non-profit organizations, such as Follow The Money by the National Institute on Money in Politics and Open Secrets by the Center for Responsive Politics. The latter two sites describe more details about donations submitted through political action committees and controversial exceptions to campaign finance laws. Across the US, state-level political contribution laws vary widely, and these public records are stored in separate databases. For example, anyone can search the Connecticut Campaign Reporting Information System to find donations made by the first author to state-level political campaigns. Individual property ownership records are public, and increasingly hosted online by many local governments. A privately-funded company compiled this US public records directory with links to county and municipal property records, where available. For example, anyone can search the property assessment database for the Town of West Hartford, Connecticut to find property owned by the first author, its square footage, and purchase price. Individual salaries for officers of tax-exempt organizations are public, which they are required to file on Internal Revenue Service (IRS) 990 forms each year. For example, anyone can search 990 forms on ProPublica’s Nonprofit Explorer, and view the salary and other compensation of the top officers of the first author’s employer, Trinity College in Hartford, Connecticut. Social and political pressures are continually changing the boundary over what types of individual-level data collected by government should be made publicly available. For example, the Black Lives Matter movement has gradually made more individual-level data about violence by police officers more widely available. For example, in 2001 the State of New Jersey required local police departments to document any “use of force” by officers, whether minor or major, such as firing their gun. But no one could easily search these paper forms until a team of journalists from NJ Advance Media submitted over 500 public records requests and compiled The Force Report digital database, where anyone can look up individual officers and investigate patterns of violent behavior. Similarly, a team of ProPublica journalists created The NYPD Files database, which now allows anyone to search closed cases of civilian complaints against New York City police officers, by name or precinct, for patterns of substantiated allegations. If you work with data, get informed about key debates over what should be public or private, become active in policy discussions about whose interests are being served, and contribute to making positive change. Even if sensitive individual-level data is legally accessible, each of us are responsible for making ethical decisions about if and how to use it in our data visualizations. In the next section, you’ll learn how to explore datasets that governments and non-governmental organizations have intentionally shared with the public. Shoshana Zuboff, The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power (PublicAffairs, 2019), https://www.google.com/books/edition/The_Age_of_Surveillance_Capitalism/lRqrDQAAQBAJ.↩︎ "],
["opendata.html", "Open Data Repositories", " Open Data Repositories Over the past decade, an increasing number of governmental and non-governmental organizations around the globe have begun to pro-actively share public data through open data repositories. While some of these datasets were previously available as individual files on isolated websites, these growing networks have made open data easier to find, enabled more frequent agency updates, and sometimes support live interaction with other computers. Open data repositories often include these features: View and Export: At minimum, open data repositories allow users to view and export data in common spreadsheet formats, such as CSV, ODS, and XLSX. Some repositories also provide geographical boundary files for creating maps. Built-in Visualization Tools: Several repositories offer built-in tools for users to create interactive charts or maps on the platform site. Some also provide code snippets for users to embed these built-in visualizations into their own websites, which you’ll learn more about in Chapter 8: Embed on Your Web. Application Program Interface (APIs): Some repositories provide endpoints with code instructions that allow other computers to pull data directly from the platform into an external site or online visualization. When repositories continuously update data and publish an API endpoint, it can be an ideal way to display live or “almost live” data in your visualization, which you’ll learn more about in Chapter 11: Leaflet Map Templates. Due to the recent growth of open data repositories, especially in governmental policy and scientific research, there is no single website that lists all of them. Instead, we list just a few sites from the US and around the globe to spark readers’ curiosity and encourage you to dig deeper: Data.gov, the official repository for US federal government agencies. Data.census.gov, the main platform to access US Census Bureau data. The Decennial Census is a full count of the population every ten years, while the American Community Survey (ACS) is an annual sample count that produces one-year, three-year, or five-year estimates for different census geographies, with margins of error. Eurostat, the statistical office of the European Union. Federal Reserve Economic Research, for US and international data. Global Open Data Index, by the Open Knowledge Foundation. Google Public Data. Google Dataset Search. IPUMS, Integrated Public Use Microdata Series, the world’s largest individual-level population database, with microdata samples from US and international census records and surveys, hosted by the University of Minnesota. openAfrica, by Code for Africa. Open Data Inception, a map-oriented global directory. Open Data Network, a directory by Socrata, primarily of US state and municipal open data platforms. United Nations data. World Bank Open Data, a global collection of economic development data. For more options, see Open Data listings that have been organized and maintained by staff at several libraries, including the University of Rochester, SUNY Geneseo, Brown University, and many others. In addition, better-resourced higher-education libraries and other organizations may pay subscription fees that allow their students and staff to access “closed” data repositories. For example, Social Explorer offers decades of demographic, economic, health, education, religion, and crime data for local and national geographies, primarily for the US, Canada, and Europe. Previously, Social Explorer made many files available to the public, but it now requires a paid subscription or 14-day free trial. Also, Policy Map provides demographic, economic, housing, and quality of life data for US areas, and makes some publicly visible in its Open Map view, but you need a subscription to download them. Now that you’ve learned more about navigating open data repositories, the next section will teach you ways to properly source the data that you discover. "],
["source.html", "Source Your Data", " Source Your Data When you find data, write the source information inside the downloaded file or a new file you create. Add key details about its origins, so that you—or someone else in the future—can replicate your steps. We recommend doing this in two places: the spreadsheet file name and a source notes tab. As a third step, make a backup sheet of your data. The first step is to label every data file that you download or create. All of us have experienced “bad file names” like these, which you should avoid: data.csv file.ods download.xlsx Write a short but meaningful file name. While there’s no perfect system, a good strategy is to abbreviate the source (such as census or worldbank or eurostat), add topic keywords, and a date or range. If you or co-workers will be working on different versions of a downloaded file, include the current date in YYYY-MM-DD (year-month-date) format. If you plan to upload files to the web, type names in all lower-case and replace blank spaces with dashes (-) or underscores (_). Better file names look like this: town-demographics-2019-12-02.csv census2010_population_by_county.ods eurostat-1999-2019-co2-emissions.xlsx The second step is to save more detailed source notes about the data on a separate tab inside the spreadsheet, which works for multi-tab spreadsheet tools such as Google Sheets, LibreOffice, and Excel. Add a new tab named notes that describes the origins of the data, a longer description for any abbreviated labels, and when it was last updated, as shown in Figure 3.1. Add your own name and give credit to collaborators who worked with you. If you need to create a CSV file from this data, give it a parallel name to your multi-tabbed spreadsheet file so that you can easily find your original source notes again in the future. Figure 3.1: Create separate spreadsheet tabs for data, notes, and backup. A third step is to make a backup of the original data before cleaning or editing it. For a simple one-sheet file in a multi-tab spreadsheet tool, right-click on the tab containing the data to make a duplicate copy in another tab, also shown in Figure 3.1. Clearly label the new tab as a backup and leave it alone! For CSV files or more complex spreadsheets, create a separate backup file. To be clear, these simple backup strategy only helps you from making non-fixable edits to your original data. Make sure you have a broader strategy to backup your files from your computer or cloud account in case either of those are deleted or those systems crash. Make a habit of using these three sourcing strategies—filenames, notes, and backups—to increase the credibility and replicability of your data visualizations. In the next section, we’ll explore more ways to reduce your chances of making “bad data” errors. "],
["bad.html", "Recognize Bad Data", " Recognize Bad Data When your data search produces some results, another key step is to open the file, quickly scroll through the content, and look for any warning signs that it might contain “bad data.” If you fail to catch a problem in your data at an early stage, it could lead to false conclusions and diminish the credibility of all of your work. Fortunately, members of the data visualization community have shared multiple examples of problems we’ve previously encountered, to help save newer members from making the same embarrassing mistakes. One popular crowd-sourced compilation by data journalists was The Quartz Guide to Bad Data, last updated in 2018. Watch out for spreadsheets containing these “bad data” warning signs: Missing values: If you see blank or “null” entries, does that mean data was not collected? Or maybe a respondent did not answer? If you’re unsure, find out from the data creator. Also beware when humans enter a 0 or -1 to represent a missing value, without thinking about its consequences on running spreadsheet calculations, such as SUM or AVERAGE. Missing leading zeros: One of the zip codes for Hartford, Connecticut is 06119. If someone converts a column of zip codes to numerical data, it will strip out the leading zero and appear as 6119. Similarly, the US Census Bureau lists every place using a FIPS code, and some of these also begin with a meaningful zero character. For example, the FIPS code for Los Angeles County, California is 037, but if someone accidentally converts a column of text to numbers, it will strip out the leading zero and convert that FIPS code to 37, which represents the state of North Carolina. 65536 rows or 255 columns: These are the maximum number of rows supported by older-style Excel spreadsheets, or columns supported by Apple Numbers spreadsheet, respectively. If your spreadsheet stops exactly at either of these limits, you probably have only partial data. Inconsistent date formats: For example, November 3rd, 2020 is commonly entered in spreadsheets in the US as 11/3/2020 (month-date-year), while people in other locations around the globe commonly type it as 3/11/2020 (date-month-year). Check your source. Dates such as January 1st 1900, 1904, or 1970: These are default timestamps in Excel spreadsheets and Unix operating systems, which may indicate the actual date was blank or overwritten. Dates similar to 43891: When you type March 1 during the year 2020 into Microsoft Excel, it automatically displays as 1-Mar, but is saved using Excel’s internal date system as 43891. If someone converts this column from date to text format, you’ll see Excel’s 5-digit number, not the dates you’re expecting. Another way to review the quality of data entry in any column in a spreadsheet is to create a filter or a pivot table as described in chapter 2. This allows you to quickly inspect the range of values that appear in that column, and whether they match what you expected to find. What should you do when you discover bad data in your project? Sometimes small issues are relatively straightforward and do not call into question the integrity of the entire dataset. Sometimes you can fix these using methods we describe in Chapter 4: Clean Up Messy Data. But larger issues can be more problematic. Follow the source of your data stream to try to identify where the issue began. If you cannot find and fix the issue on your own, contact the data provider to ask for their input, since they should have a strong interest in improving the quality of the data. If they cannot resolve an important data issue, then you need to pause and think carefully. In this case, is it wiser to continue working with problematic data and add a cautionary note to readers, or should you stop using the dataset entirely and call attention to its underlying problem? These are not easy decisions, and you should ask for opinions from colleagues. In any case, never ignore the warning signs of bad data. Finally, you can help to prevent bad data from occurring by following key steps we’ve outlined above. Give meaningful names to your data files, and add source notes in a separate tab about when and where you obtained it, along with any definitions or details about what it claims to measure and how it was recorded. Explain what any blanks or null values mean, and avoid replacing those with zeroes or other symbols. Always watch out for formatting issues when entering data or running calculations in spreadsheets. In the next section, you’ll learn more questions to help you understand your data at a deeper level. "],
["question.html", "Question Your Data", " Question Your Data Now that you’ve found, sourced, and inspected some files, the next step to question your data by looking more deeply than what appears at its surface level. Read the source notes and examine the contents to reflect on what is explicitly stated—or unstated—to better understand its origin, context, and limitations. You cannot program a computer to do this step for you, as it requires critical-thinking skills to see beyond the characters and numbers appearing on your screen. One place to start is to ask: What do the data labels really mean? and to consider these potential issues: Abbreviated column headers, such as Elevation or Income, often appear in spreadsheets. Sometimes the original software limited the number of characters that could be entered, or the people who created the header names preferred to keep them short. But was Elevation entered in meters or feet? An abbreviated data label does not answer that key question, so you’ll need to check the source notes, or if that’s not available, compare elevation data for a specific point in the dataset to a known source that includes the measurement unit. Similarly, if you’re working with US Census data, does the Income abbreviation refer to per person, per family, or per household? Also, does the value reflect the median (the mid-point in a range of numbers) or the mean (the average, calculated by adding up the sum and dividing by the number of values). Check definitions in the source notes. How exactly was the data recorded? For example, was Elevation for a specific location measured by a GPS unit on the ground? Or was the location geocoded on a digital map that contains elevation data? In most cases the two methods will yield different results, and whether that matters depends on the degree of precision required in your work. Similarly, when the US Census reports data from its annual American Community Survey (ACS) estimates for Income and other variables, these are drawn from small samples of respondents for lower levels of geography, such as a census tract with roughly 4,000 residents, which can generate very high margins of error. For example, it’s not uncommon to see ACS estimates for a census tract with a mean family income of $50,000—but also with a $25,000 margin of error—which tells you that the actual value is somewhere between $25,000 and $75,000. As a result, some ACS estimates for small geographic units are effectively meaningless. Check how data was recorded, and any reported margins of error, in the source notes. To what extent is the data socially constructed? In other words, what do the data labels reveal or hide about how people defined categories in different social and political contexts, which differ across place and time? For example, we designed an interactive historical map of racial change for Hartford County, Connecticut using over 100 years of US Census data. But Census categories for race and ethnicity changed dramatically during those decades because people in power redefined these contested terms and moved who belonged in which group. For example, through the 1930s, the US Census separated “Native White” and “Foreign-born White” in its official reports, then combined and generally reported these as “White” in later decades. Also, the Census classified “Mexican” as “Other races” in 1930, then moved this group back to “White” in 1940, then began to report “Puerto Rican or Spanish surname” data in 1960, followed by “Hispanic or Latino” in later decades, as an ethnic category that was distinct from race. The Census finally replaced “Negro” with “Black” in 1980, and in 2000 allow people to select more than one racial category, such as both “White” and “Black,” unlike prior decades when these terms were mutually exclusive and people could choose only one. As a result, historical changes in the social construction of race and ethnicity influenced how we designed our map to display “White” or “White alone” over time, with additional census categories relevant to each decade shown in the pop-up window, with our explanation of our decisions in the caption and source notes. There is no single definitive way to visualize socially-constructed data when definitions change across decades. But when you make choices about data, describe your thought process in the notes. Here’s a paradox about working with data: some of these deep questions may not be fully answerable if the data was collected by someone other than yourself, especially if that person came from a distant place, or time period, or a different position in a social hierarchy. But even if you cannot fully answer these questions, don’t let that stop you from asking good questions about the origins, context, and underlying meaning of your data. Only by clarifying what we know—and what we don’t know—can we begin to recognize the limitations of the data. When you create visualizations, your job is also to acknowledge the limitations of the data by making thoughtful decisions about its design, and how you describe what it does—and does not—tell us. We’ll return to these topics when discussing chart design in Chapter 5 and telling your data story in chapter 14. Summary This chapter reviewed two broad questions that everyone should ask during the early stages of their visualization project: Where can I find data? and What do I really know about it? We broke down both questions into more specific parts to develop your knowledge and skills in guiding questions for your search, engaging with debates over public and private data, navigating open data repositories, sourcing data origins, recognizing bad data, and questioning your data more deeply than its surface level. Remember these lessons as you leap into the next few chapters on cleaning data and creating interactive charts and maps. "],
["clean.html", "Chapter 4 Clean Up Messy Data", " Chapter 4 Clean Up Messy Data More often than not, datasets will be messy and hard to visualize right away. They will have missing values, dates in different formats, text in numeric-only columns, multiple items in the same columns, various spellings of the same name, and other unexpected things. See Figure 4.1 for inspiration. Don’t be surprised if you find yourself spending more time cleaning up data than you do analyzing and visualizing it. Figure 4.1: More often than not, raw data looks messy. In this chapter you’ll learn about different tools, in order to help you make decisions about which one to use to clean up your data efficiently. First, we’ll start with basic cleanup methods using spreadsheets, such as find and replace with a blank, split data into separate columns, and combine columns into one. While we feature Google Sheets in our examples, the same principles (and in most cases the same formulas) can be use in Microsoft Excel, LibreOffice Calc, Mac’s Numbers, or other spreadsheet packages. Next, you will learn how to extract table data from text-based PDF documents using a free tool, Tabula, used by data journalists and researchers worldwide to analyze spending data, health reports, and all sorts of other datasets that get trapped in PDFs. Finally, we will introduce OpenRefine, an extremely powerful and versatile tool to clean up the messiest spreadsheets, such as those containing dozens of different spellings of the same name. "],
["find-and-replace.html", "Find and Replace with Blank", " Find and Replace with Blank One of the simplest and most powerful cleanup tools inside your spreadsheet is the Find and Replace command. You can also use it to bulk-change different spellings of the same name, such as shortening a country’s name (from Republic of India to India), or expanding a name (from US to United States), or translating names (from Italy to Italia). Also, you can use find and replace with a blank entry to remove units of measurement that sometimes reside in the same cells as the numbers (such as changing 321 kg to 321). Let’s look at Find and Replace in practice. A common problem with US Census data is that geographic names contain unnecessary words. For example, when you download data on the population of Connecticut towns, the location column will contain the word “town” after every name: Hartford town New Haven town Stamford town But usually you want a clean list of towns, either to display in a chart or to merge with another dataset, like this: Hartford New Haven Stamford Let’s use Find and Replace on a sample US Census file we downloaded with 169 Connecticut town names and their populations, to remove the unwanted “town” label after each place name. Open the CT Town Geonames file in Google Sheets, sign in with your account, and go to File &gt; Make a Copy to create a version you can edit in your Google Drive. Select the column you want to modify by clicking its header. If you don’t select a column, you will be searching and replacing in the entire spreadsheet. In the Edit menu, choose Find and replace. You will see the window like is shown in Figure 4.2. In the Find field, type town, and be sure to insert a blank space before the word. If you do not insert a space, you will accidentally remove town from places such as Newtown. Also, you’ll accidentally create trailing spaces, or whitespace at the end of a line without any other characters following it, which can cause troubles in the future. Leave the Replace with field blank. Do not insert a space. Just leave it empty. The Search field should be set to the range you selected in step 2, or All sheets if you didn’t select anything. You have the option to match case. If checked, town and Town and tOwN will be treated differently. For our purpose, you can leave match case unchecked. Press the Replace all button. Since this sample file contains 169 towns, the window will state that 169 instances of “town” have been replaced. Inspect the resulting sheet. Make sure that places that include town in their name, such as Newtown, remained untouched. Figure 4.2: Find and Replace window in Google Sheets. "],
["split-data.html", "Split Data into Separate Columns", " Split Data into Separate Columns Sometimes multiple pieces of data appear in a single cell, such as first and last names (John Doe), geographic coordinates (40.12,-72.12), or addresses (300 Summit St, Hartford, CT, 06106). For your analysis, you might want to split them into separate entities, so that your FullName column (with John Doe in it) becomes FirstName (John) and LastName (Doe) columns, coordinates become Latitude and Longitude columns, and your FullAddress column becomes 4 columns, Street, City, State, and Zip (postcode). Example 1: Simple Splitting Let’s begin with a simple example of splitting pairs of geographic coordinates, separated by commas, into separate columns. Open the Split Coordinate Pairs sample data in Google Sheets, sign in with your account, and go to File &gt; Make a Copy to create a version you can edit in your Google Drive. Select the data you wish to split, either the full column or just several rows. Note that you can only split data from one column at a time. Make sure there is no data in the column to the right of the one you’re splitting, because all data there will be written over. Go to Data and select Split text to columns, as in Figure 4.3. Google Sheets will automatically try to guess your separator. You will see that your coordinates are now split with the comma, and the Separator is set to Detect automatically in the dropdown. You can manually change it to a comma (,), a semicolon (;), a period (.), a space character, or any other custom character (or even a sequence of characters, which we’ll discuss in Example 2 of this section). You can rename the new columns into Longitude (first number) and Latitude (second number). Figure 4.3: Select Data - Split text to columns to automatically separate data. Example 2: Complex Splitting Now, let’s look at a slightly more complicated example. Each cell contains a full address, which you want to split into four columns: street, city, state, and zipcode (postcode). But notice how the separators differ: a comma between street and city, a space between city and state, and two dashes between state and the zipcode. In this case, you’ll need to manually add some instructions to properly split the text into four columns. | Location | | --------------------------------- | | 300 Summit St, Hartford CT--06106 | | 1012 Broad St, Hartford CT--06106 | | 37 Alden St, Hartford CT--06114 | Open the Split Complex Address sample file in Google Sheets, sign in to your account, and go to File &gt; Make a Copy to save a version in your Google Drive that you can edit. Select the column and go to Data &gt; Split text to columns to start splitting from left to right. Google Sheets will automatically split your cell into two parts, 300 Summit St and Hartford CT--06106, using comma as a separator. (If it didn’t, just select Comma from the dropdown menu that appeared). Now select only the second column and perform Split text to columns again. Google Sheets will automatically separate the city from the state and zip code, because it automatically chose a space as the separator. (If it did not, choose Space from the dropdown menu). Finally, select only the third column and perform Split text to columns again. Google Sheets won’t recognize the two dashes as a separator, so you need to manually select Custom, type those two dashes (--) in the Custom separator field, as shown in Figure 4.4, and press Enter. Now you have successfully split the full address into four columns. Figure 4.4: To split the last column, select a Custom separator and manually type in two dashes. Tip: Google Sheets will treat zip codes as numbers and will delete leading zeros (so 06106 will become 6106). To fix that, select the column, and go to Format &gt; Number &gt; Plain text. Now you can manually re-add zeros. If your dataset is large, consider adding zeros using the formula introduced in the following section. "],
["combine-data.html", "Combine Data into One Column", " Combine Data into One Column Let’s perform the reverse action by combining data into one column with a spreadsheet formula, also called concatenation, using the ampersand symbol (&amp;). Imagine you receive address data in four separate columns: street address, city, state, and zip code. | Street | City | State | Zip | | ------------- | ---------- | ------ | ----- | | 300 Summit St | Hartford | CT | 06106 | But imagine you need to geocode the addresses using a tool like the one we introduced in chapter 2, which requires all of the data to be combined into one column like this: | Location | | --------------------------------- | | 300 Summit St, Hartford, CT 06106 | Using any spreadsheet, you can write a simple formula to combine (or concatenate) terms using the ampersand (&amp;) symbol. Also, you can add separators into your formula, such as quoted space (\" \"), or spaces with commas (\", \"), or any combination of characters. Let’s try it with some sample data. Open the Combine Separate Columns sample data in Google Sheets, sign in with your account, and go to File &gt; Make a Copy to create a version you can edit in your Google Drive. The sheet contains addresses that are separated into four columns: street, city, state, and zip. In column E, type a new header named location. In cell E2, type in the following formula, which combines the four items using ampersands, and separates them with quoted commas and spaces, as shown in Figure 4.5, and press Enter. =A2 &amp; \", \" &amp; B2 &amp; \", \" &amp; C2 &amp; \" \" &amp; D2 Click cell E2 and drag the bottom-right corner cross-hair downward to fill in the rest of the column. Figure 4.5: Use ampersands to combine items, and insert quoted spaces with commas as separators. Now that you have successfully combined the terms into one location column, you can use the Geocoding by SmartMonkey Google Sheets Add-on we described in chapter 2 to find the latitude and longitude coordinates, in order to map your data as we’ll discuss in chapter 6 Note: Lisa Charlotte Rost from Datawrapper has written a brilliant blog post about cleaning and preparing your spreadsheet data for analysis and visualization, which we recommend for further reading.5 Spreadsheets are great tools to find and replace data, split data into separate columns, or combine data into one column. But what if your data table is trapped inside a PDF? In the next section, we will introduce Tabula and show you how to convert tables from text-based PDF documents into tables that you can analyze in spreadsheets. Lisa Charlotte Rost, “How to Prepare Your Data for Analysis and Charting in Excel &amp; Google Sheets,” Chartable: A Blog by Datawrapper, accessed August 28, 2020, https://blog.datawrapper.de/prepare-and-clean-up-data-for-data-visualization/index.html↩︎ "],
["tabula.html", "Extract Tables from PDFs with Tabula", " Extract Tables from PDFs with Tabula It sometimes happens that the dataset you are interested in is only available as a PDF document. Don’t despair, you can likely use Tabula to extract tables and save them as CSV files. Keep in mind that PDFs generally come in two flavors: text-based and image-based. If you can use cursor to select and copy-paste text in your PDF, then it’s text-based, which is great because you can process it with Tabula. But if you cannot select and copy-paste items inside a PDF, then it’s image-based, meaning it was probably created as a scanned version of the original document. You need to use optical character recognition (OCR) software, such as Adobe Acrobat Pro or another OCR tool, to convert an image-based PDF into a text-based PDF. Furthermore, Tabula can only extract data from tables, not charts or other types of visualizations. Tabula is a free tool that runs on Java in your browser, and is available for Mac, Windows, and Linux computers. It runs on your local machine and does not send your data to the cloud, so you can also use it for sensitive documents. To get started, download the newest version of Tabula. You can use download buttons on the left-hand side, or scroll down to the Download &amp; Install Tabula section to download a copy for your platform. Unlike most other programs, Tabula does not require installation. Just unzip the downloaded archive, and double-click the icon. If you work on a Mac, you may see a warning that states, “Tabula is an app downloaded from the internet. Are you sure you want to open it?” If so, click Open. Or you may have to go to System Preferences &gt; Security &amp; Privacy &gt; General tab, and click the Open Anyway button in the lower half of the window to open the app the first time. When you start up Tabula, the default system browser will open, as shown in Figure 4.6. Tabula runs on your local computer, not the internet. The URL in the browser will be something like http://127.0.0.1:8080/. The first portion is the localhost or hostname for your computer, and 8080 refers to the port number. If you see a different port number, that’s fine, and just means that the initial number is already in use by some other program on your computer. If for any reason you decide to use a different browser, just copy-and-paste the URL. Figure 4.6: Tabula welcome page. Now let’s upload a sample text-based PDF and detect any tables we wish to extract. In the beginning of the Covid-19 pandemic, the Department of Public Health in Connecticut issued data on cases and deaths only in PDF document format. For this demonstration, you can use our sample text-based PDF from May 31, 2020, or provide your own. Select the PDF you want to extract data from by clicking the blue Browse… button. Click Import. Tabula will begin analyzing the file. As soon as Tabula finishes loading the PDF, you will see a PDF viewer with individual pages. The interface is fairly clean, with only four buttons in the header. Click the Autodetect Tables button to let Tabula look for relevant data. The tool highlights each table it detects in red, as shown in Figure 4.7. Figure 4.7: Click Autodetect Tables, which Tabula will highlight in red. Now let’s manually adjust our selected tables and export the data. Click Preview &amp; Export Extracted Data green button to see how Tabula thinks the data should be exported. If the preview tables don’t contain the data you want, try switching between Stream and Lattice extraction methods in the left-hand-side bar. If the tables still don’t look right, or you with to remove some tables that Tabula auto-detected, hit Revise selection button. That will bring you back to the PDF viewer. Now you can Clear All Selections and manually select tables of interest. Use drag-and-drop movements to select tables of interest (or parts of tables). If you want to “copy” selection to some or all pages, you can use Repeat this Selection dropdown, which appears in the lower-right corner of your selections, to propagate changes. This is extremely useful if your PDF consists of many similarly-formatted pages. Once you are happy with the result, you can export it. If you have only one table, we recommend using CSV as export format. If you have more than one table, consider switching export format in the drop-down menu to zip of CSVs.This way each table will be saved as an individual file, rather than all tables inside one CSV file. Once you exported your data, you can find it in the Downloads folder on your computer (or wherever you chose to save it), where it is ready to open with a spreadsheet tool to analyze and visualize. In the following section, we are going to look how to clean up messy datasets with OpenRefine. "],
["open-refine.html", "Clean Data with OpenRefine", " Clean Data with OpenRefine Look at the sample US Foreign Aid dataset shown in Figure 4.8. Can you spot any problems with it? Figure 4.8: Can you spot any problems with this sample data? Notice how the Country column various spellings of North and South Korea. Also note how the FundingAmount column is not standardized. Some amounts use commas to separate thousands, while some uses spaces. Some amounts start with a dollar sign, and some do not. Datasets like this can be an absolute nightmare to analyze. Luckily, OpenRefine provides powerful tools to clean up and standardize data. Note: This data excerpt is from US Overseas Loans and Grants (Greenbook) dataset, which shows US economic and military assistance to various countries. We chose to only include assistance to South Korea and North Korea for the years between 2000 and 2018. We added deliberate misspellings and formatting issues for demonstration purposes, but we did not alter values. Set up OpenRefine Let’s use OpenRefine to clean up this messy data. Download OpenRefine for Windows, Mac, or Linux. Just like Tabula, it runs in your browser and no data leaves your local machine, which is great for confidentiality. If you work on a Mac, the downloaded file will be a .dmg file. You will likely encounter a security message that will prevent OpenRefine from launching because Apple cannot identify the developer. Go to System Preferences &gt; Security and Privacy &gt; General tab, and click the Open Anyway button in the lower half of the window. If prompted with another window, click Open. If you use Windows, unzip the downloaded file. Double-click the .exe file, and OpenRefine should open in your default browser. Once launched, you should see OpenRefine in your browser with 127.0.0.1:3333 address (localhost, port 3333), as shown in Figure 4.9. Figure 4.9: OpenRefine starting page. Load Data and Start a New Project To start cleaning up messy dataset, we need to load it into a new project. OpenRefine lets you upload a dataset from your local machine, or a remote web address (such as a Google Sheet). OpenRefine also can extract data directly from SQL databases, but this is beyond the scope of this book. Download the sample messy data on US Foreign Aid in CSV format to your computer. Under Get data from: This computer, click Browse… and select the CSV file you downloaded above. Click Next. Before you can start cleaning up data, OpenRefine allows you to make sure data is parsed properly. In our case, parsing means the way the data is split into columns. Make sure OpenRefine assigned values to the right columns, or change setting in Parse data as block at the bottom of the page until it starts looking meaningful, like shown in Figure 4.10. Hit Create Project in the upper-right corner. Figure 4.10: OpenRefine parsing options. Now when you’ve successfully read the data into a new project, let’s start the fun part: converting text into numbers, removing unnecessary characters, and fixing the spellings for North and South Koreas. Convert Dollar Amounts from Text to Numbers Once your project is created, you will see the first 10 rows of the dataset. You can change it to 5, 10, 25, or 50 by clicking the appropriate number in the header Each column header has its own menu (callable by clicking the arrow-down button). Left-aligned numbers in a column are likely represented as text (as is the case with FundingAmount column in our example), and they need to be transformed into numeric format. To transform text into numbers, open the column menu, and go to Edit cells &gt; Common transforms &gt; To number. You will see that some numbers became green and right-aligned (success!), but most did not change. That is because dollar sign ($) and commas (,) confuse OpenRefine and prevent values to be converted into numbers. Let’s remove $ and , from the FundingAmount column. In the column menu, choose Edit cells &gt; Transform. In the Expression window, type value.replace(',', '') and notice how commas disappear in the preview window. When you confirm your formula works, click OK. Now, repeat the previous step, but instead of a comma, remove the $ character. (Your expression will become value.replace('$', '')). In steps 3 and 4, we replaced text (string) values with other string values, making OpenRefine think this column is no longer numeric. As a result, all values are once again left-aligned and in black. Perform step 1 again to see that all but three cells turning green (successfully converting to numeric). Now we need to remove spaces and an a character at the end of one number. Fix those manually by hovering over cells, and clicking the edit button (in the new popup window, make sure to change Data type to number, and hit Apply, like in Figure 4.11). Figure 4.11: Manually remove spaces and extra characters, and change data type to number. At this point, all funding amounts should be clean numbers, right-aligned and colored in green. We’re ready to move on to the Country column and fix different spellings of Koreas. Cluster Similar Spellings When you combine different data sources, or process survey data where respondents wrote down their answers as opposed to selecting them from a dropdown menu, you might end up with multiple spellings of the same word (town name, education level – you name it!). One of the most powerful features of OpenRefine is the ability to cluster similar responses. If you use our original sample file, take a look at the Country column and all variations of North and South Korea spellings. From Country column’s dropdown menu, go to Facet &gt; Text facet. This will open up a window in the left-hand side with all spellings (and counts) of column values. 26 choices for a column that should have just two distinct values, North Korea and South Korea! To begin standardizing spellings, click on the arrow-down button of Country column header, and choose Edit cells &gt; Cluster and edit. You will see a window like the one shown in Figure 4.12. You will have a choice of two clustering methods, key collision or nearest neighbor. Key collision clustering is a much faster technique that is appropriate for larger datasets, but it is less flexible. Nearest neighbor is a more computationally expensive approach and will be slow on larger datasets, but it allows for greater fine-tuning and precision. Both methods can be powered by different functions, which you can read about on the project’s Wiki page. For the purpose of this exercise, let’s leave the default key collision method with fingerprint function. OpenRefine will calculate a list of clusters. Values in Cluster column contains grouped spellings that OpenRefine considers the same. If you agree with a grouping, check the Merge? box, and assign the “true” value to the New Cell Value input box (see first cluster in Figure 4.12). In our example, this would be either North Korea or South Korea. You can go through all groupings, or stop after one or two and click Merge Selected &amp; Re-Cluster button. The clusters you chose to merge will be merged, and grouping will be re-calculated (don’t worry, the window won’t go anywhere). Keep regrouping until you are happy with the result. Spend some time playing with Keying function parameters, and notice how they produce clusters of different sizes and accuracy. Figure 4.12: Cluster similar text values. Export Once you are done cleaning up and clustering data, save the clean dataset by clicking Export button in the upper-right corner of OpenRefine window. You can choose your format (we recommend CSV, or comma-separated value). Now you have a clean dataset that is ready to be processed and visualized. Summary In this chapter, we looked at cleaning up tables in Google Sheets, liberating tabular data trapped in PDFs using Tabula, and using OpenRefine to clean up very messy datasets. You will often find yourself using several of these tools on the same dataset before it becomes good enough for your analysis. We encourage you to learn more formulas in Google Sheets, and explore extra functionality of OpenRefine in your spare time. The more clean-up tools and techniques you know, the more able and adaptable you become to tackle more complex cases. You now know how to clean up your data, so let’s proceed to visualizing it. In the following chapter, we will introduce you to a range of free data visualization tools that you can use to build interactive charts and embed them in your website. "],
["chart.html", "Chapter 5 Chart Your Data", " Chapter 5 Chart Your Data Charts pull readers deeper into your story. Even if your data contains geographical information, sometimes a chart tells your story better than a map. But designing meaningful, interactive charts requires careful thought about how to communicate your data story with your audience. In this chapter, we will look at main principles of chart design, and learn to identify good charts from bad ones. You will learn important rules that apply to all charts, and also some aesthetic guidelines to follow when customizing your own designs. In addition to static chart images, this book focuses on interactive charts that display more data when you float your cursor over them in your web browser. Later you’ll learn how to embed interactive charts on your website in chapter 8. To begin, decide which type of chart you wish to create in Table 5.1. Your decision will be based on the format of your data, and the story you wish to tell, such as the type of data comparison you wish to draw to your reader’s attention. Once you choose your chart type, follow our tool recommendations to create it. This chapter features easy-to-learn drag-and-drop tools to create charts, such as Google Sheets, Datawrapper, and Tableau Public. But Table 5.1 also refers to more powerful and customizable chart code templates, such as Chart.js and Highcharts templates in chapter 10, which give you ever more control over how your design and display your data, but first require learning how to edit and host code templates with GitHub in chapter 9. Table 5.1: Basic Chart Types and Tutorials Chart Best use and tutorials in this book Grouped column or bar Best to compare categories side-by-side. Vertical columns, or horizontal bars for long labels. Easy tool: Google Sheets bar and column tutorialPower tool: Chart.js and Highcharts templates Separated column or bar Best to compare categories in separate clusters. Vertical columns, or horizontal bars for long labels.Easy tool: Google Sheets bar and column tutorialPower tool: Chart.js and Highcharts templates Stacked column or bar Best to compare sub-categories, or parts of a whole. Vertical columns, or horizontal bars for long labels.Easy tool: Google Sheets bar and column tutorialPower tool: Chart.js and Highcharts templates Histogram Best to show distribution of raw data, with number of values in each bucket.Easy tool: Google Sheets bar and column tutorialPower tool: Chart.js and Highcharts templates Pie chart Best to show parts of a whole, but hard to estimate size of slices.Easy tool: Google Sheets pie chart tutorialPower tool: Chart.js and Highcharts templates Line chart Best to show continuous data, such as change over time.Easy tool: Google Sheets line chart tutorialPower tool: Chart.js and Highcharts templates Filtered line chart Best to show multiple lines of continuous data, with on-off toggle buttons. Easy tool: Tableau Public filtered line chart tutorial Stacked area chart Best to show parts of a whole, with change over time. Easy tool: Google Sheets stacked area tutorialPower tool: Chart.js and Highcharts templates XY Scatter chart Best to show the relationship between two sets of data. Easy tool: Google Sheets scatter chart tutorial or Tableau Public scatter chart tutorialPower tool: Chart.js and Highcharts templates Bubble chart Best to show the relationship between three or four sets of data, using bubble size and color.Easy tool: Google Sheets bubble chart tutorialPower tool: Chart.js and Highcharts templates "],
["chart-design.html", "Chart Design Principles", " Chart Design Principles Although not a science, data visualization comes with a set of rules, principles, and best practices that create a basis for clear and eloquent charts. Some of those rules are less rigid than others, but prior to “breaking” them, it is important to establish why they are important. Before you begin, ask yourself: Do I really need a chart to tell this data story? Or would a table or text alone do a better job? Making a good chart takes time and effort, so make sure it enhances your story. Deconstructing a Chart Let’s take a look at Figure 5.1. It shows basic chart components that are shared among most chart types. Figure 5.1: Common chart components. A title is perhaps the most important element of any chart. A good title is short, clear, and tells a story on its own. For example, “Black and Asian Population More Likely to Die of Covid-19”, or “Millions of Tons of Plastic Enter the Ocean Every Year” are both clear titles. Sometimes a more “dry” and “technical” title is preferred. Our two titles can then be changed to “Covid-19 Deaths by Race in New York City, March 2020” and “Tons of Plastic Entering the Ocean, 1950–2020”, respectively. Often these two styles are combined into a title (“story”) and a subtitle (“technical”), like that: Black and Asian Population More Likely to Die of Covid-19 Covid-19 Deaths by Race in New York City, March 2020 Make sure your subtitle is less prominent than the title. You can achieve this by decreasing font size, or changing font color (or both). Horizontal (x) and vertical (y) axes define the scale and units of measure. A data series is a collection of observations, which is usually a row or a column of numbers, or data points, in your dataset. Labels and annotations are often used across the chart to give more context. For example, a line chart showing US unemployment levels between 1900 and 2020 can have a “Great Depression” annotation around 1930s, and “Covid-19 Impact” annotation for 2020, both representing spikes in unemployment. You might also choose to label items directly instead of relying on axes, which is common with bar charts. In that case, a relevant axis can be hidden and the chart will look less cluttered. A legend shows symbology, such as colors and shapes used in the chart, and their meaning (usually values that they represent). You should add any Notes, Data Sources, and Credits underneath the chart to give more context about where the data came from, how it was processed and analyzed, and who created the visualization. Remember that being open about these things helps build credibility and accountability. In interactive charts, a tooltip is often used to provide more data or context once a user clicks or hovers over a data point or a data series. Tooltips are great for complex visualizations with multiple layers of data, because they declutter the chart. But because tooltips are harder to interact with on smaller screens, such as phones and tablets, and are invisible when the chart is printed, only rely on them to convey additional, nice-to-have information. Make sure all essential information is visible without any user interaction. Some Rules are More Important than Others Although the vast majority of rules in data visualization are open to interpretation, there are some that are hard to bend. Bar charts must start at zero Bar charts use length to represent value, therefore their value axis must start at zero. That applies to column and area charts as well. This is to ensure that a bar twice the length of another bar represents twice its value. The Figure 5.2 shows a good and a bad example. Figure 5.2: Start your bar chart at zero. Starting y-axis at anything other than zero is a common trick used by some media and politicians to exaggerate differences in surveys and election results. Learn more about how to detect bias in data stories in chapter 13. Pie Charts Represent 100% Pie charts is one of the most contentious issues in data visualization. Most dataviz practitioners will recommend avoiding them entirely, saying that people are bad at accurately estimating sizes of different slices. We take a less dramatic stance, as long as you adhere to the recommendations we give in the next section. But the one and only thing in data visualization that every single professional will agree on is that pie charts represent 100% of the quantity. If slices sum up to anything other than 100%, it is a crime. If you design a survey titled Are you a cat or a dog person? and include I am both as the third option, forget about putting the results into a pie chart. Chart Aesthetics Remember that you create a chart to help the reader understand the story, not to confuse them. Decide if you want to show absolute numbers, percentages, or percent changes, and do the math for your readers. Avoid chart junk Start with a white background and add elements as you see appropriate. You should be able to justify each element you add. To do so, ask yourself: Does this element improve the chart, or can I drop it without decreasing readability? This way you won’t end up with so-called “chart junk” as shown in Figure 5.3, which includes 3D perspectives, shadows, and unnecessary elements. They might have looked cool in early versions of Microsoft Office, but let’s stay away from them today. Chart junk distracts the viewer and reduces chart readability and comprehension. It also looks unprofessional and doesn’t add credibility to you as a storyteller. Figure 5.3: Chart junk distracts the viewer, so stay away from shadows, 3D perspectives, unnecessary colors and other fancy elements. Do not use shadows or thick outlines with bar charts, because the reader might think that decorative elements are part of the chart, and thus misread the values that bars represent. The only justification for using three dimensions is to plot three-dimensional data, which has x, y, and z values. For example, you can build a three-dimensional map of population density, where x and y values represent latitude and longitude. In most cases, however, three dimensions are best represented in a bubble chart, or a scatterplot with varying shapes and/or colors. Beware of pie charts Remember that pie charts only show part-to-whole relationship, so all slices need to add up to 100%. Generally, the fewer slices—the better. Arrange slices from largest to smallest, clockwise, and put the largest slice at 12 o’clock. Figure 5.4 illustrates that. Figure 5.4: Sort slices in pie charts from largest to smallest, and start at 12 o’clock. If your pie chart has more than five slices, consider showing your data in a bar chart, either stacked or separated, like Figure 5.5 shows. Figure 5.5: Consider using bar charts instead of pies. Don’t make people turn their heads to read labels When your column chart has long x-axis labels that have to be rotated (often 90 degrees) to fit, consider turning the chart 90 degrees so that it becomes a horizontal bar chart. Take a look at Figure 5.6 to see how much easier it is to read horizontally-oriented labels. Figure 5.6: For long labels, use horizontal bar charts. Arrange elements logically If your bar chart shows different categories, consider ordering them, like is shown in Figure 5.7. You might want to sort them alphabetically, which can be useful if you want the reader to be able to quickly look up an item, such as their town. Ordering categories by value is another common technique that makes comparisons possible. If your columns represent a value of something at a particular time, they have to be ordered sequentially, of course. Figure 5.7: For long labels, use horizontal bar charts. Do not overload your chart When labelling axes, choose natural increments that space equally, such as [0, 20, 40, 60, 80, 100], or [1, 10, 100, 1000] for a logarithmic scale. Do not overload your scales. Keep your typography simple, and use (but do not overuse) bolding to highlight major insights. Consider using commas as thousands separators for readability (1,000,000 is much easier to read than 1000000). Be careful with the colors The use of color is a complex topic, and there are plenty of books and research devoted to it. For an excellent overview, see Lisa Charlotte Rost’s “A Friendly Guide to Colors in Data Visualization” blog post for Datawrapper.6 But some principles are fairly universal. First, do not use colors just for the sake of it, most charts are fine being monochromatic. Second, remember that colors come with some meaning attached, which can vary among cultures. In the world of business, red is conventionally used to represent loss, and it would be unwise to use this color to show profit. Make sure you avoid random colors. Whatever colors you end up choosing, they need to be distinguishable (otherwise what is the point?). Do not use colors that are too similar in hue (for example, various shades of green––leave them for choropleth maps). Certain color combinations are hard to interpret for color-blind people, like green/red or yellow/blue, so be very careful with those. Figure 5.8 shows some good and bad examples of color use. Figure 5.8: Don’t use colors just for the sake of it. If you follow the advice, you should end up with a de-cluttered chart as shown in Figure 5.9. Notice how your eyes are drawn to the bars and their corresponding values, not bright colors or secondary components like the axes lines. Figure 5.9: Make sure important things catch the eye first. Lisa Charlotte Rost, “Your Friendly Guide to Colors in Data Visualisation,” Chartable: A Blog by Datawrapper, July 31, 2018, https://blog.datawrapper.de/colorguide/↩︎ "],
["chart-google-sheets.html", "Google Sheets Charts", " Google Sheets Charts In addition to powerful data wrangling capabilities, Google Sheets has robust support for charting. In this section, we will start by creating three different types of column and bar charts: grouped, separated, and stacked. Then we’ll move on to making histogram, pie, line, area, and scatter charts, and learn to visualize three-dimensional data using bubble charts. See all of the types of charts you can create with Google Sheets. Although many people export charts as static images in JPG or PNG format, we’ll focus on designing interactive charts that display tooltips when you hover over the data, which you’ll learn how to easily embed on your website in chapter 8. Like most easy-to-use tools, Google Sheets has its shortcomings. You won’t be able to annotate or highlight items inside your charts, and there’s no easy way to cite your source or link to your Google Sheets data inside your chart. Furthermore, there are limitations within certain types of charts, such as the inability to control the data that appears in the tooltips for XY scatter charts. But Google Sheets excels at helping you to quickly create good-looking interactive charts from your data. But you will be able to quickly make good-looking interactive charts. If Google Sheets does not meet your needs, refer back to Table 5.1 for other types of chart tools and tutorials. "],
["column-bar-google.html", "–Column and Bar Charts", " –Column and Bar Charts Column and bar charts are some of the most common visualization techniques to compare values across categories. Remember to use columns to display data vertically, and bars to display it horizontally when you have long data labels. This section focuses on why and how to use Google Sheets to build different types of interactive column (or bar) charts: grouped, separated, stacked, and histograms. Grouped Column or Bar Charts A grouped column (or bar) chart is best to compare categories side-by-side. For example, if you wish to emphasize gender differences in obesity across age brackets, then format the male and female data series together in vertical columns in your Google Sheet, as shown in Figure 5.10. Now you can easily create a grouped column chart to displays these data series side-by-side, as shown in Figure 5.11. Figure 5.10: To create a grouped column (or bar) chart, format each data series vertically in Google Sheets. Figure 5.11: Grouped column chart: Explore the interactive version. Data from StateOfObesity.org. To create your own interactive grouped column (or bar) chart, use our template and follow these steps. Open our Grouped Column chart template in Google Sheets with US obesity data by gender and age. Sign in to your account, and go to File &gt; Make a Copy to save a version you can edit to your own Google Drive, as shown in Figure 5.12. Figure 5.12: Make your own copy of the Google Sheet template. To remove the current chart from your copy of the spreadsheet, float your cursor to the top-right corner of the chart to make the 3-dot kebab menu appear, and select Delete, as shown in Figure 5.13. Figure 5.13: Float cursor in top-right corner of the chart to make the 3-dot kebab menu appear, and select Delete. Note: Another name for the 3-dot menu symbol is the “kebab menu” because it resembles Middle Eastern food cooked on a skewer, in contrast to the three-line “hamburger menu” on many mobile devices, as shown in Figure 5.14. Software developers must be hungry. Figure 5.14: Distinguish between the hamburger verus kebab menu icons. Format your data to make each column a data series (such as male and female), as shown in Figure 5.10, which means it will display as a separate color in the chart. Feel free to add more than two columns. Use your cursor to select only the data you wish to chart, then go to the Insert menu and select Chart, as shown in Figure 5.15. Figure 5.15: Select your data and Insert the Chart. In the Chart Editor, change the default selection to Column chart, with Stacking none, to display Grouped Columns, as shown in Figure 5.16. Or select Horizontal bar chart if you have longer labels. Figure 5.16: Change the default to Column chart, with Stacking none. To customize title, labels, and more, in the Chart Editor select Customize, as shown in Figure 5.17. Also, you can select the chart and axis titles to edit them. Figure 5.17: Select Customize to edit title, labels, and more. To make your data public, go to the upper-right corner of your sheet to click the Share button, and in the next screen, click the words “Change to anyone with the link,” as shown in Figure 5.18. This means your sheet is no longer Restricted to only you, but can be viewed by anyone with the link. See additional options. Figure 5.18: Click the Share button and then click Change to anyone with the link to make your data public. To embed an interactive version of your chart in another web page, click the kebab menu in the upper-right corner of your chart, and select Publish Chart, as shown in Figure 5.19. In the next screen, select Embed and press the Publish button. See Chapter 8: Embed on the Web to learn what to do with the iframe code. Figure 5.19: Select Publish Chart to embed an interactive chart on another web page. Note: Currently, there is no easy way to cite or link to your source data inside a Google Sheets chart. Instead, cite and link to your source data in the text of the web page. Remember that citing your sources adds credibility to your work. Separated Column or Bar Charts A separated column (or bar) chart is best to compare categories in separate clusters. For example, imagine you wish to emphasize calorie counts for selected foods offered at two different restaurants, Starbucks and McDonalds. Format the restaurant data in vertical columns in your Google Sheet, as shown in Figure 5.20. Since food items are unique to each restaurant, only enter calorie data in the appropriate column, and leave other cells blank. Now you can easily create a separated bar (or column) chart that displays the restaurant data in different clusters, as shown in Figure 5.21. Unlike the grouped column chart previously shown in Figure 5.11, here the bars are separated from each other, because we do not wish to draw comparisons between food items that are unique to each restaurant. Also, our chart displays horizontal bars (not columns) because our some data labels are long. Figure 5.20: To create a separated bar (or column) chart, format each data series vertically, and leave cells blank where appropriate. Figure 5.21: Separated bar chart: Explore the full-screen interactive version. Data from Starbucks and McDonalds. Create your own version using our Separated Bar Chart in Google Sheets template with Starbucks and McDonalds data. Organize each data series vertically so that it becomes its own color in the chart. Leave cells blank when no direct comparisons are appropriate. The remainder of the steps are similar to the grouped column chart tutorial above. Stacked Column or Bar Charts Stacked column (or bar) charts are best to compare subcategories, or parts of a whole. For example, if you wish to compare the percentage of overweight residents across nations, format each weight-level data series in vertical columns in your Google Sheet, as shown in Figure 5.22. Now you can easily create a stacked column (or bar) chart that displays comparisons of weight-level subcategories across nations, as shown in Figure 5.23. Often it’s better to use a stacked chart instead of multiple pie charts, because people can see differences more precisely in rectangular stacks than in circular pie slices. Figure 5.22: To create a stacked column (or bar) chart, format each data series vertically in Google Sheets. Figure 5.23: Stacked column chart: Explore the interactive version. Data from WHO and CDC. Create your own version using our Stacked Column Chart in Google Sheets template with international weight-level data. Organize each data series vertically so that it becomes its own color in the chart. In the Chart Editor window, choose Chart Type &gt; Stacked column chart (or choose Stacked bar chart if you have long data labels). The rest of the steps are similar to the ones above. To change the color of a data series (for example, to show Overweight category in red), click the kebab menu in the top-right corner of the chart, then go to Edit Chart &gt; Customize &gt; Series. Then choose the appropriate series from the dropdown menu, and set its color in the dropdown menu, as shown in Figure 5.24. Figure 5.24: To edit a column color, select Edit Chart - Customize - Series. Histograms A histogram is a specific type of column or bar chart that is best for showing the distribution of raw data, with the number of values in each bucket (or bin). To build a histogram, you need to assign each data point, whether numerical or categorical, into one of the non-overlapping buckets. For example, imagine that you wish to track the number of customers each hour in a local coffee shop. Format the raw customer data series in a vertical column in your Google Sheet, as shown in Figure 5.25. Now you can easily create a histogram column chart that displays the number of customers per hour, as shown in Figure 5.26, which resembles the “popular times” format for businesses in Google Maps. This coffee shop experiences a morning rush and an afternoon rush, but the middle of the day and late evenings are relatively quiet. Figure 5.25: To create a histogram, format the raw data series vertically in Google Sheets. Figure 5.26: Histogram: Explore the interactive version. Fictitious data on coffee shop customers. Create your own version using our Histogram Chart in Google Sheets template with coffee shop customer data. Google Sheets considers histograms to be regular column charts, so in the Chart Editor window, choose Chart Type &gt; Column chart and follow the rest of the directions in the Column or Bar Chart tutorial above. Alternatively, you could choose to sort customers into larger bins, such as time of day (morning, afternoon, evening), as shown in the second tab of the template. Tip: We set a custom number format to display 8 AM and other times as desired in the Hour column. In Google Sheets, select a column, then go to Format &gt; Number &gt; More Formats &gt; Custom Number Formats to define your preferred format. "],
["pie-line-area-google.html", "–Pie, Line, and Area Charts", " –Pie, Line, and Area Charts This section focuses on why and how to use Google Sheets to build more types of interactive charts: pie charts (to show parts of a whole), line charts (to show change over time), and stacked area charts (to combine showing parts of a whole, with change over time). Pie Charts Some people use pie charts to show parts of a whole, but we urge caution with this type of chart for reasons explained further below. For example, if you wish to show the number of different fruits sold by a store in one day, as a proportion of total fruit sold, then format the labels and values in vertical columns in your Google Sheet, as shown in Figure 5.27. Values can be expressed as either raw numbers or percentages. Now you can easily create a pie chart that displays these values as colored slices of a circle, as shown in Figure 5.28. Viewers can see that bananas made up slightly over half of the fruit sold, followed by apples and oranges. Figure 5.27: To create a pie chart, format the data values vertically in Google Sheets. Figure 5.28: Pie chart: Explore the interactive version. Data is fictitious. But you need to be careful when using pie charts, as we described in the Chart Design section of this chapter. First, make sure your data adds up to 100 percent. If you created a pie chart that displayed some but not all of the fruits sold, it would not make sense. Second, avoid creating too many slices, since people cannot easily distinguish smaller ones. Ideally, use no more than 5 slices in a pie chart. Finally, start the pie at the top of the circle (12 o’clock) and arrange the slices clockwise, from largest to smallest. Create your own version using our Pie Chart in Google Sheets template. The steps are similar to those in prior Google Sheets chart tutorials in this chapter. Go to File &gt; Make a Copy to create a version you can edit in your Google Drive. Select all of the cells and go to Insert &gt; Chart. If Google Sheets does not correctly guess that you wish to create a pie chart, then in the Chart editor window, in the Setup tab, select Pie chart from the Chart type dropdown list. Note that slices are ordered the same way they appear in the spreadsheet. Select the entire sheet and Sort the values column from largest to smallest, or from Z to A. In Customize tab of the Chart editor, you can change colors and add borders to slices. Then add a meaningful title and labels as desired. Line Charts A line chart is the best way to represent continuous data, such as change over time. For example, imagine you wish to compare the availability of different meats per capita in the US over the past century. In your Google Sheet, organize the time units (such as years) into the first column, since these will appear on the horizontal X-axis. Also, place each data series (such as beef, pork, chicken) alongside the vertical time-unit column, and each series will become its own line, as shown in Figure 5.29. Now you can easily create a line chart that emphasizes each data series changed over time, as shown in Figure 5.30. In the US, the amount of chicken per capita steadily rose and surpassed pork and beef around 2000. Figure 5.29: To create a line chart, format the time units and each data series in vertical columns. Figure 5.30: Line chart: Explore the interactive version. Data from US Department of Agriculture. Create your own version using our Line Chart in Google Sheets template. The steps are similar to those in prior Google Sheets chart tutorials in this chapter. Go to File &gt; Make a Copy to create a version you can edit in your Google Drive. Select the data, and choose Insert &gt; Chart. If Google Sheets does not correctly guess that you wish to create a line chart, in the Chart editor, Setup tab, select Line chart from the Chart type dropdown list. Stacked Area Charts A stacked line chart is best for combining two concepts from above: showing parts of the whole (like a pie chart) and continuous data over time (like a line chart). For example, the line chart above shows how the availability of three different meats changed over time. But it’s hard to estimate if the total availability of these three meets went up or down over time in a line chart. However, a stacked line chart shows the availability of each meat and the total meet availability per capita over time. Organize the data in the same way as you did for the line chart in Figure 5.29. Now you can easily create a stacked line chart that displays the availability of each meat—and their combined total—over time, as shown in Figure 5.31. Overall, we can see that total available meat per capita increased after the 1930s Depression, and chicken steadily became a larger portion of the total after 1970. Figure 5.31: Stacked area chart: Explore the interactive version. Data from US Department of Agriculture. Create your own version using our Stacked Area Chart in Google Sheets template. The steps are similar to those in prior Google Sheets chart tutorials in this chapter. Go to File &gt; Make a Copy to create a version you can edit in your Google Drive. Set up the data exactly as you would for a line chart, with the first column for time units in the X-axis, and place each data series in its own column. Select the data, and choose Insert &gt; Chart. In the Chart editor, in tab Setup, select Stacked area chart from the Chart type dropdown list. "],
["scatter-bubble-google.html", "–XY Scatter and Bubble Charts", " –XY Scatter and Bubble Charts Scatter charts (also known as XY charts or scatter plots) and bubble charts are best to show the relationship between two, three, or four sets of data. Scatter charts display dots on a grid to represent the XY coordinates of two variables. In the scatter chart example below, each dot represents a nation, with its life expectancy on the horizontal X axis and its fertility rate on the vertical Y axis. The overall dot pattern illustrates the relationship between these two datasets: life expectancy and fertility. Bubble charts go beyond scatter charts by adding two more visual elements—dot size and color—to represent a third or fourth dataset. Further below, the bubble chart begins with the same XY coordinates to represent life expectancy and fertility for each nation, then changes the size of each circular dot to represent population, and its color to indicate region of the world. As a result, a bubble chart can show relationships between four datasets. In this section, you’ll learn how to create both scatter and bubble charts in Google Sheets, as well as some limitations of this tool. Fancier bubble charts introduce one more visual element—animation—to represent a fifth dataset for change over time. Although creating an animated bubble chart is beyond the scope of this book, watch a famous TED talk by Hans Rosling, a renowned Swedish professor of global health, to see animated bubble charts in action, and learn more about his work at the Gapminder Foundation website. XY Scatter Charts TODO: START REVISIONS AGAIN HERE The scatter chart in Figure 5.32 uses World Bank data to reveal a downward slope: nations with lower fertility (births per woman) tend to have higher life expectancy. You can also phrase is the other way, nations with higher life expectancy at birth have lower fertility. Remember that correlation does not mean causation, so you cannot use this chart to argue that fewer births result in longer lives, or that longer-living females give birth to fewer children. Figure 5.32: This scatter chart shows that nations with lower fertility tend to have higher life expectancy. See data by World Bank. Explore the full-screen interactive version. The data used in Figure 5.32 is available from our Google Sheets Scatter chart template. You can copy it to your own Google Drive so that you’re able to edit it (go to File &gt; Make a copy). Figure 5.33 shows the first few rows of the dataset. Notice that the data is structured in three columns. The first column, Life Expectancy, is plotted on the x-axis (horizontal). The second column, Fertility, is plotted on the y-axis (vertical). The third column contains Country labels. Figure 5.33: Data for a scatterplot is usually represented in 3 columns: x-values, y-values, and labels. To build a scatter chart, select the two columns that contain your numeric data, and go to Insert &gt; Chart. Google Sheets will likely to guess the chart type and you will see a scatterplot, but if not, you can always manually pick Scatter chart from the Chart type dropdown. Make sure your x-axis is set to Life Expectancy, and your Series shows Fertility. Note that both Life Expectancy and Fertility have 123 icon, meaning they are numeric. You will see a lot of scatter charts out there that do not label data points, and that’s okay. Some scatter plots are designed to show whether or not there is a correlation, and knowing which points are which is not important. But sometimes labels are important for your storytelling. In Chart editor, open the kebab menu (3 dots) of your Series dataset (Fertility), and then Add labels (see Figure 5.34). The labels added by default will be the x-values of points. To make Google Sheets read labels from the third column (Country), click the name of your label dataset (Life Expectancy), then Select a data range button in the upper-right corner of the dropdown, and choose cells in the relevant columns. Make sure to include the header (first row) if all other data ranges include it. Figure 5.34: In the chart’s Setup window, choose Add labels to the Series. Tip: You may notice that some data points are too close to edges, and their labels are cut off. To fix this, go to Customize tab of the Chart editor. There, you can set minimum and maximum values for both horizontal and vertical axes. Unlike in bar charts, axes in scatter plots do not have to start at zero. You can set your minimum and maximum values to be a few units below and above the extreme points of your data range. Bubble Charts with 3 columns In this tutorial, we will show you a little trick that you can use if you want a scatter chart with both data values displayed in a tooltip. We will use the same World Bank dataset as we did for the scatter plot. The bubble chart (more about the proper use of bubble charts in the next section) in Figure 5.35 shows the same data as our scatterplot on life expectancy vs fertility. In the interactive version of the chart, hover your cursor over each bubble (dot) to reveal a tooltip with the country name and the two data points. Figure 5.35: This bubble chart is essentially a scatter chart, because no other dimensions (colors, sizes) are used. See data by World Bank. Explore the full-screen interactive version. The data for this example is available in Google Sheets Bubble chart with 3 columns template. Notice that we moved the labels column (Country) to be the first one in the dataset, but the order shouldn’t matter in this case. So our first column is the label for each bubble, the second column is the data to be plotted on horizontal x-axis, and the third column (fertility) will be placed on the y-axis. Select all three columns, and go to Insert &gt; Chart. Google Sheets will likely create a stacked column chart by default, so choose Bubble from the Chart type dropdown window. If you want to remove labels from the bubbles, remove the ID series (click on the kebab menu &gt; Remove). Unfortunately, there is no easy way to reduce all bubbles to a uniformly smaller size. In the following section, we will introduce you to the proper way of using bubble charts. Bubble Charts with 5 columns Bubble charts are a good alternative to scatter charts if you need to include one or two extra series in addition to your x- and y-coordinates. One of those can be expressed through bubble size (bigger bubbles represent larger values). Another one can make use of color (best for categorical data). The bubble chart in Figure 5.36 shows fertility and life expectancy for a subset of the nations, with population (shown by bubble size) and region (shown by bubble color). Float your cursor over bubbles to view data details in the interactive version of the chart. Figure 5.36: This bubble chart shows fertility and life expectancy for several countries, including their population (shown by bubble size) and region (shown by bubble color). See data by World Bank. Explore the full-screen interactive version. The five-column dataset is available in this Google Sheets Bubble chart with 5 columns template. The columns are arranged in the following order: country label, x-axis value, y-axis value, color, and bubble size. Figure 5.37: Bubble chart data. Bubble size represents population, color – region. Select all data and go to Insert &gt; Chart, and choose Bubble as the Chart type. Make sure your ID, X-axis, Y-axis, Series, and Size fields contain the series you want to display, and make sure to have Use row 1 as headers option checked. To change labels color, go to Customize tab of the Chart editor, and set Text color under the Bubble menu. Make it gray or black, so that it won’t interfere with the bubble colors themselves. Tip: If some of your bubbles are too close to the borders, set Min and Max values for the axis manually under Horizontal axis and Vertical axis menus. "],
["chart-datawrapper.html", "Datawrapper Charts", " Datawrapper Charts TODO: probably annotated chart? "],
["chart-tableau-public.html", "Tableau Public Charts", " Tableau Public Charts Tableau is powerful data visualization software used by many professionals and organizations to analyze and present data. Tableau can combine multiple datasets to show in a single chart (or a map), and allows to create dashboards with multiple visualizations. Individual visualizations and dashboards can be published and embedded on your website through an iframe. This book focuses on the free Tableau Public tool, available to download for Mac or Windows. This free version of Tableau Public is very similar to the pricier versions that the company sells, but one constraint is that the data visualizations you create will be public, as the name suggests, so do not use it for any sensitive or confidential data that should not be shared with others. You might be overwhelmed by the amount of options and features Tableau provides through its interface. We will show you the very basics enough to get started, and if you want to dive further, there are many great books on Tableau available. In this book, we will show you how to add datasets to Tableau Public, and how to create a scatterplot and a filtered line chart. "],
["scatter-chart-tableau.html", "–XY Scatter Chart", " –XY Scatter Chart Just to remind you, scatter charts plot two variables against each other, on x- and y-axis, revealing possible correlations. With Tableau Public, you can create an interactive scatter chart, letting users hover over points to view specific details. Figure 5.38 illustrates a strong relationship between Connecticut school district income and test scores. Figure 5.38: This scatterplot is made in Tableau Public an shows the relationship between household income and test scores in Connecticut school districts. Install Tableau and Get Data You can download Tableau Public for Windows or Mac from Tableau’s official website. You will need to provide your email address. If you wish to use the dataset from the scatter plot in Figure 5.38, you can download the sample Excel file. This data file consists of three columns: district, median household income, and grade levels (above/below national average for 6th grade Math and English test scores). The Notes tab explains how this data is based on the work of Sean Reardon et al. at the Stanford Education Data Archive, Motoko Rich et al. at The New York Times, Andrew Ba Tran at TrendCT, and the American Community Survey 2009-13 via Social Explorer. Connect Data and Create a Scatterplot Tableau Public’s welcome page includes three sections: Connect, Open, and Discover. Under Connect, choose Microsoft Excel if you decided to use the sample dataset or your own Excel file. To load a CSV file, choose Text file. If your data is in Google Sheets, click More… and choose Google Sheets. Once you successfully connect to your data source, you will see it under Connections in the Data Source tab. Under Sheets, you will see two tables, data and notes. Drag data sheet into Drag tables here area, like is shown in Figure 5.39. You will see the preview of the table under the drag-and-drop area. You have successfully connected one data source to Tableau Public, and you are ready to build your first chart. Figure 5.39: Drag data sheet into Drag tables here area. Go to Sheet 1 tab (in the lower-left corner of the window) to view your worksheet. Although it may feel overwhelming at first, the key is learning where to drag items from the Data pane (left) into the main worksheet. Tableau marks all data fields as blue (discrete values, mostly text fields or numeric labels) or green (continuous values, mostly numbers). Drag the Grade Levels field into the Rows field above the charting area, which for now is just empty space. You can consult Figure 5.40 for this and two following steps. Tableau will apply a summation function to it, and you will see the SUM(Grade Levels) appearing in the Rows row, and a blue bar in the charting area. It makes little sense so far, so let’s plot another data field. Drag Median Household Income to the Columns field (just above the Rows field). Tableau will once again apply the summation function, so you will see SUM(Median Household Income) in the Columns. The bar chart will transform into a scatter chart with just one data point in the upper-right corner. That is because the data for both is aggregated (remember the SUM function). We want to tell Tableau to disaggregate the household and grade levels variables. To do so, drag District dimension into the Detail box of the Marks card. You will now see a real scatter chart in the charting area. If you hover over points, you will see all three values associated with it. Figure 5.40: Drag data fields to the right places in Tableau. Add Title and Caption, and Publish Give your scatter chart a meaningful title by double-clicking on default Sheet 1 title above the charting area. You will normally need to provide additional information about the chart, such as source of the data, who built the visualization and when, and other important things. You can do so inside a Caption, a text block that accompanies your Tableau visualization. In the menu, go to Worksheet &gt; Show Caption. Double-click the Caption block that appeared, and edit the text. As a result, your final worksheet will look like shown in Figure 5.41. Figure 5.41: This scatter chart is ready to be published. Tip: In the dropdown above Columns section, change Standard to Fit Width to ensure your chart occupies 100% of available horizontal space. To publish the chart to the web, Go to File &gt; Save to Tableau Public As…. A window to sign in to your account will pop up. If you don’t have an account, click Create one now for free at the bottom. Once signed in, a window to set the workbook title will appear. Change the default Book1 title to something meaningful, as this name will appear in the URL for your published work. Click Save. Once the dashboard is saved, Tableau Public will open up a window in your default browser with the visualization. In the green ribbon above the chart, click Edit Details to edit the title or description. Under Toolbar Settings, see checkbox to Allow others to download or explore and copy this workbook and its data (Figure 5.42), and enable/disable it as you think is appropriate. As advocates for open and accessible data, we recommend leaving the box checked. Figure 5.42: This scatter chart is ready to be published. See the Embed Tableau Public on Your Website section of this book to insert the interactive version of your chart on a web page that you control. Tip: Your entire portfolio of Tableau Public visualizations is online at https://public.tableau.com/profile/USERNAME, where USERNAME is your unique username. To learn more, see Tableau Public resources page. "],
["filtered-line-chart-tableau.html", "–Filtered Line Chart", " –Filtered Line Chart One of the advantages of interactive visualizations over static (including printed) is the ability to store a lot more data, and show it only when required. In other words, an interactive visualization can be made into a data-exploration tool that won’t overwhelm the viewer at first sight, but will allow the viewer to “dig” and find specific data points and patterns. In this tutorial, we will build an interactive filtered line chart with Tableau Public like is shown in Figure 5.43. The filter will be a collection of checkboxes that allow to add/remove lines from the chart. Viewers can hover over each line to identify the school name and data attached to it. We will use % Population with Internet Access by the World Bank. You can download the dataset here. Figure 5.43: Internet Access by Country, 1995–2018. We assume that you have Tableau installed. If not, see the previous tutorial, Create XY Scatter Chart with Tableau Public. Connect Text File and Build a Line Chart Open Tableau Public, and under Connect menu, choose Text file. Tableau may or may not have imported the table automatically. If you see the preview of the table with three columns: Country Name, Year, and Percent Internet Users, you can proceed to Sheet 1. If not, drag and drop the file (under Files section in the left) to the Drag tables here area. Once you see the preview, go to Sheet 1. Your variables will be listed under Tables in the left-hand side. The original variables are displayed in normal font, the generated variables will be shown in italics (such as Latitude and Longitude that Tableau guessed from the country names). To build a line chart, Drag Year variable to Columns. Drag Percent Internet Users variable to Rows. The variable will change to SUM(Percent Internet Users). You should see a single line chart that sums up percentages for each year. That is completely incorrect, so let’s fix it. In order to “break” aggregation, drag and drop Country Name to the Color box of the Marks card. Tableau will warn you that the recommended number of colors should not exceed 20. Since we will be adding filtering, we don’t care about it much. So go ahead and press Add all members button. Now you should see an absolute spaghetti plate of lines and colors. To add filtering, drag Country Name to the Filters card. In the Filter window, make sure all countries are checked, and click OK. Right-click on Country Name pill in Filters card, and check Show Filter (see Figure 5.44) You will see a list of options with all checkboxes on have appeared to the right of the visualization. Click (All) to add/remove all options, and add a few of your favorite countries to see how the interactive filtering works. Figure 5.44: After you drag Country Name to the Filters card, make sure the Filter is displayed. Add Title and Caption, and Publish Replace Sheet 1 title (above the chart) with “Internet Access by Country, 1995–2018” by double-clicking on it. In the menu, go to Worksheet &gt; Show Caption to add a Caption block under the chart. Use this space to add source of your data (World Bank), and perhaps credit yourself as the author of this visualization. Change Standard to Fit Width in the dropdown above the Columns field. You may notice that the x-axis (Year) starts with 1994 and ends with 2020, although our data is for 1995–2018. Double-click on the x-axis, and change Range from Automatic to Fixed, with the Fixed start of 1995, and the Fixed end of 2018. Close the window and see that the empty space on the edges has disappeared. Once your filtered line chart looks like the one shown in Figure 5.45, you are ready to publish. Figure 5.45: This workbook is ready to be published. To publish the filtered line chart to the web, go to File &gt; Save to Tableau Public As…. You may be prompted with the window to log in to your account (or create one if you don’t have it yet). The next steps are fairly self-explanatory, and you can consult the previous tutorial for more information on publishing. See the Embed Tableau Public on Your Website section of this book to insert the interactive version of your chart on a web page that you control. Summary Congratulations on creating interactive charts that pull readers deeper into your story, and encourage them to explore the underlying data! As you continue to create more, always match the chart type to your data format and the story you wish to emphasize. Also, design your charts based on the principles and aesthetic guidelines in this chapter. While anyone can click a few buttons to quickly create a chart nowadays, your audiences will greatly appreciate well-designed charts that thoughtfully call their attention to meaningful patterns in the data. The next chapter on Map Your Data follows a similar format to introduce different map types, design principles, and hands-on tutorials to create interactive visualizations with spatial data. Later you’ll learn how to embed interactive charts on your web in chapter 8. To learn about more powerful charting tools, see Chart.js and Highcharts templates in chapter 9, which give you ever more control over how your design and display your data, but also requires learning how to edit and host code templates with GitHub in chapter 9. "],
["map.html", "Chapter 6 Map Your Data", " Chapter 6 Map Your Data Maps entice readers to explore your data story and develop a stronger sense of place. But good maps require careful thought about how to clearly communicate spatial concepts with your audience. We will begin this chapter by introducing key principles and definitions related to maps. We will then practice making interactive maps using free online tools, including Google My Maps, Socrata, Tableau, and Datawrapper. We will build two point maps and two choropleth maps. By the end of this chapter, you will be able to use four powerful tools to map your data. Table 6.1: Basic Map Types and Tutorials Map Best use and tutorials in this book Point map Best to show specific locations, such as addresses with geocoded coordinates, with colors for different categories. Easy tool: Google My Maps tutorialPower tool: Leaflet Maps with Google Sheets and other Leaflet templates Polygon map Best to show regions (such as nations or neighborhoods), with colors or shading to represent data values. Also known as choropleth map. Easy tool: n/a Power tools: Tableau Public or Leaflet Maps with Google Sheets and other Leaflet templates Polyline map Best to show routes (such as trails or transit), with colors for different categories. Easy tool: n/a Power tool: Leaflet Maps with Google Sheets and other Leaflet templates Combination map Best to show any combination of points, polygons, or polylines. Easy tool: n/a Power tool: Leaflet Maps with Google Sheets and other Leaflet templates Storymap Best for guided point-by-point journey through a historical narrative, with optional photos, audio, or video on an interactive map. Easy tool: Knight Lab’s StoryMap, ESRI Story Maps Power tool: Leaflet Storymaps with Google Sheets TODO ABOVE: UPDATE table to match chapter contents. Add tab-view map for historical change template? Add synchronized side-by-side map template? "],
["map-design.html", "Map Design Principles", " Map Design Principles Most of the data collected today comes with some sort of geospatial component. People’s home and places of business have addresses associated with them, such as 1012 Broad St, Hartford, CT. When we track our runs or bike journeys on Strava, they come with latitude and longitude components. National statistical agencies across the world collect data about regions and territories, such as average income or population counts, making it possible to compare countries and other geographical entities. However, just because data can be mapped does not mean it should be mapped. Before you decide to create a map, ask yourself: Does location really matter to your story? If precise values are more important to your story than spatial patterns, consider using a simple table to show values. Most people are familiar with the table, and can easily retrieve information from it as long as you arrange it logically (for example, alphabetically or sorted by value). If you want to show change over time for various geographies, consider using a line chart instead. Sometimes even a simple bar chart can be a much better alternative to a map. An effective map should show interesting geospatial patterns and should be easy to read in both black-and-white (as is often the case with printed materials) and color. Understand the Vocabulary Take a look at Figure 6.1 to get familiar with main basic elements of an interactive map. Similar to a chart, a good maps should have a title and a description that gives a bit of context about what the map is showing. Figure 6.1: Map elements. The data in the map is presented as layers. A base layer is often satellite imagery of the earth or vector representations of buildings and streets (also known as vector tiles). A base layer provides the foundation of the map. The data displayed on the maps can be generally described as points (such as marker locations of nearby restaurants), polylines (connected points, such as roads or trails), and polygons (polylines where the final point is connected with the initial one). Polygons represent areas, such as building footprints or country boundaries. The legend provides the mapping between shapes and colors and the values they represent. For example, you may wish to use blue markers to represent restaurants, and orange markers to represent bars, and legend will be the right place to explain that difference. Interactive maps often “hide” data inside popups or tooltips – boxes with information that appear when you click or hover over map elements. Interactive web maps often have zoom controls (+ and - buttons) to allow users to inspect data from various “distances”. Color Palettes: Sequential, Diverging, and Qualitative If you build a choropleth map, the choice of colors is very important as color is the main way to represent values. So let’s talk about color palettes. Color palettes can be grouped into sequential, diverging, and qualitative. The examples are shown in Figure 6.2. Figure 6.2: Examples of sequential, diverging, and qualitative color schemes from ColorBrewer. Sequential palettes are used to represent continuous numeric values, in other words, anything that can be placed on a scale. For example, average income, population counts, percent unemployed, etc. Usually such palettes are single-hue (for example, different shades of blue), and typically darker colors represent higher values (but not always). Diverging palettes also represent continuous values. Unlike sequential palettes, however, diverging colors represent “direction” from some reference value, such as below or above zero, or below or above the average value. Diverging palettes typically have two distinct hues for “positive” and “negative” values, with a neutral color in the middle. Qualitative palettes typically consist of distinct hues that represent distinct classes. For example, the US Department of State issues travel advisory to foreign destinations ranging from “exercise normal precautions” to “do not travel” relying on a series of qualitative and quantitative measures, such as the likelihood of terror attacks, political and criminal situation, etc. But classes can also be derived from numerical values, as is the case with the World Bank’s classification of countries by income. The organization groups countries and territories into “low”, “lower-middle”, “higher-middle”, and “high” income categories based on gross national income per capita. It is important you choose an appropriate classification for your choropleth map. While the nature of certain datasets will make the choice of a color palette obvious, most of the time you will have to actively choose how to display your data. In Figure 6.3a, we presented the same dataset using three differnet color palettes. The map in Figure 6.3a represents per capita income for the contiguous US states using a sequential color scheme consisting of five shades of blue. The darker the color, the higher the income. You can quickly see that states in the north-east, such as Connecticut, Massachusettes, New Jersey, and Maryland have the highest per capita income. In Figure 6.3b, we used a divergent color scheme to show whether states have higher or lower per capita incomes than the United States as a whole. We subtracted the US per capita income value of $33,831 from each state’s value. This new relative measure is positive for states with higher per capita income, and negative for the states whose per capita income is lower than in the US. In the map, sub-zero values are painted in orange, and above-zero values are in purple. Such color palette could be appropriate for a story about the north-south divide. You can also split the 48 states into three groups of 16 based on their per capita income, and group them in three thirds, as “low”, “middle”, and “top” third. This is what we did in the map shown in Figure 6.3c. Figure 6.3: Representing per capita income in US states using three different classifications. ColorBrewer One of the most useful color picking tools for meaningful choropleth maps is ColorBrewer, created by Cynthia Brewer and Mark Harrower. You can see ColorBrewer’s interface in Figure 6.4. Figure 6.4: ColorBrewer interface. ColorBrewer can generate color palettes for a specified number of classes - between three and nine for sequential, three and elevel for diverging, and three and twelve for qualitative. You can also choose palettes that are colorblind safe and print friendly. Remember that more colors (or “buckets”) does not equal better maps. People are quite bad at distinguishing hues, and an excessive number of buckets will make it harder for reader to compare map values with the legend. If you build a sequential color palette, we recommend you start with five buckets, then try four and six and decide what is appropriate for your data and your story. Fewer colors create a coarse map with differences in colored ranges becoming more visible. More colors create a more granular map, but differences in colored ranges become less visible. At this point, you should have some understanding of how maps work. So let’s move to the first practical exercise of creating a point map with Google My Maps. "],
["mymaps.html", "Point Map with Google My Maps", " Point Map with Google My Maps My Maps is Google’s service that allows users to create custom maps using Google Maps platform. It is perhaps the fastest ways of building point and basic polygon maps, although it limits your styling options. My Maps is most powerful when it comes to collaboration. The platform functions within Google Drive, and so allows you to invite other users with Google accounts to work on the map. In this section, we will look at building a point map of airports in Nigeria, as is shown in Figure 6.5. We will create a map, change a baselayer, import point data, style points, and share the map. Figure 6.5: A map of airports in Nigeria built using Google My Maps. Create a New Map in My Maps Navigate to Google My Maps. In the upper-right corner, click + Create a New Map button, as shown in Figure 6.6. Figure 6.6: A map of airports in Nigeria built using Google My Maps. You will see a typical Google Maps with no data. Click on the current title (Untitled map), and add appropriate title and description in the modal window that appeared (see Figure 6.7 for inspiration). Figure 6.7: Add title and description to your map. Before we add any points, let’s change the basemap to something less boring. At the bottom of the control window, open Base map dropdown, and pick one of nine available basemaps. For this tutorial, we chose Dark Landmass. Let’s now proceed to the most important step—adding data. You can download a dataset of Nigerian airports that we got from the World Bank as a Shapefile and then converted to a CSV. Under Untitled layer item, click Import button, and drag-and-drop the CSV file. Once the data file is uploaded, My Maps will ask which columns contain location data. In our case, these are LATITUDE and LONGITUDE columns, as shown in Figure 6.8. Figure 6.8: Check LATITUDE and LONGITUDE as your location columns. Once the two boxes are checked, click Continue. Another window will pop up, asking which column to use to annotate points. Choose City, as shown in Figure 6.9, and then Finish. Figure 6.9: Choose City as the title for your markers. It will take a few moments for My Maps to create a new layer, which will be added to the layer menu as nigeria-airports.csv. Once the layer is created, My Maps will center the map to fit the points. Let’s replace the original blue markers to orange airport symbols. In layers menu, hover over All items and click the paint bucket symbol on the right. Change “All items” text to “Airports”, choose orange color, and click on More icons to find an airport symbol (we recommend using Filter to search for “airport”, or simply scroll down to Transportation section). The marker in the layers menu will change to an orange airplane, as shown in Figure 6.10. Figure 6.10: In My Maps, you can change marker colors and icons. Click on the layer name, which by default is set to the name of imported file (nigeria-airports.csv), and change it to Nigerian Airports. Alternatively open a kebab menu to the right of the layer name, and choose Rename this layer. You can accompany each marker with a label. Click Uniform style under the layer, and choose Alt_name in the Set labels dropdown menu. You will see alternative airport names, such as BENIN, displayed to the right of the markers. Click Preview to see how the map looks like outside of the My Maps editing studio. Share Your Google Map If you are happy with the result, click Share, and click Change to anyone with the link (see Figure 6.11), just as you would with any other Google Drive document. Figure 6.11: Make sure anyone with the link can view your map before you share it. You can now generate a code snippet to embed the map as an iframe. From the main kebab menu to the right of the map title, choose Embed on my site (Figure 6.12). You can use now use this iframe code to embed your map to your Wordpress, Squarespace, or any other website. Figure 6.12: My Maps can generate an iframe code to include the map on your own website. Going Beyond Points Google My Maps has more powerful features for map making. Instead of uploading datasets with latitude/longitude pairs, you can use simple addresses (and My Maps will take care of geocoding), or add markers by clicking on the map using Add marker feature. You can classify points based on a property, and use different colors to represent them. You are not limited to just point maps. You can also draw your own shapes, including lines and polygons. You can add data to multiple layers. Unfortunately, Google My Maps has no comprehensive documentation, so you have to explore the studio yourself if you want to create more complex projects. "],
["map-with-datawrapper.html", "Choropleth Map with Datawrapper", " Choropleth Map with Datawrapper In addition to creating wonderful interactive charts, Datawrapper lets you create stylish and interactive point and polygon maps. In this section, we will create a choropleth map of average home values in US states in 2019 according to Zillow data, as shown in Figure 6.13. We calculated average 2019 prices for 50 US states and DC, and put them in a spreadsheet, which you can download for this tutorial. Figure 6.13: This choropleth map is created in Datawrapper Create a New Choropleth Map Sign in to your Datawrapper account and click New Map in the header. Datawrapper will offer a choice of a Choropleth, Symbol, and Locator maps, as shown in Figure 6.14. Go ahead and choose choropleth. Figure 6.14: Sign in to Datawrapper, click New Map, and choose Choropleth. Datawrapper splits the process of creating a map into four steps. In step one, you need to choose your map boundaries. Datawrapper has a wide collection of most common geographical boundaries, including states and counties and municipalities for most countries in the world, and zip code and census tract areas for the United States. But you are not limited to the boundaries that Datawrapper already has. You can also upload your own custom geographies as a TopoJSON or GeoJSON file, and you will learn more about that in the Convert to GeoJSON section of chapter 12. Because we are mapping average home prices by US state, choose United States &gt; States, as shown in Figure 6.15, and hit Next to go to step 2. Figure 6.15: To map home prices by US state, choose appropriate boundaries. In the second step, you can attach data to the chosen boundaries. You can set values manually in the interactive table that Datawrapper offers. This is fine for several values, but is too time-consuming for all 50 values (District of Columbia is not a US state, so is not present in the boundaries). Instead, click Import your dataset button under the table. Datawrapper will warn you that you need either Names (full state names, such as Connecticut), or ISO-Codes (the standardized two-letter codes for the state, such as CT for Connecticut) columns in order to perform merging. Since the dataset that we prepared contains both columns (titled State and StateAbbr), you can confidently press the Start import button. In the following window, you can either copy/paste values from the spreadsheet, or upload a CSV file. We recommend uploading a file, so click the link and choose the file us-states-home-values-zillow-2019.csv. The table will then get populated, and Datawrapper will ask for help identifying the relevant column with geographical names. Make sure your Matched as ISO-Codes tooltip is blue above the StateAbbr column, scroll down and click Next, as shown in Figure 6.16. Figure 6.16: Tell Datawrapper which column contains geography names (ISO-Codes of states). In a similar fashion, you will then be asked to identify a column that contains values to be mapped. Make sure it is HomeValue2019 that is Matched As Values. Style and publish your map When finished uploading data, go to step 3 to begin visualizing. Start with the Refine tab and choose a diverging color palette, from reds to blues. Make sure your “middle” color value corresponds to the state with the median home price by choosing min/median/max value from the Stops dropdown, as shown in Figure 6.17. Figure 6.17: Choose red/blues divergent color scheme, and make sure to match median with the neutral (middle) value. When finished with colors, scroll down to Tooltips section and click Customize tooltips button. In a popup window, set Title to the state name and Body to the average home value, as shown in Figure 6.18. The easiest way to do this is to click on column names in the upper-right corner of the popup window, where all available names are listed, which is circled in Figure 6.18. Note that references to variables are put in double curly brackets ({{ ColumnNameGoesHere }}). Make sure your dollar symbol ($) in outside of the curly brackets. Click Save, and hover over the map to make sure your tooltip displays the state name and the average home price. Figure 6.18: To reference values from the spreadsheet, add column names in double curly brackets. You can now move to the Annotate tab and set values for the map’s title and description, which is the line just below the title. Make sure you reference Zillow Data as data source. Being transparent about your sources and methods adds credibility to your work. In the final, fourth step, you can publish the chart and copy the iframe code that Datawrapper generated for you. In the following section, we will create a point map inside Socrata data platform. "],
["filtered-point-map-socrata.html", "Filtered Point Map with Socrata", " Filtered Point Map with Socrata Socrata is a database service that is used by government agencies, cities and countries to make open data available to the public. It offers user-friendly ways to view, filter, and export data. In addition, the Socrata platform includes built-in support to create interactive charts and maps, which can be embedded in other websites (including your own). One advantage of creating data visualizations directly on an open data platform is that the chart or map is linked to the data repository. For example, if the Socrata platform administrator updates the data table, then a Socrata dataviz based on that data will be automatically updated, too. This may be especially useful for “live” data that is continuously updated by agency administrators such as fires, crimes, and property data. In this section, we will build an interactive point map of hospitals in Texas using General Hospital Information dataset by Medicare, which you can see in Figure 6.19. Figure 6.19: In this tutorial, we will build a point map of hospitals in Texas using Socrata. Generally, in order to create a map in Socrata, you need to be a registered user, and the dataset you wish to visualize has to contain a column with location data. This is not just an address column (such as 3500 Gaston Avenue, Dallas, TX), but a geocoded column that contains latitude and longitude values. Sign Up for Socrata Account Navigate to Data.Medicare.gov click Sign In button in the upper-right corner. Scroll down to Sign Up link. Follow the instructions, including setting up two-step authentication, to create a free account. Note: You can still practice creating a map in Socrata without being logged in. You won’t be able to save or share it, however. Once you have an account, log in using your credentials. Navigate to your profile by clicking your username in the upper-right corner and make sure you Accept Terms and Conditions, otherwise you won’t be able to save your draft map. This username and password are only valid for Data.Medicare.gov, not other websites that use Socrata. Create Your First Socrata Point Map Navigate to the Hospital General Dataset, and in the menu on the right-hand side choose Visualize &gt; Launch New Visualization, as shown in Figure 6.20. This will open up a Configure Visualization studio where you can create the map. Figure 6.20: Go to Visualize &gt; Launch New Visualization. In the top menu, click Map (globe icon between a scatter chart icon and a calendar). You will see an updated layout of the studio, with the map in the middle, and Map Layers and Map Settings items in the side menu on the left. Socrata was able to determine which column contains geospatial value, and automatically set Geo Column value to Location in the Layer List menu. By default, points are clustered (grouped together), so instead of seeing individual hospital locations, you see bubbles with numbers (such as 12 in Alaska). Let’s first select only hospitals that are located in the southern state of Texas. To do so, go to Filters &gt; Add filter. The dropdown menu lists all columns (or fields) of the dataset, where we should choose State. In the newly appeared State dropdown, choose TX (for Texas) as shown in Figure 6.21, and scroll down and click Apply. Socrata should zoom in on the map and center on Texas. Close Filters window to free screen space. Figure 6.21: Select Texas as the only value for State field. Let’s now disaggregate the map so that we can see individual hospitals instead of clusters. Go to Map Settings &gt; Cluster, and bring the Stop Clustering at Zoom Level slider to 1, as shown in Figure 6.22. You will see the map now shows individual points. Figure 6.22: To show individual points instead of clusters, set Stop Clustering at Zoom Level to 1. In the same accordion menu, change Basemap &gt; Type to Dark to bring the map a fashionable 2020 look. In General, set Title to Texas Hospitals, and hide data table below the map by unchecking the Show data table below visualization box. Under Map Controls, uncheck Show Search Bar and Show Locate Button to get rid of unnecessary elements. Feel free to experiment with other settings as well. Now, let’s return back to Map Layers menu and choose our Hospitals General Information point layer. You can notice that in Data Selection accordion menu, Resize Points by Value is grayed out. That is because the dataset doesn’t contain columns with continuous variables that can be transformed to point sizes. Instead, we can use Style by Value option to classify categorical points. The dataset contains multiple variables that can be effectively visualized, such as Hospital Type, Emergency Services (a yes/no category), Mortality national comparison and others. Let’s stick with Hospital Type, as is illustrated in Figure 6.23. Figure 6.23: Let’s display different types of hospitals in different colors. If you look at the bottom-right corner of the map, you should notice a minimized Legend control. Click on it to see what each color represents. Change the color palette (in Color menu) from Categorical 1 to Categorical 2, which includes a wider range of unique colors. You can also use Custom… item to set individual colors, as well as change the order of categories in the legend. To change what is shown in tooltips when you hover or click on points, go to Flyout Details, and set Flyout Title to Facility Name, adding city and phone number as additional flyout values, as is shown in Figure 6.24. Figure 6.24: To edit tooltip information, use Flyout Details menu item. At this point you should have a fully-functional interactive map showing all hospitals in Texas, colored according to their type. Before you can share it, you need to save it as a draft, and publish. Save Draft and Publish In the lower-right corner, click Save Draft button. Give your map a name, and hit Save. The gray ribbon at the top will tell you it is still a draft, and you can go ahead and Publish… it. Now you can embed the map on your website as an iframe. To do so, click the Share button in the upper-right side of your map (see Figure 6.25), and copy the generated code from Embed Code text area (Figure 6.26). Learn more in Chapter 8: Embed on Your Web. Figure 6.25: Click Share button to bring up Share and Embed window. Figure 6.26: Copy iframe code to embed this map in another website. Limitations of Socrata But there are limitations to creating your chart or map on an open data repository platform. First, if the agency stops using the platform, or changes the structure of the underlying data, your online map (or chart) may stop functioning. Second, you are generally limited to using datasets and geographic boundaries that already exist on that platform. If these limitations concern you, a simple alternative is to export data from the open repository (which means that any “live” data would become “static”), and import it into your preferred dataviz tool, such as Tableau. A second, more advanced alternative, is to learn to pull live data from Socrata using an API (Application Programming Interface). That requires coding skills that are beyond the scope of this book. Visit the official documentation to learn more about Socrata API. "],
["tableau-polygon.html", "Polygon Map with Tableau Public", " Polygon Map with Tableau Public In the previous chapter, we looked at using Tableau Public to build scatterplots and filtered line charts. Tableau can also be used to create point and polygon maps. In this tutorial, we will create a choropleth map of military spending per country as percentage of gross dometic product as shown in Figure 6.27. Remember that choropleth maps work best when they show relative, not absolute numbers. Displaying total spending per country is a bad idea, as bigger countries tend to have larger populations and as a result larger values for a lot of measures, including military spending. Figure 6.27: This choropleth map is made in Tableau Public To create maps in Tableau, you do not always need geospatial files. Tableau can recognize of a lot of locations, including boundaries for countries and territories, counties within countries, states, US zip codes, airport codes, city locations, and some others. A simple spreadsheet that references these locations can suffice. In this tutorial, we will rely on Tableau to automatically recognize country names. If you require custom boundaries or points (such as town names in your local language), take a look at Create Tableau Maps from Spatial Files article from the official Tableau documentation. Before we begin, download the 2018 data that we obtained from the World Bank. Create a Choropleth Map in Tableau Launch Tableau. In Connect section on start up, choose Text file, and select military-spending-2018.csv. From Data Source tab, inspect the dataset contents. It contains four columns: Country Name, which includes countries and territories defined by the World Bank, the three-digit Country Code, Indicator Name (same for all rows), and percent value, as shown in Figure 6.28. Notice that some values are set to null (not available). Figure 6.28: When finished inspecting the connected file, go to Sheet 1. In the variables list on the left, notice how Tableau generated Latitude and Longitude fields based on country names and country codes (by the way, you only need one or the other, not both). Drag and drop Longitude to Columns, and Latitude to Rows, as shown in Figure 6.29. You should see that the chart area shows an empty map of the world (if not, double-check that Latitude is indeed in Rows, not Columns). In Marks box, change Automatic to Map, and drag Country Name variable to the Size box of the Marks card. You will see that country outlines turned blue. Figure 6.29: Drag and drop variables to the right places. We want colors to represent military spending values, so drag Value variable to the Color box of the Marks card. You should now see a proper choropleth map. Places like Greenland and Libya do not have available values, but they are still painted with the lightest color, which is misleading. To remove countries with null values from the map, drag Values to the Filters card. A popup window will ask you how you want to filter, just leave everything unchanged. This will leave the whole range of values, and exclude null values (see the checkbox in the lower-right corner of the Filter window in Figure 6.30). Figure 6.30: Filter values to remove countries with no data from display. You can change the color scheme by clicking the Color box of the Marks card, and then Edit colors. Change the palette to Reds, and make it stepped rather than continuous, as shown in Figure 6.31. Figure 6.31: Change the color scheme to Reds with 5 steps. You may notice the tooltip calls values Value when hovering over countries. Click the Tooltip box of the Marks card to change text to Military spending, and add a percentage sign after the value itself, as shown in Figure 6.32. Make sure not to change values between &lt; and &gt;, as these are references to variables. Figure 6.32: Change tooltip text to make it more user-friendly. And finally, let’s add a proper title to the map. Double-click the default Sheet 1 name to bring up the Edit Title window, and change the name of your chart to a more meaningful Military Spending as % of GDP (2018). Publish Your Tableau Map Once you are ready to publish and share the map, go to File &gt; Save to Tableau Public. In the pop-up window, log in to your account if requested. Give it a title, such as Military Spending, and click Save. Summary In this chapter, we looked at free mapping platforms to create simple point and polygon maps. Google My Maps is a good choice for point maps that can be created in collaboration with others. If the data you are interested in lives on Socrata platform, you might be able to create a point map within the platform itself, and embed it as an iframe in your own website. Tableau is another very powerful tool to build and share polygon and point maps. In reviewing all these tools, we only scratched the surface and showed simple examples to get you started quickly. All platforms allow layering data to create powerful exploration mapping visualizations. None of the platforms required special geospatial data, as all were smart enough to perform geocoding and know the boundaries and coordinates of objects given to them. In Chapter 12, we will talk more about geospatial data, how it can be obtained, stored, modified, and shared. "],
["table.html", "Chapter 7 Table Your Data", " Chapter 7 Table Your Data You might be surprised that a data visualization book which emphasizes charts and maps also includes a chapter on creating tables. We don’t normally think about data tables as a type of visualization. But depending on your data and the story you wish to tell about it, sometimes a table is the best way to present detailed information. Tables make sense when readers want to look up a specific row of data that’s highly relevant to them, such as their local community or an organization they belong to, which can be too hard to identify inside a large chart or map. Also, tables work best when readers want to precisely compare individual values to one another, but not necessarily to the rest of the dataset. Finally, tables may be more appropriate than charts when there is no broad visual pattern you wish to emphasize, and more appropriate than maps when there is no spatial pattern to highlight. Before you start designing a chart or map, consider whether it makes more sense to create a table. In this chapter, you’ll learn about table design principles and how to use Datawrapper, a tool we introduced in Chapter 5: Chart Your Data and Chapter 6: Map Your Data, to create an interactive table. Interactive tables have many advantages over static tables when you publish your information online rather than print-only. First, interactive tables allow readers to search by keyword for specific details that interest them, which is vital when you present long tables with lots of rows. Second, readers can sort interactive tables in ascending or descending order for any column, which enables them to quickly scan those near the top or bottom of a long list. Finally, you’ll also learn how to insert sparklines, or tiny charts that visually summarize data trends in each row, and automatically place them inside your Datawrapper table. Sparklines blend the best qualities of tables and charts by making it easier for readers to visually scan for patterns while skimming down the rows and columns of your data table. Later in Chapter 8: Embed On Your Web, you’ll learn how to integrate your interactive table into your website. "],
["table-design.html", "Table Design Principles", " Table Design Principles Let’s begin with some principles of good table design, similar to how we learned about chart design in chapter 5 and map design in chapter 6. Jonathan Schwabish, an economist who specializes in creating policy-relevant data visualizations, offers his advice in recent publications about creating tables that communicate well with multiple audiences.7. Here’s a summary of several of his key points, which also appear in Figure 7.1. Make column headers stand out above the data. Use light shading to separate rows or columns. Left-align text and right-align numbers for easier reading. Avoid unnecessary repetition by placing labels only in the first row. Group and sort data to show meaningful patterns. Figure 7.1: A sample table that illustrates selected design principles. In addition, Schwabish and others recommend using color to highlight key items or outliers in your data, and we’ll return to this theme in Chapter 14: Tell Your Data Story. Several of these table design principles are built into Datawrapper, the tool we feature in the next section. Jon Schwabish, “Thread Summarizing ’Ten Guidelines for Better Tables’,” Twitter, August 3, 2020, https://twitter.com/jschwabish/status/1290323581881266177; Jonathan A. Schwabish, “Ten Guidelines for Better Tables,” Journal of Benefit-Cost Analysis 11, no. 2: 151–78, accessed August 25, 2020, https://doi.org/10.1017/bca.2020.11; Jonathan Schwabish, Better Data Visualizations: A Guide for Scholars, Researchers, and Wonks (Columbia University Press, 2021), https://cup.columbia.edu/book/better-data-visualizations/9780231193115↩︎ "],
["datawrapper-table.html", "Datawrapper Table with Sparklines", " Datawrapper Table with Sparklines In this tutorial, you’ll learn how to create an interactive table with sparklines, which makes it easier to spot different changes in this life expectancy dataset from 1960 to 2018 for over 195 nations around the world. While it’s possible to present this data in a filtered line chart as shown in chapter 5, it would be difficult for readers to spot differences when shown over 180 lines at the same time. Likewise, it’s possible to present this data in a choropleth map as shown in chapter 6, but it would be hard for readers to identify data for nations with smaller geographies compared to larger ones. In this case, we’ll blend sparklines for longitudinal data trends into our interactive table to help readers spot subtle differences in changes over time for life expectancy by nation, categorized by continent. This tutorial was adapted from the Datawrapper training materials and gallery of examples, which we highly recommend. To simplify this tutorial, we downloaded World Bank data on life expectancy at birth from 1960 to 2018 by nation, one of the open data repositories we listed in Chapter 3: Find and Question Your Data. Then we cleaned up the data, such as removing nations with 5 or fewer years of data reported over a half-century, as described in the Notes. Using the VLookup spreadsheet method from chapter 2, we merged in columns of two-letter nation codes and continents from Datawrapper. We also created two new columns: one named Life Expectancy 1960 (intentionally blank for the sparkline to come) and Difference (which calculates the difference between the earliest and the most recent year of data available, in most cases from 1960 to 2018). See the Notes tab for more details. Open our cleaned-up World Bank data on life expectancy at birth, 1960 to 2018, in this Google Sheet. Go to Datawrapper and select New Table. You are not required to sign in, but if you wish to save your work, we recommend that you create a free account. In the Upload Data screen, select that you wish to import your data from a Google Spreadsheet. Paste in the web address of our cleaned-up Google Sheet and click Proceed. Inspect the data in the Check and Describe screen. Make sure that the First row as label box is checked, then click Proceed. In the Visualize screen, under Customize Table, check two additional boxes: Make Searchable (so that users can search for nations by keyword) and Stripe Table (to make lines more readable). Let’s use a special Datawrapper code to display tiny flags before each country’s name. In the Nation column, each entry begins with a two-letter country code, surrounded by colons, followed by the country name, such as :af: Afghanistan. We created the Nation column according to the Combine Data into One Column section of Chapter 4: Clean Up Messy Data. To learn more flag icons, read the Datawrapper post on this topic and their list of country codes and flags on GitHub. In the Visualize screen, under Customize columns, select the third line named Nation. Then scroll down and push the slider to Replace country codes with flags, as shown in Figure 7.2. Figure 7.2: Customize the Nation column and push slider to replace codes with flags. Let’s hide the first two columns, since they’re no longer necessary to display. In the Visualize screen under Customize columns, select the Name column, then scroll down and un-check the boxes to Show on desktop and mobile. Repeat this step for the Code column. A “not visible” symbol (an eye with a slash through it) appears next to each customized column to remind us that we’ve hidden it. Now let’s color-code the Continent column to make it easier for readers to sort by category it in the interactive table. In the Visualize screen under Customize columns, select the Continent column, then scroll down and push the slider to select Color cells based on categories. In the drop-down menu, select the column Continent, and click on the Background: customize colors button. Select each continent and assign them different colors, as shown in Figure 7.3. Figure 7.3: Customize the Continent column and push slider to color cells based on categories. Now let’s prepare our data for sparklines, or tiny line charts, to visually represent change in the Life expectancy 1960 column, which we intentionally left blank. Before you begin, you must change this column from textual data (represented by the A symbol in the Customize columns window) to numerical data (represented by the # symbol). At the top of the screen, click on the 2. Check and Describe arrow to go back a step. (Datawrapper will save your work.) Now click on the table header to edit the properties for column E: Life Expectancy 1960. On the left side, use the drop-down menu to change its properties from auto (text) to Number, as shown in Figure 7.4. Then click Proceed to return to the Visualize window. Figure 7.4: Go back to Check &amp; Describe to change the properties of column E from textual to numerical data. To create the sparklines, in the Visualize screen under Customize columns, select all of the columns from Life expectancy 1960 down to 2018. To select all at once, click on one column, then scroll down and shift-click on the next-to-last column. Then scroll down the page and click the Show selected columns as tiny chart button, as shown in Figure 7.5. These steps will create the sparklines in the column, renamed Life expectancy 1960–2018, as shown in Figure 7.6. Tip: By design, we initially named this column Life expectancy 1960, because when we selected several columns to create sparklines, the tool added –2018 to the end of the new column name. Figure 7.5: Shift-click to select all columns from Life expectancy 1960–2018 down to 2018, then click on Show selected columns as tiny chart. Let’s add one more visual element: a bar chart to visually represent the Difference column in the table. In the Visualize screen under Customize columns, select Difference. Then scroll down and push the slider to select Show as bar chart, as shown in Figure 7.6. Figure 7.6: Select the Difference column and Show as bar chart. In the Visualize screen, click the Annotate tab to add a title, data source, and byline. Click on Publish &amp; Embed to share the link to your visualization, which is also shown in Figure 7.7. In the interactive version of the table, readers can explore the data in several ways: Search by keyword to display a specific nation or an entire continent. Sort each column in ascending or descending order. Scroll through pages of sparklines to quickly identify differences that would be hard to spot in the raw data table. Overall, life expectancy gradually rises in most nations, but a few display “dips” that stand out in the tiny line charts. For example, Cambodia and Vietnam both experienced a significant decrease in life expectancy, which corresponds with the deadly wars and refugee crises in both nations from the late 1960s to the mid-1970s. Sparklines help us to visually detect patterns like these, which anyone can investigate further by downloading the raw data through the link at the bottom of the interactive table. Figure 7.7: Explore the interactive table with sparklines. Also on the Publish &amp; Embed screen, you’ll see a blue Publish chart button to obtain the embed code to place your visualization on the web, which you’ll learn about in Chapter 8: Embed On Your Web. Summary In this chapter you reviewed principles about table design, and how to create an interactive table with sparklines using Datawrapper. In the next chapter, you’ll learn how to embed interactive charts, maps, and tables on your website so that readers can explore your data and engage with your stories. "],
["embed.html", "Chapter 8 Embed On Your Web", " Chapter 8 Embed On Your Web TODO: Reorganize and rewrite chapter After you create a chart or map, how do display it inside your website as an interactive visualization? Our goal is not a static picture, but a live chart or map that users can explore. This is an important question for beginners, since data visualizations are not valuable unless you can control where and how your work appears. This chapter walks you through the key steps. First, you need to own a website that supports iframe codes (which we’ll explain below). If you do not have a website that supports this, then follow this quick tutorial to Create a simple web page with GitHub Pages. Even if you already have a website, still do this tutorial, because it introduces a tool used many times in this book. Second, you need to copy or create an iframe code from your chart or map. An iframe is one line of HTML code with instructions on how to display a web page from a specific address (called a URL). A simple iframe looks like this: &lt;iframe src=\"https://handsondataviz.org/embed/index.html\"&gt;&lt;/iframe&gt; No coding skills are necessary. See these easy-to-follow examples: -Copy iframe from a Google Sheets chart -Convert a link into an iframe Finally, you need to paste (or embed) the iframe code inside your website. Like a picture frame, an iframe allows you to display one web page (your data visualization) inside another web page (your personal website). But unlike a picture frame, where the image is static, an iframe makes content interactive, so visitors can explore the chart or map on your site, even though it may actually be hosted on an entirely different website. Go to this third tutorial, which combines the two steps above, called Embed Iframe in GitHub Pages. See more tutorials in this chapter to copy iframes from other visualization tools (such as Tableau Public and embed them in other common websites (such as WordPress, etc.) ** TO DO: add more tutorials and links ** "],
["github-pages.html", "Create a Simple Web Page with GitHub Pages", " Create a Simple Web Page with GitHub Pages Question: After you create an interactive chart or map, how do you embed the live version in a website that you control? The full answer requires three steps: Create a web page that supports iframe codes Copy or create an iframe code from your visualization Embed (or paste) the iframe code into your web page This tutorial focuses on the first step. If you don’t already have your own website, or if you are not sure whether your site supports iframe codes, then follow the steps below. We will create a simple web page with a free and friendly tool called GitHub http://github.com, and host it on the public web with the built-in GitHub Pages feature. For steps 2 and 3, see the Copy iframe from Google Sheets tutorial and the Embed iframe in GitHub Pages tutorial in this chapter. Tool review: GitHub http://github.com is a versatile tool that can be used to create simple web pages. Pros: Free and easy-to-learn tool to edit and host simple pages on the public web. All steps below can be completed in your web browser. Cons: All work on GitHub is public by default. Private repositories (folders) require payment. New users sometimes confuse the links for code repositories versus published web pages. Video Sign up for free GitHub account, then sign in, at http://github.com. Create a new repository (also called a “project” or similar to a “folder”). Name your repository (or “repo”), and select Initialize with a README file. Optional steps: add a description and select a license. Scroll down and click the green button to Create your repo, which will appear in a new browser tab, with this URL format: https://github.com/YOUR-USERNAME/YOUR-REPO-NAME In your GitHub repo, click on Settings, scroll down to GitHub Pages, select Master branch as your source, then Save. This publishes the code from your repo to the public web. Hint: Do NOT select Theme Chooser for this exercise. It will create additional files that will interfere with displaying an iframe in your README.md file. When the Settings page refreshes, scroll back down to GitHub Pages to see the new link to your published website, which will appear in this format: https://YOUR-USERNAME.github.io/YOUR-REPO-NAME Right-click and Copy the link to your published web site. At the top of the page, click on the repo name to return to the main level. Click the README.md file to open it in your browser, and click the pencil symbol to edit it. Inside your README.md file, paste the link to your published web site, and type any text you wish to appear. The .md extension refers to Markdown, an easy-to-read computer language that GitHub Pages can process. Scroll down and click the green Commit button to save your edits. When your GitHub repo page refreshes, click on the new link to go to your published web site. BE PATIENT! Your new site may not appear instantly. Refresh the browser every 10 seconds. You may need to wait up to 1 minute for a new site to appear the first time, but later changes will be much faster. Remember that GitHub Pages is designed to create simple web pages and sites. See other web publishing tools mentioned in this chapter to create more sophisticated web sites. "],
["iframe-google-sheets.html", "Copy an iframe code from a Google Sheets interactive chart", " Copy an iframe code from a Google Sheets interactive chart Question: After you create an interactive chart or map, how do you embed the live version in a website that you control? The full answer requires three steps: Create a web page that supports iframe codes Copy the iframe code from your visualization Embed (or paste) the iframe code into your web page This tutorial focuses on the second step, and shows how to publish a Google Sheets interactive chart, and copy its iframe code. Details may differ for other visualization tools, but the general iframe concept will be similar to most cases. For steps 1 and 3, see the Create a Simple Web Page with GitHub Pages tutorial and the Embed iframe in GitHub Pages tutorial in this chapter. Tutorial Create a Google Sheets chart, which requires a free Google Drive account. Learn more in the Google Sheets Charts tutorial in this book. Click the drop-down menu in the upper-right corner of the interactive chart and select Publish chart. Click OK on next screen. Screenshot: Drop-down menu to publish a Google Sheets chart Select the Embed tab, select the Interactive version, and click the blue Publish button. If you make changes to the chart, they will continue to be published to the web automatically, unless you click the Stop button or checkbox at the bottom. Screenshot: Publish to the web for a Google Sheets chart Copy the iframe embed code. Screenshot: Copy the iframe code from a Google Sheets chart No coding skills are necessary, but it helps to be code-curious. This iframe is a line of HTML code that contains these instructions: iframe tags to mark the beginning and end width and height: to display your chart in a second site, in pixels seamless frameborder: “0” means no border will appear around the chart in the second site scrolling: “no” means the chart will not include its own web scrolling feature src: the web address (or URL) of the visualization to be displayed in the second site See the next tutorial in this chapter, Embed iframe in GitHub Pages, to learn how to paste the iframe into a simple web page. Or see related tutorials in this chapter to embed an iframe in other common web sites. "],
["link-to-iframe.html", "Convert a Weblink into an Iframe", " Convert a Weblink into an Iframe After you publish your data visualization to the web, how do you convert its weblink (or URL) into an iframe, to embed in your personal website? The answer depends: did you publish your visualization as a code template on GitHub Pages? Or did you publish it using a drop-and-drag tool such as Google Sheets or Tableau Public? Published with a code template on GitHub Pages If you published your visualization from a code template (such as Leaflet or Chart.js) with GitHub Pages, follow these easy steps: Copy the URL of your published visualization on GitHub, which will be in this format: https://USERNAME.github.io/REPOSITORY Add iframe tags to the beginning and end, insert src= and enclose the URL inside quotation marks, like this: &lt;iframe src=\"https://USERNAME.github.io/RESPOSITORY\"&gt;&lt;/iframe&gt; Optional: Insert preferred width and height (in pixels by default, or percentages), like this: &lt;iframe src=\"https://USERNAME.github.io/RESPOSITORY\" width=\"90%\" height=\"400\"&gt;&lt;/iframe&gt; Go to the appropriate tutorial to embed your iframe in your personal website: Embed an iframe in GitHub Pages Embed an iframe in WordPress.org Published with Google Sheets or Tableau Public Or, if you published your visualization using a drop-and-drag tool, see these tutorials: Copy an iframe code from a Google Sheets interactive chart Embed Tableau Public on your Website "],
["iframe-github.html", "Embed an Iframe in GitHub Pages", " Embed an Iframe in GitHub Pages Question: After you create an interactive chart or map, how do you embed the live version in a website that you control? Here’s the full three-step answer that combines lessons from the Embed on the Web chapter introduction and the two previous tutorials: First, create a web page that supports iframe embed codes. If you don’t know what that means or don’t yet have a personal website, go back to the previous tutorial, Create a Simple Web Page with GitHub Pages, or see the video and step-by-step instructions below. Second, copy or create an iframe code from your data visualization. Go back to the previous tutorial, Copy an iframe code from a Google Sheets interactive chart, or see the video and step-by-step instructions below. Third, embed (or paste) the iframe code into your website. The video and instructions below show how to paste an iframe from a Google Sheets interactive chart into a simple web page with GitHub Pages. Try it: The goal is to embed the iframe code from a Google Sheets interactive chart, which resides on a Google web server, into your GitHub Pages web site. The result will be similar to the one below: TODO: Convert to code-chunk iframe: https://docs.google.com/spreadsheets/d/1YgBWYm9nTGlCuyqSwU3SDb7xk-SMSPgjfYq5iLqL0nQ/pubchart?oid=200651442&amp;format=interactive [Video](https://youtube.be/enjhlnqaXOE] Sign up for free GitHub account, then sign in, at https://github.com. Create a new repository (think of it as a folder that contains your project). Name your repository (or “repo”), and select Initialize this repository with a README. Optional steps: add a description and select a license. Scroll down and click the green button to Create your repo, which will appear in a new browser tab, with this URL format: https://github.com/YOUR-USERNAME/YOUR-REPO-NAME In your GitHub repo, click on Settings tab, scroll down to GitHub Pages, select master branch as your Source, then Save. This publishes the code from your repo to the public web. When the Settings page refreshes, scroll back down to GitHub Pages to see the new link to your published website, which will appear in this format: https://YOUR-USERNAME.github.io/YOUR-REPO-NAME Right-click and Copy this link to your published web site. At the top of the page, click on the repo name to return to the main level. Click the README.md file to open it in your browser, and click the pencil symbol in the upper right corner to edit it. Inside your README.md file, paste the link to your published web site, and type any text you wish to appear. The .md extension refers to Markdown, an easy-to-read markup language that GitHub Pages can process and display as HTML. Go to a data visualization you have created, such as a Google Sheets chart, select Publish &gt; Embed, and copy the iframe code. This line of HTML code displays the interactive visualization website inside your personal website. Scroll down and click Commit to save your edits. When your GitHub repo page refreshes, click on the new link to go to your published web site. BE PATIENT! Your new site may not appear instantly. Refresh the browser every 10 seconds. You may need to wait for a few minutes for a new site to appear the first time, but later changes will be much faster. Important: A published README.md file will display an HTML iframe code, unless you add other HTML files (such as index.html) to your repository. Remember that GitHub Pages is designed to create simple web pages and sites. See other web publishing tools mentioned in this chapter to create more sophisticated web sites. "],
["iframe-wordpress.html", "Embed an Iframe on WordPress.org", " Embed an Iframe on WordPress.org TODO: rewrite this tutorial to merge the two versions (top and bottom) then update all links and check all code tags To embed one web page (the data visualization) inside a second web page (the organization’s website), we use a simple HTML code known as iframe. (Read more about the iframetag at W3Schools.) The general iframe concept works across many data visualization tools and many websites: - Copy the embed code or URL from your dataviz website - Paste (and modify) the code as an iframe in your destination website To embed your dataviz in a self-hosted Wordpress.org site, the [iframe plugin] (http://wordpress.org/plugins/iframe/) must be installed and activated. This plugin allows authors to embed iframe codes inside posts/pages, in a modified “shortcode” format surrounded by square brackets. Without the plugin, self-hosted WordPress.org sites will usually “strip out” iframe codes for all users except the site administrator. I have already installed and activated the iframe plugin on my site, and the Dashboard view looks like this: Note that most WordPress.com sites do NOT support an iframe embed code. But details vary, so read and experiment with the examples that follow. To embed the iframe in a WordPress.org site, the iframe plugin must be installed, as explained in the Embed with iframe on WordPress.org chapter. TO DO fix self-reference Log into your Wordpress.org site and create a new post. In the editor window, switch from the Visual to the Text tab, which allows users to modify the code behind your post. Paste the iframe code from your interactive dataviz. Initially, the code you pasted includes HTML iframe tags at the front &lt;iframe... and the end ...&gt;&lt;/iframe&gt;, which looks like this: &lt;iframe width=\"600\" height=\"371\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/1fwnl5hvkkwz-YDZrogyGnx274BqmozGlIeXyjJ2TKmE/pubchart?oid=462316012&amp;amp;format=interactive\"&gt;&lt;/iframe&gt; Modify the front end of the iframe code by replacing the less-than symbol ( &lt; ) with a square opening bracket ( [ ). Modify the back end by erasing the greater-than symbol ( &gt; ) and the end tag ( ). Replace the back end with a square closing bracket ( ] ). Your modified code should look like this: [iframe width=\"600\" height=\"371\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/1fwnl5hvkkwz-YDZrogyGnx274BqmozGlIeXyjJ2TKmE/pubchart?oid=462316012&amp;amp;format=interactive\"] Click Preview or Publish/View Post to see how it appears on the web. If desired, continue to modify the iframe code to improve the display of your dataviz on your website. For example, the initial code was 600 pixels wide (width=“600”). To display the dataviz across the full width of your website, change this part of the code to 100% (width=“100%”). The goal is to embed an interactive chart inside your website, so that users can explore the data. This tutorial displays a very basic chart to simplify the process, and the end result will appear like the one below. Try it. TODO: Convert to code-chunk iframe: https://docs.google.com/spreadsheets/d/1fwnl5hvkkwz-YDZrogyGnx274BqmozGlIeXyjJ2TKmE/pubchart?oid=462316012&amp;format=interactive "],
["iframe-tableau.html", "Embed Tableau Public on your Website", " Embed Tableau Public on your Website Question: After learning how to create an interactive data visualization with Tableau Public in this book, how do I embed it on my website? Answer: Tableau Public supports two embedding methods, and your choice depends on your type of website. Embed code: if you can paste directly into an HTML web page Convert Link to iframe: to paste into WordPress.org, Wix, SquareSpace, Weebly, and many other web platforms Try it: Both methods produce an embedded visualization like the one below. Float your cursor over points to view data details. TODO: convert to code-chunk iframe: https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true A) Embed code method for HTML web pages Use this method if you can paste HTML and JavaScript code directly into a website with HTML pages. Go to the public web page of any Tableau Public visualization, such as this sample: https://public.tableau.com/profile/jackdougherty#!/vizhome/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1 Before you begin the embed process, click the upper-right Edit Details button to make any final modifications to the title or toolbar settings. Click the bottom-right Share button, click inside the Embed Code field, and copy its contents. A typical embed code is a long string of HTML and JavaScript instructions to display the visualization. Screenshot: Edit and Share buttons in Tableau Public web page Open an HTML page on your website and paste the embed code in the body section. Below is an example of a sample Tableau Public embed code pasted between the body tags of a simple HTML page. TODO: find a way to replace this triple backtic code snippet, since it may throw errors into Markdown output. &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;sample web page&lt;/title&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&#39;tableauPlaceholder&#39; id=&#39;viz1489158014225&#39; style=&#39;position: relative&#39;&gt;&lt;noscript&gt;&lt;a href=&#39;https:&amp;#47;&amp;#47;handsondataviz.org&amp;#47;chart&amp;#47;scatter-chart-tableau&amp;#47;&#39;&gt;&lt;img alt=&#39;CT School Districts by Income and Grade Level Equivalents, 2009-13 &#39; src=&#39;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;CT&amp;#47;CTSchoolDistrictsbyIncomeandGradeLevels2009-13&amp;#47;Sheet1&amp;#47;1_rss.png&#39; style=&#39;border: none&#39; /&gt;&lt;/a&gt;&lt;/noscript&gt;&lt;object class=&#39;tableauViz&#39; style=&#39;display:none;&#39;&gt;&lt;param name=&#39;host_url&#39; value=&#39;https%3A%2F%2Fpublic.tableau.com%2F&#39; /&gt; &lt;param name=&#39;site_root&#39; value=&#39;&#39; /&gt;&lt;param name=&#39;name&#39; value=&#39;CTSchoolDistrictsbyIncomeandGradeLevels2009-13&amp;#47;Sheet1&#39; /&gt;&lt;param name=&#39;tabs&#39; value=&#39;no&#39; /&gt;&lt;param name=&#39;toolbar&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;static_image&#39; value=&#39;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;CT&amp;#47;CTSchoolDistrictsbyIncomeandGradeLevels2009-13&amp;#47;Sheet1&amp;#47;1.png&#39; /&gt; &lt;param name=&#39;animate_transition&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_static_image&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_spinner&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_overlay&#39; value=&#39;yes&#39; /&gt;&lt;param name=&#39;display_count&#39; value=&#39;yes&#39; /&gt;&lt;/object&gt;&lt;/div&gt; &lt;script type=&#39;text/javascript&#39;&gt; var divElement = document.getElementById(&#39;viz1489158014225&#39;); var vizElement = divElement.getElementsByTagName(&#39;object&#39;)[0]; vizElement.style.width=&#39;100%&#39;;vizElement.style.height=(divElement.offsetWidth*0.75)+&#39;px&#39;; var scriptElement = document.createElement(&#39;script&#39;); scriptElement.src = &#39;https://public.tableau.com/javascripts/api/viz_v1.js&#39;; vizElement.parentNode.insertBefore(scriptElement, vizElement); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; B) Convert Link to iframe method Use this method if you need to paste an iframe into common web authoring platforms (such as WordPress.org, Squarespace, Wix, Weebly, etc.), since these platforms typically do not support HTML and JavaScript code pasted directly into content. Go to the public web page of any Tableau Public visualization, such as this sample: https://public.tableau.com/profile/jackdougherty#!/vizhome/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1 Before you begin the embed process, click the upper-right Edit Details button to make any final modifications to the title or toolbar settings. Click the bottom-right Share button, click inside the Link field (NOT the Embed Code field), and copy its contents. Screenshot: Edit and Share buttons in Tableau Public web page A typical link will look similar to this example (scroll to right to see all): https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:embed=y&amp;:display_count=yes We need to edit the link to convert it into an iframe format. First, delete any code that appears after the question mark, to make it look like this (scroll to right to see all): https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1? Add this snippet of code to the end, to replace what you deleted above: :showVizHome=no&amp;:embed=true Now your edited link should look similar to this (scroll to right to see all): https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true Enclose the link inside an iframe source tag src= with quotes, to make it look similar to this (scroll to right to see all): src=\"https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true\" Add iframe tags for width and height in percentages or pixels (default), to make it look similar to this (scroll to right to see all): src=\"https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true\" width=\"90%\" height=\"500\" Hint: Insert 90% width, rather than 100, to help readers easily scroll down your web page Add iframe tags at the beginning and end, to make it look similar to this (scroll to right to see all): &lt;iframe src=\"https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true\" width=\"90%\" height=\"500\"&gt;&lt;/iframe&gt; Exceptions to the last step above. As described in the Embed iframe on WordPress chapter in this book, in a self-hosted WordPress.org site, with the iframe plugin, insert iframe brackets rather than HTML tags to make a shortcode like this (scroll to right to see all): [iframe src=\"https://public.tableau.com/views/CTSchoolDistrictsbyIncomeandGradeLevels2009-13/Sheet1?:showVizHome=no&amp;:embed=true\" width=\"90%\" height=\"500\"] Learn more: Embedding Tableau Public Views in iframe, Tableau Support page http://kb.tableau.com/articles/howto/embedding-tableau-public-views-in-iframes Summary TODO "],
["github.html", "Chapter 9 Edit and Host Code with GitHub", " Chapter 9 Edit and Host Code with GitHub In the first half of this book, you created interactive charts and maps on free drag-and-drop tool platforms created by companies such as Google and Tableau. These platforms are great for beginners, but their pre-set tools limit your options for designing and customizing your visualizations, and they also require you to depend upon their web servers and terms of service to host your data and work products. If these companies change their tools or terms, you have little choice in the matter, other than deleting your account and switching services, which means that your online charts and maps would appear to audiences as dead links. In the second half of this book, get ready to make a big leap—and we’ll help you through every step—by learning how to copy, edit, and host code templates. These templates are pre-written software instructions that allow you to upload your data, customize its appearance, and display your interactive charts and maps on a web site that you control. No prior coding experience is required, but it helps if you’re code-curious and willing to experiment with your computer. Code templates are similar to cookbook recipes. Imagine you’re in your kitchen, looking at our favorite recipe we’ve publicly shared to make brownies (yum!), which begins with these three steps: Melt butter, Add sugar, Mix in cocoa. Recipes are templates, meaning that you can follow them precisely, or modify them to suit your tastes. Imagine that you copy our recipe (or “fork” it, as coders say) and insert a new step: Add walnuts. If you also publicly share your recipe, now there will be two versions of instructions, to suit both those who strongly prefer or dislike nuts in their brownies. (We do not take sides in this deeply polarizing dispute.) Currently, the most popular cookbook among coders is GitHub, with more than 40 million users and over 100 million recipes (or “code repositories” or “repos”). You can sign up for a free account and choose to make your repos private (like Grandma’s secret recipes) or public (like the ones we share below). Since GitHub was designed to be public, think twice before uploading any confidential or sensitive information that should not be shared with others. GitHub encourages sharing open-source code, meaning the creator grants permission for others to freely distribute and modify it, based on the conditions of the type of license they have selected. When you create a brand-new repo, GitHub invites you to Choose a License. Two of the most popular open-source software licenses are the MIT License, which is very permissive, and the GNU General Public License version 3, which mandates that any modifications be shared under the same license. The latter version is often described as a copyleft license that requires any derivatives of the original code to remain publicly accessible, in contrast to traditional copyright that favors private ownership. When you fork a copy of someone’s open-source code on GitHub, look at the type of license they’ve chosen (if any), keep it in your version, and respect its terms. To be clear, the GitHub platform is also owned by a large company (Microsoft purchased it in 2018), and when using it to share or host code, you’re also dependent on its tools and terms. But the magic of code templates is that you can migrate and host your work anywhere on the web. You could move to a competing repository-hosting service such as GitLab, or purchase your own domain name and server space through one of many web hosting services. Or you can choose a hybrid option, such as hosting your code on GitHub and choosing its custom domain option, to display it under a domain name that you’ve purchased, just like the web version of this book is hosted on GitHub under our domain name, https://HandsOnDataViz.org. If we choose to move the code away from GitHub, we have the option to repoint our domain to a different web host. In the next section of this chapter, we will introduce basic steps to copy, edit, and host a simple Leaflet map code template on GitHub. Later you’ll learn how to create a new GitHub repo and upload code files. This chapter introduces GitHub using its web browser interface, which works best for beginners. Later you’ll learn about intermediate-level tools, such as GitHub Desktop and Atom Editor, to work more efficiently with code repos on your personal computer. If problems arise, turn to the Fix Common Mistakes section in the appendix. All of us make mistakes and accidentally “break our code” from time to time, and it’s a great way to learn how things work—and what to do when it doesn’t work! "],
["copy-leaflet.html", "Copy, Edit, and Host a Simple Leaflet Map Template", " Copy, Edit, and Host a Simple Leaflet Map Template Now that you understand how GitHub code repositories are like a public cookbook of recipes, which anyone can copy and modify, let’s get into the kitchen and start baking! In this section, we’ll introduce you to a very simple code template that creates an interactive map using Leaflet, an open-source code library that’s very popular with coders, journalists, businesses, and government agencies. Many people chose Leaflet because the code is freely available to everyone, relatively easy to use, and has an active community of supporters who regularly update it. But unlike drag-and-drop tools that we covered in previous chapters, such as Google My Maps or Tableau Public, Leaflet requires you to write (or copy and paste) several lines of code, which need to be hosted on a web server so that other people can view your map in their web browser. Fortunately, we can do all of these steps in our web browser on GitHub. This means you can do this on any type of computer: Mac, Windows, Chromebook, etc. Here’s an overview of the key steps you’ll learn about GitHub in this section: Make a copy of our simple Leaflet map code template Edit the map title, start position, background layer, and marker Host a live online version of your modified map code on the public web Your goal is to create your own version of this simple interactive map, with your edits, as shown in Figure 9.1. Figure 9.1: Create your own version of this simple interactive Leaflet map. Create your own free account on GitHub. It may ask you to do a simple quiz to prove you’re a human! If you don’t see a confirmation message in your email, check your spam folder. Tip: Choose a GitHub username that’s relatively short, and one that you’ll be happy seeing in the web address of charts and maps you’ll publish online. In other words, DrunkBrownieChef6789 may not be the wisest choice for a username, if BrownieChef is also available. After you log into your GitHub account in your browser, go to our simple Leaflet map template at https://github.com/HandsOnDataViz/leaflet-map-simple Click the green Use this template button to make your own copy of our repo, as shown in Figure 9.2. Figure 9.2: Click Use this template to make your own copy. On the next screen, your account will appear as the owner. Name your copy of the repo leaflet-map-simple, the same as ours, as shown in Figure 9.3. Click the green Create repository from template button. Figure 9.3: Name your copied repo leaflet-map-simple. Note: We set up our repo using GitHub’s template feature to make it easier for users to create their own copies. If you’re trying to copy someone else’s GitHub repo and don’t see a Template button, then click the Fork button, which makes a copy a different way. Here’s the difference: Template allows you to make multiple copies of the same repo by giving them different names, while Fork allows you to create only one copy of a repo because it uses the same name as the original, and GitHub prevents you from creating two repos with the same name. If you need to create a second fork of a GitHub repo, go to the Create a New Repo and Upload Files on GitHub section of this chapter. The upper-left corner of the next screen will say USERNAME/leaflet-map-simple generated from HandsOnDataViz/leaflet-map-simple, where USERNAME refers to your GitHub account username. This confirms that you copied our template into your GitHub account, and it contains only three files: LICENSE shows that we’ve selected the MIT License, which allows anyone to copy and modify the code as they wish. README.md provides a simple description and link to the live demo, which we’ll come back to later. index.html is the key file in this particular, because it contains the map code. Click on the index.html file to view the code, as shown in Figure 9.4. Figure 9.4: Click the index.html file to view the code. If this is the first time you’re looking at computer code, it may feel overwhelming, but relax! We’ve inserted several “code comments” to explain what’s happening. The first block you see is written in HyperText Markup Language (HTML) that tells web browsers the formatting to read the rest of the page of code. The second block instructs the browser to load the Leaflet code library, the open-source software that constructs the interactive map. The third block describes where the map and title should be positioned on the screen, written in a language called Cascading Style Sheet (CSS). The good news is that you don’t need to touch any of those blocks of code, so leave them as-is. But you do want to modify a few lines further below. To edit the code, click on the the pencil symbol in the upper-right corner, as shown in Figure 9.5. Figure 9.5: Click the pencil button to edit the code. Let’s start by making one simple change to prove to everyone that you’re now editing your map, by modifying the map title, which appears in the HTML division tag block around lines 21-23. In this line &lt;div id=\"map-title\"&gt;EDIT your map title&lt;/div&gt;, type your new map title in place of the words EDIT your map title. Be careful not to erase the HTML tags that appear on both ends inside the &lt; &gt; symbols. To save your edit, scroll to the bottom of the page and click the green Commit Changes button, as shown in Figure 9.6. Figure 9.6: Click the green Commit Changes button to save your edits. In the language of coders, we “commit” our changes in the same way that most people “save” a document, and later you’ll see how GitHub tracks each code commit so that you can roll them back if needed. By default, GitHub inserts a short description of your commit as “Update index.html”, and you have the option to customize that description when you start making lots of commits to keep track of your work. Also, GitHub commits your changes directly to the default branch of your code, which we’ll explain later. Now let’s publish your edited map to the public web to see how it looks in a web browser. GitHub not only stores open-source code, but its built-in GitHub Pages feature allows you to host a live online version of your HTML-based code, which anyone with the web address can view in their browser. While GitHub Pages is free to use, there are some restrictions on usage, file size, and content and it is not intended for running an online business or commercial transactions. But one advantage of code templates is that you can host them on any web server you control. Since we’re already using GitHub to store and edit our code template, it’s easy to turn on GitHub Pages to host it online. To access GitHub Pages, scroll to the top of your repo page and click the Settings button as shown in Figure 9.7. Figure 9.7: Click the Settings button to access GitHub Pages and publish your work on the web. In the Settings screen, scroll way down to the GitHub Pages area. In the drop-down menu, change Source from None to Master, keep the default /(root) option in the middle, and press Save as shown in Figure 9.8. This step tells GitHub to publish a live version of your map on the public web, where anyone can access it in their browser, if they have the web address. Figure 9.8: In Settings, go to GitHub Pages, and switch the source from None to Master. Note: TODO: GitHub recently announced it plans to change the default branch from Master to Main to eliminate its master-slave metaphor. GitHub recommends waiting until later in 2020 for their system to support this change. When that happens, we need to update repos, text, and screenshots. See more at https://github.com/github/renaming Scroll back down to Settings &gt; GitHub Pages to see the web address where your live map has been published online, and right-click it to open in a new browser tab, as shown in Figure 9.9. Figure 9.9: In Settings for GitHub Pages, right-click your published map link to open in a new tab. Now you should have at least two tabs open in your browser. The first tab contains your GitHub repo, where you edit your code, with a web address in this format, and replace USERNAME and REPOSITORY with your own: https://github.com/USERNAME/REPOSITORY The second tab contains your GitHub Pages live website, where your edited code appears online. GitHub Pages automatically generates a public web address in this format: https://USERNAME.github.io/REPOSITORY Remember how we told you not to create your account with a username like DrunkBrownieChef6789? GitHub automatically places your username automatically in the public web address. Keep both tabs open so you can easily go back and forth between editing your code and viewing the live results online. Note: The live version of your code points to the index.html page by default, so it’s not necessary to include it in the web address. Also, web addresses are not case sensitive, meaning you can save time by typing all of it in lower-case. Tip: If your live map does not appear right away, wait up to 30 seconds for GitHub Pages to finish processing your edits. Then give your browser a “hard refresh” to bypass any saved content in your cache and re-download the entire web page from the server, using one of these key combinations: Ctrl + F5 (most browsers for Windows or Linux) Command + Shift + R (Chrome or Firefox for Mac) Shift + Reload button toolbar (Safari for Mac) Ctrl + Shift + Backspace (on Chromebook) Now let’s edit your the GitHub repo so that the link points to your live map, instead of our live map. Copy the web address of your live map from your second browser tab. Go back to your first browser tab with your GitHub repo, and click on the repo title to return to its home page, as shown in Figure 9.10. Figure 9.10: On your first browser tab, click the repo title. On your repo page, click to open the README.md file, and click the pencil again to edit it, as shown in Figure 9.11. Paste your live web link under the label (replace with link to your site) and scroll down to commit the change. Figure 9.11: Open and edit the README file to paste the link to your live map. Now that you’ve successfully made simple edits and published your live map, let’s make more edits to jazz it up and help you learn more about how Leaflet code works. On your repo home page, click to open the index.html file, and click the pencil symbol to edit more code. Wherever you see the EDIT code comment, this points out a line that you can easily modify. For example, look for the code block shown below that sets up the initial center point of the map and its zoom level. Insert a new latitude and longitude coordinate to set a new center point. To find coordinates, right-click on any point in Google Maps and select What’s here?, as described in the geocoding section in chapter 2. var map = L.map(&#39;map&#39;, { center: [41.77, -72.69], // EDIT latitude, longitude to re-center map zoom: 12, // EDIT from 1 to 18 -- decrease to zoom out, increase to zoom in scrollWheelZoom: false }); The next code block displays the basemap tile layer that serve as the map background. Our template uses a light map with all labels, publicly provided by CARTO, with credit to OpenStreetMap. One simple edit is to change light_all to dark_all, which will substitute a different CARTO basemap with inverted coloring. Or see many other Leaflet basemap code options that you can paste in at https://leaflet-extras.github.io/leaflet-providers/preview/. Make sure to attribute the source, and also keep }).addTo(map); at the end of this code block, which displays the basemap. L.tileLayer(&#39;https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png&#39;, { attribution: &#39;&amp;copy; &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;OpenStreetMap&lt;/a&gt;, &amp;copy; &lt;a href=&quot;https://carto.com/attribution&quot;&gt;CARTO&lt;/a&gt;&#39; }).addTo(map); The last code block displays a single point marker on the map, colored blue by default in Leaflet, with a pop-up message when users click it. You can edit the marker coordinates, insert the pop-up text, or copy and paste the code block to create a second marker. L.marker([41.77, -72.69]).addTo(map) // EDIT latitude, longitude to re-position marker .bindPopup(&quot;Insert pop-up text here&quot;); // EDIT pop-up text message After making edits, remember to scroll down and press the Commit button to save changes. Then go to your browser tab with the live map, and do a hard-refresh to view changes. If your map edits do not appear right away, remember that GitHub Pages sometimes requires up to 30 seconds to process code edits. If you have problems, see the Fix Common Mistakes section in the appendix. Congratulations! If this is the first time that you’ve edited computer code and hosted it online, you can now call yourself a “coder”. The process is similar to following and modifying a cookbook recipe, just like you also can call yourself a “chef” after baking your first batch of brownies! Although no one is likely to hire you as a full-time paid coder (or chef) at this early stage, you now understand several of the basic skills needed to copy, edit, and host code online, and you’re ready to dive into the more advanced versions, such as Chart.js and Highcharts templates in chapter 10 and Leaflet map templates in chapter 11. The next section describes how to enhance your GitHub skills by creating new repos and uploading your files. These are essential steps to create a second copy of a code template or to work with more advanced templates in the next two chapters. "],
["create-repo.html", "Create a New Repo and Upload Files on GitHub", " Create a New Repo and Upload Files on GitHub Now that you’ve made a copy of our GitHub template, the next step is to learn how to create a brand-new repo and upload files. These skills will be helpful for several scenarios. First, if you have to fork a repo, which GitHub allows you to do only one time, this method will allow you to create additional copies. Second, you’ll need to upload some of your own files when creating data visualizations using Chart.js and Highcharts templates in Chapter 10 and Leaflet map templates in Chapter 11. Once again, we’ll demonstrate how to do all of these steps in GitHub’s beginner-level browser interface, but see the next section on GitHub Desktop for an intermediate-level interface that’s more efficient for working with code templates. In the previous section, you created a copy of our GitHub repo with the Use this template button, and we intentionally set up our repos with this newer feature because it allows the user to make multiple copies and assign each one a different name. Many other GitHub repos do not include a Template button, so to copy those you’ll need to click the Fork button, which automatically generates a copy with the same repo name as the original. But what if you wish to fork someone’s repo a second time? GitHub prevents you from creating a second fork to avoid violating one of its important rules: every repo in your account must have a unique name, to avoid overwriting and erasing your work. So how do you make a second fork of a GitHub repo, if there’s no Use this template button? Follow our recommended workaround that’s summarized in these three steps: Download the existing GitHub repo to your local computer Create a brand-new GitHub repo with a new name Upload the existing code repo files to your brand-new repo Click on the Code &gt; Download Zip drop-down menu button on any repo, as shown in Figure 9.12. Your browser will download a zipped compressed folder with the contents of the repo to your local computer, and it may ask you where you wish to save it. Decide on a location and click OK. Figure 9.12: Click Code and select Download Zip to create a compressed folder of a repo on your computer. Navigate to the location on your computer where you saved the folder. Its file name should end with .zip, which means you need to double-click to “unzip” or de-compress the folder. After you unzip it, a new folder will appear named in this format, REPOSITORY-BRANCH, which refers to the repository name (such as leaflet-map-simple) and the branch name (such as master or main), and it will contain the repo files. One of those files is named index.html, which you’ll use in a few steps below. Go back to your GitHub account in your web browser, click on the plus (+) symbol in the upper-right corner of your account, and select New repository, as shown in Figure 9.13. Figure 9.13: Click the plus (+) symbol in upper-right corner to create a new repo. On the next screen, GitHub will ask you to enter a new repo name. Choose a short one, preferably all lower-case, and separate words with hyphens if needed. Let’s name it practice because we’ll delete it at the end of this tutorial. Check the box to Initialize this repository with a README to simplify the next steps. Also, select Add a license that matches the code you plan to upload, which in this case is MIT License. Other fields are optional. Click the green Create Repository button at the bottom when done, as shown in Figure 9.14. Figure 9.14: Name your new repo practice, check the box to Initialize this repo with a README, and Add a license (select MIT) to match any code you plan to upload. Your new repo will have a web address similar to https://github.com/USERNAME/practice. On your new repo home page, click the Add File &gt; Upload Files drop-down menu button, near the middle of the screen, as shown in Figure 9.15. Figure 9.15: Click the Upload Files button. Inside the repo folder that you previously downloaded and unzipped on your local computer, drag-and-drop the index.html file to the upload screen of your GitHub repo in your browser, as shown in Figure 9.16. Do not upload LICENSE or README.md because your new repo already contains those two files. Scroll down to click the green Commit Changes button. Figure 9.16: Drag-and-drop the index.html file to the upload screen. When the upload is complete, your repo should contain three files, now including a copy of the index.html code that you previously downloaded from the leaflet-map-simple template. This achieved our goal of working around GitHub’s one-fork rule, by creating a new repo and manually uploading a second copy of the code. Optionally, you could use GitHub Pages to publish a live version of the code online, and paste the links to the live version at the top of your repo and your README.md file, as described in the Copy, Edit, and Host a Simple Leaflet Map Template section of this chapter. Since this was only a practice repo, let’s delete it from GitHub. In the repo screen of your browser, click the top-right Settings button, scroll all the way down to the Danger Zone, and click Delete this repository, as shown in Figure 9.17. GitHub will ask you to type in your username and repo name to ensure that you really want to delete the repo, to prove you are not a drunken brownie chef. Figure 9.17: After clicking the Delete Repository button, GitHub will ask you to type your username and repo name to confirm. So far, you’ve learned how to copy, edit, and host code using the GitHub web interface, which is a great introduction for beginners. Now you’re ready to move up to tools that will allow you to work more efficiently with GitHub, such as GitHub Desktop and Atom Editor, to quickly move entire repos to your local computer, edit the code, and move them back online. "],
["github-desktop-atom.html", "GitHub Desktop and Atom Editor to Code Efficiently", " GitHub Desktop and Atom Editor to Code Efficiently Editing your code through the GitHub web interface is a good way to start, especially if you only need to make a few edits or upload a couple of files to your repo. But the web interface will feel very slow if you edit or upload multiple files in your repo. To speed up your work, we recommend that you download two free tools—GitHub Desktop and Atom Text Editor—which run on Mac or Windows computers. When you connect your GitHub web account to GitHub Desktop, it allows you to “pull” the most recent version of the code to your local computer’s hard drive, make and test your edits, and “push” your commits back to your GitHub web account. Atom Text Editor, which is also created by the makers of GitHub, allows you to view and edit code repos on your local computer more easily than the GitHub web interface. While there are many text editors for coders, Atom is designed to work well with GitHub Desktop. Tip: Currently, neither GitHub Desktop nor Atom Editor are supported for Chromebooks, but Google’s Web Store offers several text editors, such as Text and Caret, which offer some of the functionality described below.) Let’s use GitHub Desktop to pull a copy of your leaflet-map-simple template to your local computer, make some edits in Atom Editor, and push your commits back up to GitHub. Go to the GitHub web repo you wish to copy to your local computer. In your browser, navigate to https://github.com/USERNAME/leaflet-map-simple, using your GitHub username, to access the repo you created in the Copy, Edit, and Host a Simple Leaflet Map Template section of this chapter. Click the Add file &gt; Open with GitHub Desktop drop-down menu button near the middle of your screen, as shown in Figure 9.18. The next screen will show a link to the GitHub Desktop web page, and you should download and install the application. Figure 9.18: In your GitHub repo on the web, click Add file to Open with GitHub Desktop to download and install GitHub Desktop. When you open GitHub Desktop for the first time, you’ll need to connect it to the GitHub web account you previously created in this chapter. On the welcome screen, click the blue Sign in to GitHub.com button, as shown in Figure 9.19, and login with your GitHub username and password. On the next screen, GitHub will ask you to click the green Authorize desktop button to confirm that you wish to connect to your account. Figure 9.19: Click the blue Sign in to GitHub.com button to link GitHub Desktop to your GitHub account. In the next setup screen, GitHub Desktop asks you to configure Git, the underlying software that runs GitHub. Confirm that it displays your username and click Continue, as shown in Figure 9.20. Figure 9.20: Click the Continue button to authorize GitHub Desktop to send commits to your GitHub account. On the “Let’s Get Started” with GitHub Desktop screen, click on Your Repositories on the right side to select your leaflet-map-sample, and further below click the blue button to Clone it to your local computer, as shown in Figure 9.21. Figure 9.21: Select your leaflet-map-simple repo and click the Clone button to copy it to your local computer. When you clone a repo, GitHub Desktop asks you to select the Local Path, meaning the location where you wish to store a copy of your GitHub repo on your local computer, as shown in Figure 9.22. Before you click the Clone button, remember the path to this location, since you’ll need to find it later. Figure 9.22: Select the Local Path where your repo will be stored on your computer, then click Clone. On the next screen, GitHub Desktop may ask, “How are you planning to use this fork?” Select the default entry “To contribute to the parent project,” which means you plan to send your edits back to your GitHub web account, and click Continue, as shown in Figure 9.23. Figure 9.23: If asked how you plan to use this fork, select the default To contribute to the parent project and click Continue. Now you have copies of your GitHub repo in two places—in your GitHub web account and on your local computer—as shown in Figure 9.24. Your screen may look different, depending on whether you use Windows or Mac, and the Local Path you selected to store your files. Figure 9.24: Now you have two copies of your repo: in your GitHub online account (on the left) and on your local computer (on the right, as shown in the Mac Finder). Windows screens will look different. Before we can edit the code in your local computer, download and install the Atom Editor application. Then go to your GitHub Desktop screen, confirm that the Current Repository is leaflet-map-simple, and click the Open in Atom button as shown in Figure 9.25. Figure 9.25: In GitHub Desktop, confirm the Current Repo and click the Open in Atom button to edit the code. Since Atom Editor is integrated with GitHub Desktop, it opens up your entire repo as a “project,” where you can click files in the left window to open as new tabs to view and edit code, as shown in Figure 9.26. Open your index.html file and edit the title of your map, around line 22, then save your work. Figure 9.26: Atom Editor opens your repo as a project, where you can click files to view code. Edit your map title. After saving your code edit, it’s a good habit to clean up your Atom Editor workspace. Right-click on the current Project and select Remove Project Folder in the menu, as shown in Figure 9.27. Next time you open up Atom Editor, you can right-click to Add Project Folder, and choose any GitHub repo that you have copied to your local computer. Figure 9.27: To clean up your Atom Editor workspace, right-click to Remove Project Folder. Now that you’ve edited the code for your map on your local computer, let’s test how it looks before uploading it to GitHub. Go to the location where you saved the repo on your local computer, and right-click the index.html file, select Open With, and choose your preferred web browser, as shown in Figure 9.28. Figure 9.28: Right-click the index.html file on your local computer and open with a browser to check your edits. Note: Since your browser is displaying only the local computer version of your code, the web address will begin with file:///... rather than https://..., as appears in your GitHub Pages online map. Also, if your code depends on online elements, those features may not function when viewing it locally. But for this simple Leaflet map template, your updated map title should appear, allowing you to check its appearance before pushing your edits to the web. Now let’s transfer your edits from your local computer to your GitHub web account, which you previously connected when you set up GitHub Desktop. Go to GitHub Desktop, confirm that your Current Repo is leaflet-map-simple, and you will see your code edits summarized on the screen. In this two-step process, first click the blue Commit to Master button at the bottom of the page to save your edits to your local copy of your repo. (If you edit multiple files, GitHub Desktop will ask you write a summary of your edit, to help you keep track of your work.) Second, click the blue Push origin button to transfer those edits to the parent copy of your repo on your GitHub web account. Both steps are shown in Figure 9.29. Figure 9.29: In this two-step process, click Commit to Master, then click Push origin to save and copy your edits from your local computer to your GitHub web account, as shown in this animated GIF. Congratulations! You’ve successfully navigated a round-trip journey of code, from your GitHub account to your local computer, and back again to GitHub. Since you previously used the GitHub Pages settings to create an online version of your code, go see if your edited map title now appears on the public web. The web address you set up earlier follows this format https://USERNAME.github.io/REPOSITORY, substituting your GitHub username and repo name. While you could have made the tiny code edit above in the GitHub web interface, hopefully you’ve begun to see many advantages of using GitHub Desktop and Atom Editor to edit code and push commits from your local computer. First, you can make more complex code modifications with Atom Editor, which includes search, find-and-replace, and other features to work more efficiently. Second, when you copy the repo to your local computer, you can quickly drag-and-drop multiple files and subfolders for complex visualizations, such as data, geography, and images. Third, depending on the type of code, you may be able to test how it works locally with your browser, before uploading your commits to the public web. Tip: Atom Editor has many built-in features that recognize and help you edit code, plus the option to install more packages in the Preferences menu. One helpful built-in tool is Edit &gt; Toggle Comments, which automatically detects the coding language and converts the selected text from executable code to non-executed code comments. Another built-in tool is Edit &gt; Lines &gt; Auto Indent, which automatically cleans up selected text or an entire page of code for easier reading. GitHub also offers a powerful platform for collaborative projects, such as Hands-On Data Visualization. As co-authors, we composed the text of these book chapters and all of the sample code templates on GitHub. Jack started each day by “pulling” the most recent version of the book from our shared GitHub account to his local computer using GitHub Desktop, where he worked on sections and “pushed” his commits (aka edits) back to GitHub. At the same time, Ilya “pulled” the latest version and “pushed” his commits back to GitHub as well. Both of us see the commits that each other made, line-by-line in green and red (showing additions and deletions), by selecting the GitHub repo Code tab and clicking on one of our commits, as shown in Figure 9.30. Figure 9.30: Drag-and-drop the file to the upload screen. Although GitHub does not operate like Google Documents, which displays live edits, the platform has several advantages when working collaboratively with code. First, since GitHub tracks every commit we make, it allows us to go back and restore a very specific past version of the code if needed. Second, when GitHub repos are public, anyone can view your code and submit an “issue” to notify the owner about an idea or problem, or send a “pull request” of suggested code edits, which the owner can accept or reject. Third, GitHub allows collaborators to create different “branches” of a repo in order to make edits, and then “merge” the branches back together if desired. Occasionally, if two or more coders attempt to push incompatible commits to the same repo, GitHub will warn about a “Merge Conflict,” and ask you to resolve these conflicts in order to preserve everyone’s work. Many coders prefer to work on GitHub using its Command Line Interface (CLI), which means memorizing and typing specific commands directly into the Terminal application on Mac or Windows, but this is beyond the scope of this introductory book. Summary If this is the first time you’ve forked, edited, and hosted live code on the public web, welcome to the coding family! We hope you agree that GitHub is a powerful platform for engaging in this work and sharing with others. While beginners will appreciate the web interface, you’ll find that the GitHub Desktop and Atom Editor tools makes it much easier to work with Chart.js and Highcharts code templates in Chapter 10 and the Leaflet map code templates in Chapter 11. Let’s build on your brand-new coding skills to create more customized charts and maps in the next two chapters. "],
["chartcode.html", "Chapter 10 Chart.js and Highcharts Templates", " Chapter 10 Chart.js and Highcharts Templates TODO: Rewrite chapter to include Highcharts While beginners appreciate the drag-and-drop chart tools and tutorials described earlier in this book, such as Google Sheets and Tableau Public, more advanced users may wish to customize their visualizations, add more complex data, and control exactly how and where their work appears on the web. A more powerful and relatively easy-to-learn solution is to use code templates built with Chart.js https://www.chartjs.org/, an open-source library, which you can modify and host on GitHub, as described in this book. Working with Chart.js Pros Open-source code that is distributed under MIT license and is free for all and Easier for beginners to understand than more complex visualization code libraries such as D3.js 10.0.0.0.1 Cons Must host your own code repositories to publish to the web (with a free service such as GitHub Pages) Table 10.1: Chart Templates and Tutorials Chart Templates Best use and tutorials in this book Chart.js Bar Chart Bar charts (vertical bar charts are often called column charts) can be used to compare categorical data. Template with tutorial: Bar Chart.js with CSV Data Chart.js Line Chart Line charts are normally used to show trends (temporal data). Template with tutorial: Line Chart with CSV Data Chart.js Scatter Chart Scatter charts (also scatterplots) are used to display data of 2 or more dimensions. Template with tutorial: Scatter Chart with CSV Data Chart.js Bubble Chart Bubble charts are used to display data of 3 or more dimensions. Template with tutorial: Bubble Chart with CSV Data Inside the templates The templates featured above vary from simple to complex, but all of them rely on four basic pillars: HTML: language to structure content on the web (example: index.html) CSS, or Cascading Style Sheet: to shape how content appears on the web (example: style.css) JavaScript: code to create the chart and interactivity (example: script.js) CSV: data that powers the visualization that is expressed in comma-separated format (example: data.csv) Also, these templates refer to other code elements: library: link to online instructions to complete routine tasks (example: Chart.js) data: content to appear in chart, typically in CSV format (example: data.csv) or pulled from Google Sheets Learn more: - Chart.js Samples, https://www.chartjs.org/samples/latest/ "],
["chartjs-bar-csv.html", "Bar Chart.js with CSV Data", " Bar Chart.js with CSV Data Bar charts (vertical bar charts are often called column charts) can be used to compare categorical data. The y-axis (or x-axis for horizontal bar chart) should always start at 0. Figure 10.1: Interactive bar chart with Chart.js. See detailed instructions on GitHub. Bar Chart.js with CSV Data (with Error Bars) If your data comes with uncertainty (margins of error), we recommend you show it in your visualizations. The bar chart template shown in Figure 10.2 shows median and mean (average) income for select US states. You can notice that error bars are larger for less populated states, such as Alaska, Vermont, and Wyoming. Data for the two of the most populous states, California and Texas, have tiny margins of error. Figure 10.2: Interactive bar chart with error bars in Chart.js. See detailed instructions on GitHub. "],
["chartjs-line-csv.html", "Line Chart.js with CSV Data", " Line Chart.js with CSV Data Line charts are often used to show temporal data (trends). The x-axis often represents time intervals. Unlike column or bar charts, y-axes of line charts do not necessarily start at 0. Figure 10.3: Interactive line chart with Chart.js. See detailed instructions on GitHub. "],
["chartjs-scatter-csv.html", "Scatter Chart.js with CSV Data", " Scatter Chart.js with CSV Data Scatter charts (also scatterplots) are used to display data of 2 or more dimensions. The scatter chart below shows the relationship between household income and test performance for school districts in Connecticut. Using x- and y-axes to show two dimensions, it is easy to see that test performance improves as household income goes up. Figure 10.4: Interactive scatter chart with Chart.js. See detailed instructions on GitHub. Going beyond two dimensions To show more than two dimensions in scatter charts, one can: color each data point differently to show third dimension, eg use shades of red and green to show 5-year trend in test performance; resize each data point to display fourth dimension, eg number of students in each school district; use different icons or glyphs to display fifth dimension, eg circles for male students and squares for female students. Remember not to overwhelm the viewer and communicate only the data that are necessary to prove or illustrate your idea. "],
["chartjs-bubble-csv.html", "Bubble Chart.js with CSV Data", " Bubble Chart.js with CSV Data Bubble charts are similar to scatter plots. The size of each dot (marker) is used to represent an additional dimension. In the demo below, the bubble chart shows the relationship between median household income (x-axis) and test performance (y-axis) in 6 school districts in Connecticut. The size of data point (marker) corresponds to the number of students enrolled in the school district: bigger circles represent larger school districts. Figure 10.5: Interactive bubble chart with Chart.js. See detailed instructions on GitHub. Tip: Use semi-transparent circles Data points may obstruct each other. To avoid this, play with color transparency. For example, rgba(160, 0, 0, 0.5) is a semi-transparent red in RGBA color model. The a stands for alpha, and is a number between 0 and 1, where 1 is solid, and 0 is completely transparent. Using transparency, you will be able to see data points that are hidden behind bigger neighbors. Going beyond three dimensions To show more than three dimensions in bubble charts, one can: color each data point differently to show fourth dimension, eg use shades of red and green to show 5-year trend in test performance; use different icons or glyphs to display fifth dimension, eg circles for male students and squares for female students. Remember not to overwhelm the viewer and communicate only the data that are necessary to prove or illustrate your idea. Summary TODO "],
["leaflet.html", "Chapter 11 Leaflet Map Templates", " Chapter 11 Leaflet Map Templates In Chapter 6: Map Your Data, we described several drag-and-drop tools designed for beginners, such as Google My Maps and Datawrapper. In this chapter, we offer more advanced map tutorials using our open-source code templates, which you can copy and modify with skills you learned in Chapter 9: Edit and Host Code with GitHub. We built all of the templates in this chapter with Leaflet, a powerful open-source code library for creating interactive maps on desktop or mobile devices. No coding skills are required to use our first two easy-to-use templates because they pull your map data from a linked Google Sheet. The first template, Leaflet Maps with Google Sheets, is a general-purpose tool that can display points, polygons, or polylines, using your choice of colors, icons, and images, based on data uploaded into your linked Google Sheet and GitHub repository. It also includes the option to display a table of point markers next to your map. The second template, Leaflet Storymaps with Google Sheets, displays your map as a scrolling narrative of chapters to guide readers through a storyline, with the option to display paragraphs of text, images, audio or video clips, and historical map backgrounds loaded into your linked Google Sheet and GitHub repo. If you wish to add some of these extra features, look back at Chapter 2 to geocode addresses with a Google Sheets Add-on, or jump ahead to Chapter 12: Transform Your Map Data to learn how to create and edit polygons and polylines with the GeoJson.io tool, edit or join data with polygons using the MapShaper tool, or georectify a scanned map to use as a background overlay with the MapWarper tool. Our remaining Leaflet templates are designed to help users develop their map coding skills. Even if you have no prior coding experience, but can follow instructions and are code-curious about how things work on your computer, start with the Leaflet Maps with CSV Data tutorial, which walks you through the steps of creating a point map that pulls data from a CSV file, a generic spreadsheet format we discussed in Chapter 2. Then move on to the Leaflet Maps with Open Data API tutorial, to learn how to code using an application program interface to pull information directly from open data repositories as we described in Chapter 3. In both of these templates, you’ll learn how Leaflet maps are written using three coding languages: HTML: to structure content on the web page, typically in a file named index.html. CSS or Cascading Style Sheet: to shape how content appears on the page, either inside index.html or in a separate file such as style.css. JavaScript: to create the interactive map using instructions from the Leaflet code library, either inside index.html on in a separate file, such as script.js. Explore our Leaflet map templates and you’ll also see how they refer to different code components, such as basemap tiles from various open-access online providers, such as Carto, Esri, Stamen, and Open Street Map, that allow you to zoom into background maps. You’ll also see data files to place information about points, polygons, or polylines on top of the map, usually in CSV or GeoJSON format—see chapter 12, with names similar to data.csv or map.geojson. If you’re new to coding, creating Leaflet maps can be a great place to start and quickly see the results of what you’ve learned. To help you solve problems that may arise, see Fix Common Mistakes in the appendix. Table 11.1: Map Templates and Tutorials Map Templates Best use and tutorials in this book Leaflet Maps with Google Sheets Best to show interactive points, polygons, or polylines, using your choice of colors, styles, and icons, based on data loaded into your linked Google Sheet (or CSV file) and GitHub repository. Includes option to display a table of point map markers next to your map. Template with tutorial: Leaflet Maps with Google Sheets Leaflet Storymaps with Google Sheets Best to display your map as a scrolling narrative of chapters to guide readers through a storyline, with the option to include paragraphs of text, images, audio or video clips, and historical map backgrounds loaded into your linked Google Sheet (or CSV) and GitHub repo. Template with tutorial: Leaflet Storymaps with Google Sheets Leaflet Maps with CSV Data Learn how to code your own Leaflet point map that pulls data from a CSV file in your GitHub repo.Template with tutorial: Leaflet Maps with CSV Data Leaflet Maps with Open Data API Learn how to code your own Leaflet map with an application program interface (API) that pulls content directly from open data repositories, such as Socrata and others.Template with tutorial: Leaflet Maps with Open Data API TODO: decide whether to add any other Leaflet map templates we created for HandsOnDataViz or OnTheLine "],
["leaflet-maps-with-google-sheets.html", "Leaflet Maps with Google Sheets", " Leaflet Maps with Google Sheets Sometimes you need to create a map that cannot be made easily with drag-and-drop tools, because you need to customize its appearance or add new layers of point, polygon, or polyline data. In these cases, consider making a copy of our Leaflet Maps with Google Sheets template on GitHub. It gives you more control over choosing colors, icons, and images, and also the option to display a data table of point markers. To customize your interactive map, you enter data into a Google Sheet template, which you link directly to your copy of the Leaflet code repository, as shown in Figure 11.1 and Figure 11.2. TODO: Create and insert a new version of the demo, featuring ECGreenway route thru CT, points with photos, and pop density of towns to highlight how this bike route connects cities. Figure 11.1: Explore a live demonstration of Leaflet Maps with Google Sheets. Figure 11.2: Explore the live Google Sheet template that feeds data into the Leaflet map above. Tutorial Outline Make sure you meet these requirements, and read this overview to prepare yourself for this multi-step tutorial. Before you begin, you must: Have a Google Drive account. Know how to File &gt; Make a Copy in Google Sheets, as described in Chapter 2. Have a GitHub account. Know how to Edit and Host Code with GitHub, as described in Chapter 9. In the first part of the tutorial, you will create and publish your copies of our GitHub and Google Sheets templates: Copy the GitHub template and publish your version with GitHub Pages File &gt; Make a Copy of Google Sheet template, Share, and Publish Paste your Google Sheet browser address in two places in your GitHub repo Update your Google Sheet Options tab info and refresh your live map In the second half, you will learn how to upload and display different types of map data, such as points, polygons, and polylines, and to edit colors, icons, and images, based on information you enter into the linked Google Sheet and upload to your GitHub repo. Geocode locations and customize new markers in the Points tab Remove or display point, polygon, or polylines data and legends Then you will finalize your map by following either step G OR step H: Save each Google Sheets tab as a CSV file and upload to GitHub OR Get your own Google Sheets API Key to insert into the code If any problems arise, see the Fix Common Mistakes section of the appendix. A) Copy the GitHub template and publish your version with GitHub Pages Right-click to open this GitHub code template in a new tab: https://github.com/handsondataviz/leaflet-maps-with-google-sheets In the upper-right corner of the code template, sign in to your free GitHub account. In the upper-right corner, click the green Use this template button to make a copy of the repository in your GitHub account. On the next screen, name your repo leaflet-maps-with-google-sheets or choose a different meaningful name in all lower-case. Click the Create repository from template button. Your copy of the repo will follow this format: https://github.com/USERNAME/leaflet-maps-with-google-sheets In your new copy of the code repo, click the upper-right Settings button and scroll way down to the GitHub Pages area. In the drop-down menu, change Source from None to Master, keep the default /(root) setting, and press Save as shown in Figure 11.3. This step tells GitHub to publish a live version of your map on the public web, where anyone can access it in their browser, if they have the web address. Figure 11.3: In Settings, go to GitHub Pages, and switch the source from None to Master. Note: TODO: GitHub recently announced it plans to change the default branch from Master to Main to eliminate its master-slave metaphor. GitHub recommends waiting until later in 2020 for their system to support this change. When that happens, we need to update repos, text, and screenshots. See more at https://github.com/github/renaming Scroll down to GitHub Pages section again, and copy the link to your published web site, which will appear in this format: https://USERNAME.github.io/leaflet-maps-with-google-sheets Scroll up to the top, and click on your repo name to go back to its main page. At the top level of your repo main page, click on README.md, and click the pencil icon to edit this file. Delete the link to the our live site, and paste in the link to your published site. Scroll down and Commit to save your edits. TODO: Insert image here On your repo main page, right-click the link to open your live map in a new tab. Be patient during busy periods on GitHub, when your website may take up to 1 minute to appear for the first time. B) File &gt; Make a Copy of Google Sheet template, Share, and Publish Open this Google Sheets template in a new tab Sign into your Google account, and select File &gt; Make a Copy to save your own version of this Google Sheet on your Google Drive Click the blue Share button, and click Change to anyone with the link, then click Done. This publicly shares your map data, which is required to make this template work. Go to File &gt; Publish to the Web, and click the green Publish button to publish the entire document, so that the Leaflet code can read it. Then click the upper-right X symbol to close this window. At the top of your browser, copy your Google Sheet address or URL (which usually ends in ...XYZ/edit#gid=0). Do NOT copy the Published to the web address (which usually ends in ...XYZ/pubhtml), as shown in Figure 11.4. Figure 11.4: Copy the Google Sheet address at the top of the browser, NOT the Publish to the web address. C) Paste your Google Sheet browser address in two places in your GitHub repo Our next task is to link your Google Sheet to your Leaflet code in GitHub, so that content from your Sheet will appear in your map. At the top of your GitHub repo, click to open the file named google-doc-url.js, and click the pencil symbol to edit it. Paste your Google Sheet address or URL (which usually ends in ...XYZ/edit#gid=0) to replace the existing URL, as shown in Figure 11.5. Be careful NOT to erase the single quotation marks or the semicolon at the end. See separate instructions about the Google API key further below. Figure 11.5: Paste in your Google Sheet URL to replace our URL. Scroll to bottom of page and press Commit to save your changes. Now your published Google Sheet is linked to your published Leaflet map code. Also, let’s paste your Google Sheets browser address in a second place to keep track of it. In your GitHub repo, click to open the README.md file, click the pencil symbol to edit it, and paste your Google Sheet browser address to replace the existing address. Scroll down and commit to save your changes. TODO: Insert image here D) Update your Google Sheet Options tab info and refresh your live map Now that your published Google Sheet is linked to your live map, go to the Options tab and update any of these items: Map Title Map Subtitle Author Name Author Email or Website Author Code Repo Open the browser tab that displays your live map and refresh the page to see your changes. If your changes do not appear within a few seconds, see the Fix Common Problems section of the appendix. E) Geocode locations and customize new markers in the Points tab In the Points tab of your Google Sheet, you’ll see column headers to organize and display interactive markers on your map. Replace the demonstration data with your own, but do not delete or rename the column headers, since the Leaflet code looks for these specific names. Group: Create any labels to categorize groups of markers in your legend. Marker Icon: Search Font Awesome Icons and insert any standard icon name such as school or bus, or leave blank for no icon inside the marker. To create your own custom icon, see further below. Marker Color: Search W3Schools Color Names and insert any standard name such as blue or darkblue. Or insert a web color code such as #775307 or rgba(200,100,0,0.5). Icon Color: Set the color of the icon inside the marker. The default is white, which looks good inside darker-colored markers. Custom Size: Leave blank, unless you are creating your own custom icon further below. The next set of columns include items that appear when users click on point markers: - Name: Add a title to display in the marker pop-up window. - Image: Insert link to an external image link, or upload a small image to the media folder in your GitHub repo and add its pathname, such as media/trinity-college.jpg. TODO: add this to GSheet after code update - Description: Add text to appear in the marker pop-up window. You may include HTML web links in this format: &lt;a href=\"url\"&gt;link text&lt;/a&gt;. If a map link should open in a new browser tab, set the target attribute to _blank. Learn about HTML syntax at W3Schools. The next three columns—Location, Latitude, and Longitude—help to place your marker on the map. Although the Leaflet code only requires Latitude and Longitude, it’s wise to paste an address or place name into the Location column as a reminder to correspond with the numerical coordinates. Use the Geocoding by SmartMonkey Add-on that we introduced in Chapter 2 to convert addresses to x- and y-coordinates in a separate tab of your Google Sheet, and paste the results of those three columns into Location, Latitude, and Longitude. Optional: You can display a table of viewable markers at the bottom of your map, as shown in Figure 11.6. In the Options tab, set Display Table (cell B30) to On. You can also adjust the Table Height, and modify the display of Table Columns by entering the column headers, separated with commas. Figure 11.6: One option is to display a table of viewable markers at the bottom of your map. Optional: You can create your own custom marker, such as the Trinity College Bantam mascot in the demo. Use an image editing tool to create a square image, 64 x 64 pixels or smaller, with a transparent background. Save it in PNG format with a filename using all lower-case letters with no spaces. Upload the image to the markers folder in your GitHub repo. In the Marker Icon column, set the pathname in this format: markers/custom-trinity-64.png. In the Custom Size column, set to 64x64 or similar. Open the browser tab that displays your live map and refresh the page to see your changes. If your changes do not appear within a few seconds, see the Fix Common Problems section of the appendix. F) Remove or display point, polygon, or polylines data and legends By default, the demo map displays three types of data—points, polygons, and polylines—and their legends. You can remove any of these from your map by modifying your linked Google Sheet: To remove points: In the Options tab, set Point Legend Position (cell B27) to Off to hide it. In the Points tab, delete all rows of point data. To remove polylines: In the Options tab, set Polyline Legend Position (cell B36) to Off to hide it. In the Polylines tab, delete all rows of polyline data. To remove polygons: In the Polygons tab, set Polygon Legend Position (cell B4) to Off to hide it. Also in the Polygons tab, set Polygon GeoJSON URL (cell B6) to remove that data from your map. In the next tab Polygons1, use the tab drop-down menu to select Delete to remove the entire sheet. You’ve already learned how to add more markers in the Points tab as described above. But if you wish to add new polygon or polyline data, you’ll need to prepare those files in GeoJSON format using either the GeoJson.io tool tutorial or the MapShaper tool tutorial in Chapter 12. After you’ve prepared your GeoJSON data, name the files using all lower-case characters and no spaces, and upload them into the geometry subfolder of your GitHub repo. Then update these settings in your linked Google Sheet: To display polylines: In the Options tab, make sure Polyline Legend Position (cell B36) is visible by selecting topleft or a similar position. In the Polylines tab, enter the GeoJSON URL pathname to the file you uploaded to your GitHub repo, such as geometry/polylines-bike-lanes.geojson. Then insert a Display Name, Description, and Color. To display polygons: In the Polygons tab, make sure Polygon Legend Position (cell B4) is visible by selecting topleft or a similar position. Also, in Polygon GeoJSON URL (cell B6) enter the pathname to the file you uploaded to your GitHub repo, such as geometry/polygons-town-population.geojson. Also, you can change the Polygon Legend Title (cell B3) and add an optional Polygon Legend Icon (cell B5). Also, edit the Polygon Data and Color Settings sections to modify the labels and ranges to align with the properties of your GeoJSON file. In the Property Range Color Palette, you can automatically select a color scheme from the ColorBrewer tool we described in the Map Design section of Chapter 6, or manually insert colors of your choice in the cell below. Read the Hints column in the Polygons sheet for tips on how to enter data. If you wish to display multiple polygon layers, use the Polygons tab drop-down menu to Duplicate the sheet, and name additional sheets in this format: Polygons1, Polygons2, etc. Finalize Your Map Now you’re ready to finalize your map. Read the options below and choose either step G OR step H. G) Save each Google Sheets tab as a CSV file and upload to GitHub If you have finished entering most of your data into your Google Sheets, save each tab as a CSV file and upload them to GitHub. The Leaflet map code will pull data directly from your CSV files, rather than your Google Sheets. And you can still edit your CSV files in GitHub. Moving your data from Google Sheets to CSV format is the best long-term preservation strategy, because it keeps your map and data together in the same GitHub folder, and removes the risk that your map will break due to an interruption to Google services, as described in Step H. To move your map data from Google Sheets to CSV format, go to each tab and select File &gt; Download As into CSV format, as shown in Figure 11.7, using these file names: TODO: should we warn to keep the first letter upper-case? Options.csv Points.csv Polylines.csv Polygons.csv (if needed, also use: Polygons1.csv, Polygons2.csv, etc.) Notes.csv (or .txt) Upload all of these CSV files into the main level (or root level) of your GitHub repository. The Leaflet code looks here first for the data, and when it locates them, will pull the data directly from the CSV files into your map, skipping over the Google Sheets. TODO: Confirm this code request is working Figure 11.7: One way to finalize your map is to download each Google Sheets tab as a CSV file. H) Get your own Google Sheets API Key to insert into the code If you wish to keep using your Google Sheets to store your data, go to the chapter section named Get Your Own Google Sheets API Key, and insert it into the Leaflet map code as described, to avoid overusing our key. Google Sheets requires an API key to maintain reasonable usage limits on its service. You can get a free Google Sheets API key if you have a personal Google account, but not a Google Suite account provided by your school or business. TODO: confirm this detail Warning: We reserve the right to change our Google Sheets API key at any time, especially if other people overuse or abuse it. This means that you must finalize your map using either step J or K above, since it will stop working if we change our key. If problems arise, see the Fix Common Mistakes section of the appendix. TODO: Start again here "],
["leaflet-storymaps-with-google-sheets.html", "Leaflet Storymaps with Google Sheets", " Leaflet Storymaps with Google Sheets TODO: Add intro text Try it: Explore the map or right-click to view full-screen map in a new tab The map pulls the point data and settings from a linked Google Sheet, which you can explore below or right-click to view full-screen Sheet in a new tab Features Show map points, text, images, and links with scrolling narrative Free and open-source code template, built on Leaflet and linked to Google Sheets Fork the code and host your live map on the web for free with GitHub Pages Geocode location data with US Census or Google, using script inside the Google Sheet Easy-to-modify data and map options in Google Sheet tabs or uploaded CSV files Responsive design resizes your maps to display inside most mobile devices Create Your Own Fork (copy) the code template and publish your version with GitHub Pages File &gt; Make a Copy of Google Sheet template, Share, and File &gt; Publish Paste your Google Sheet URL in two places in your GitHub repo C2) NEW: Create a free Google Sheets API key to paste into the code Modify your map settings in the Options tab and test your live map Geocode locations in the Points tab To solve problems, see the Fix Common Mistakes section of the appendix. A) Fork (copy) the code template and publish your version with GitHub Pages Before you begin, this tutorial assumes that you: have a free Google Drive account, and learned the File &gt; Make a Copy in Google Sheets tutorial in this book have a free GitHub account, and understand concepts from the Edit and Host Code with GitHub chapter in this book Right-click to open this GitHub code template in a new tab: https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets In the upper-right corner of the code template, sign in to your free GitHub account In the upper-right corner, click Fork to copy the template (also called a code repository, or repo) into your own account. The web address (URL) of the new copy in your account will follow this format: https://github.com/USERNAME/leaflet-storymaps-with-google-sheets Reminder: You can only fork a GitHub repo one time. If needed, see how to make a second copy in the Create a New Repo in GitHub chapter in this book. In your new copy of the code repo, click on Settings, scroll down to the GitHub Pages area, select Master, and Save. This publishes your code to a live map on a public website that you control. Scroll down to GitHub Pages section again, and copy the link to your published web site, which will follow this format: https://USERNAME.github.io/leaflet-storymaps-with-google-sheets Scroll up to the top, and click on your repo name to go back to its main page. At the top level of your repo main page, click on README.md, and click the pencil icon to edit this file, written in easy-to-read Markdown code. Delete the link to the current live site, and paste in the link to YOUR site. Scroll down and Commit to save your edits. On your repo main page, right-click the link to your live map to open in a new tab. Be patient during busy periods on GitHub, when your website may take up to 1 minute to appear the first time. B) File &gt; Make a Copy of Google Sheet template, Share, and File &gt; Publish Right-click to open this Google Sheets template in a new tab: https://docs.google.com/spreadsheets/d/1AO6XHL_0JafWZF4KEejkdDNqfuZWUk3SlNlQ6MjlRFM/ Sign into your Google account File &gt; Make a Copy of the Google Sheet template to your Google Drive Click the blue Share button, click Advanced, click to change Private to Anyone with the link &gt; Can View the Sheet. This will make your public data easier to view in your map. File &gt; Publish the Link to your Google Sheet to the public web, so the Leaflet map code can read it. Screenshot: File &gt; Publish the link to your Google Sheet At the top of your browser, copy your Google Sheet web address or URL (which usually ends in ...XYZ/edit#gid=0). Do NOT copy the published URL (which usually ends in ...XYZ/pubhtml). Screenshot: Copy the Google Sheet URL, not the Publish URL C) Paste your Google Sheet URL in two places in your GitHub repo First, connect your Google Sheet directly to your Leaflet Map code. In your Github code repo, click to open this file: google-doc-url.js Click the pencil symbol to edit the file. Paste your Google Sheet URL into the code to replace the current URL. Do not delete the single-quotation marks or semicolon. Scroll to bottom of page and press Commit to save your changes. Now the Leaflet Map code can locate your published Google Sheet. Next, let’s paste your Google Sheet URL in a second place to keep track of it. Go to the README.md file in your GitHub repo, click to open and edit, and paste your Google Sheet web address to replace the existing link near the top. Commit to save your changes. D) Modify your map settings in the Options tab and test your live map In the top-level of your GitHub repo, test the new links to your map and your Google Sheet to make sure they work and point to your versions. ** TO DO - redo GIF ** In your linked Google Sheet, go to the Options Tab and modify these items: Map Title – insert your own title Map Subtitle – insert your own version Author Name – insert your own name, or first name, or initials (will be public) Author Email or Website – insert your own (will be public), or delete the current name to make it blank Open the link to your live map in a new browser tab and refresh to see your changes. E) Geocode locations and customize new markers in the Points tab In your new map, our next goal is to add and modify the appearance of a new set of point markers, based on new addresses that you will enter and geocode. In the Points tab of your Google Sheet: Do NOT delete or rename any column headers. However, you have the option to add new column headers to display in your map table. Geocode your new data inside your Google Sheet by dragging your cursor to select 6 columns of data: Location - Latitude - Longitude - Found - Quality - Source In the Geocoder menu that appears in this Google Sheet template, select one of the geocoding services. If one service cannot locate your data, try the other. Always inspect the accuracy of the Found column. Open the link to your live map in a new browser tab and refresh to see your changes. If your new markers appear correctly, then delete the existing rows that came with this template. TODO Add documentation for new features added in 2020 Add links to your text in the Google Sheet Add line breaks to your text in the Google Sheet TODO to code: Add Scroll Down text and symbol after the subtitle Markers I added a new column to the Chapter tab called “Marker”. It has a dropdown with currently three options: Numerated (defaults to that, even if empty value), Plain (with no number), and No marker. The latter is what you want. It can be potentially extended to colours, types of markers, etc. https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets/blob/master/scripts/storymap.js#L121-L131 Overlay GeoJSONs I added two columns, GeoJSON Overlay with the URL to the GeoJSON, and GeoJSON Feature Properties, which is CSS that defines style of features. List the styles separated by semicolon, and no quotation marks required. Eg fillColor: orange; weight:2, opacity: 0.5, color: red, fillOpacity: 0.1 In the code, you will see two vertical lines: they mean “or”. If the value of the left-most expression is not undefined, it uses it. If not, it keeps moving to the right until there is a value that is not an empty string. For example, https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets/blob/master/scripts/storymap.js#L310 color: feature.properties.COLOR || props.color || ‘silver’, Will first attempt to extract the color from the COLOR property of each geoJson feature (useful for choropleth). If not found, it tries the GeoJSON Feature Properties “color”. If that is not set, it uses silver. https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets/blob/master/scripts/storymap.js#L288-L316 Data in local CSV files If googleDocURL variable does not exist (eg you delete the file) or is an empty string, it reads two spreadsheets: Options.csv and Chapters.csv from the /csv folder. Otherwise, it reads from the google sheet. https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets/blob/master/scripts/storymap.js#L13-L35 When data is read from a .CSV, it links that in the attribution (https://github.com/handsondataviz/leaflet-storymaps-with-google-sheets/blob/master/scripts/storymap.js#L393-L396) Modify your Style Sheet To adjust title size: In GitHub, go to css/styles.css file, scroll all the way to the bottom, and adjust font-size values (or just use the links below). See your title around line 170, and change font-size up or down…. To add a horizontal line, you need to be a bit creative (see screenshot attached)! Break down text in your Description with the following code for the horizontal line: &lt;span style=\"display:block;width:100%;height:1px;background-color: silver; margin: 20px 0;\"&gt;&lt;/span&gt; When you copy-paste this snippet, the straight quotation marks do not turn into curly marks, otherwise it won’t work. Learn more: To solve problems, see Fix Common Mistakes section of the appendix. "],
["google-sheets-api-key.html", "Get Your Google Sheets API Key", " Get Your Google Sheets API Key After you’ve created your own version of Leaflet Maps with Google Sheets or Leaflet Storymaps with Google Sheets, there are two ways to finalize your map, as described above: either save your Google Sheet tabs in CSV format, or get your own Google Sheets API key and paste it into your Leaflet code on GitHub. You’ll learn about the latter method in this section. Google requires a API (application program interface) key to allow your computer code to read data from your Google Sheets, beginning with version 4 in September 2020. (If you created your own Leaflet Maps or Storymaps with Google Sheets using our template prior to September 2020, and you want to continue to pull data from your Google Sheet, you’ll need to update your code to make sure it keeps working TODO: explain pull request.) Google requires this API key to maintain reasonable limits on use of its services. For Google Sheets, the limit is 500 requests per 100 seconds per project, and 100 requests per 100 seconds per user. There is no daily usage limit. You can get your own API key for free by following the steps below. Overall, you will create and name your Google Cloud project, enable the Google Sheets API to allow a computer to read data from your Google Sheet, copy your new API key, and paste it into the Leaflet code in place of our key. Before you begin: You need a personal Google account, not a Google Suite account issued by your school or business. This tutorial presumes that you have already have completed the Leaflet Maps with Google Sheets or Leaflet Storymaps with Google Sheets template above, and wish to finalize your map. If you already created a Google Sheets API key for one template above, you can also use that key for another template. Go to the Google Developers Console at https://console.developers.google.com/ and log in to your Google account. Google may ask you to identify your country and agree to its terms of service. Click on Create a Project on the opening screen, as shown in Figure 11.8. Or alternatively, go to the upper-left drop-down menu to Select a project &gt; New project. Figure 11.8: Select Create a Project or use the menu to select a new project. In the next screen, give your new project a meaningful short name to remind you of its purpose, such as handsondataviz. You do not need to create an organization or parent folder. Then click Create, as shown in Figure 11.9. Figure 11.9: Give your project a meaningful short name. In the next screen, press the + Enable APIs and Services at the top of the menu, as shown in Figure 11.10. Make sure that your new project name appears near the top. Figure 11.10: Press the + Enable APIs and Services button. In the next screen, enter Google Sheets into the search bar, and select this result, as shown in Figure 11.11. Figure 11.11: Search for Google Sheets and select this result. In the next screen, select the Enable button to turn on the Google Sheets API for your project, as shown in Figure 11.12. Figure 11.12: Select the Enable button for Google Sheets API. In the left sidebar menu, click Credentials, then click + Create Credentials and select API key, as shown in Figure 11.13. Figure 11.13: Select Credentials - Create Credentials - API key. In the next screen, the console will generate your API key. Copy it, then press Restrict key, as shown in Figure 11.14. Figure 11.14: Copy your API key and press Restrict key. In the new window, under API restrictions, choose the Restrict key radio button. In the dropdown that appears, choose Google Sheets API, then click Save, as shown in Figure 11.15. Figure 11.15: Choose API restrictions - Restrict key - Google Sheets API In your Leaflet map code on your GitHub repo, open the google-doc-url.js file, click the pencil symbol to edit it, and paste in your Google Sheets API key to replace our key, as shown in Figure 11.16. Be careful not to erase the single-quote marks or the semicolon. Scroll down to Commit your changes. Figure 11.16: Paste in your Google Sheets API key to replace our key. You might receive a notification from GitHub stating that you have an exposed API key, but don’t worry. This key can only be used with Google Sheets, you received it for free, and you did not attach any billing information to it, so Google cannot charge you for its use. Now that you’ve learned how to create a Google Sheets API key to use with Leaflet Maps with Google Sheets or Leaflet Storymaps with Google Sheets, in the next sections you’ll learn more about other types of Leaflet map templates. "],
["leaflet-maps-with-csv.html", "Leaflet Maps with CSV Data", " Leaflet Maps with CSV Data TODO: REWRITE this to serve as a more advanced version using repo https://github.com/HandsOnDataViz/leaflet-map-csv rather than leaflet-map-simple (used in ch8) This tutorial introduces more sophisticated Leaflet map code templates (http://leafletjs.com) that you can modify and host online with GitHub in your browser (http://github.com). You will learn how to: Fork (copy) Leaflet template to your GitHub account Publish your live map to public web with GitHub Pages Modify your map title and add layer controls Geocode addresses in a Google Sheet and upload points from data.csv Code templates help us to move beyond the limits of drag-and-drop web mapping services (such as Google MyMaps) and to create more customized visualizations on a web server that you control. Before you begin, learn the broad concepts in the chapter introduction Edit and Host Code with GitHub. If you have problems with this tutorial, go to the Fix Common Mistakes section of the appendix. TODO: add demo, remove unnecessary basic steps from below (covered in prior chapter) Video A) Fork (copy) Leaflet template to your GitHub account Before you begin, sign up for a free GitHub account: http://github.com Right-click to open this GitHub code template in a new tab: https://github.com/handsondataviz/leaflet-map-csv In the upper-right corner of the code template, sign in to your free GitHub account In the upper-right corner, click Fork to copy the template (also called a code repository, or repo) into your GitHub account. The web address (URL) of the new copy in your account will follow this format: https://github.com/USERNAME/REPOSITORY Reminder: You can only fork a GitHub repo one time. If needed, see how to make a second copy in the Create a New Repo in GitHub chapter in this book. B) Publish your live map to public web with GitHub Pages In your new copy of the code repo, click on Settings, scroll down to the GitHub Pages area, select Master, and Save. This publishes your code template to a live map on a public website that you control. Scroll down to GitHub Pages section again, to select and copy the link to your published web site, which will follow this format: https://USERNAME.github.io/REPOSITORY Scroll up to the top, and click on your repo name to go back to its main page. At the top level of your repo main page, click on README.md, and click the pencil icon to edit this file, written in easy-to-read Markdown code. Delete the link to the current live site, and paste in the link to your site. Scroll down and Commit to save your edits. On your repo main page, right-click on the link to your published site to open in a new tab. Be patient during busy periods, because your website may take up to 1 minute to appear the first time. C) Modify your map title and add layer controls Go back to your browser tab for your code repo. Click on the index.html file (which contains the map code), and click the pencil icon to edit it. Explore the map code, which contains HTML, CSS, and JavaScript. Look for sections that begin with “EDIT” for items that you can easily change. Scroll down to Commit your changes. Go to your live website browser tab and refresh the page to view your edits. Be patient during busy periods, when some edits may take up to 1 minute to appear. To change your map title in the index.html file, click the pencil symbol (to edit) and go to lines 23-25. Replace “EDIT your map title” with your new title: TODO: decide if these triple backtic snippets will stay, or if they will throw errors into Markdown output &lt;!-- Display the map and title with HTML division tags --&gt; &lt;div id=&quot;map-title&quot;&gt;EDIT your map title&lt;/div&gt; &lt;div id=&quot;map&quot;&gt;&lt;/div&gt; To change your initial map zoom level, edit the index.html file and go to line 33. The zoom range for this map is from 1 (max zoom out) to 18 (max zoom in). // Set up initial map center and zoom level var map = L.map(&#39;map&#39;, { center: [41.77, -72.69], // EDIT latitude, longitude to re-center map zoom: 12, // EDIT from 1 to 18 -- decrease to zoom out, increase to zoom in scrollWheelZoom: false }); To change the default basemap, edit lines 46 and 52 to delete “.addTo(map)” from the Carto light layer, then add it to the Stamen colored terrain layer. DO NOT erase the semicolons! Your original code looks like this (scroll to right to see all): /* Carto light-gray basemap tiles with labels */ var light = L.tileLayer(&#39;https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png&#39;, { attribution: &#39;&amp;copy; &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;OpenStreetMap&lt;/a&gt;, &amp;copy; &lt;a href=&quot;https://carto.com/attribution&quot;&gt;CARTO&lt;/a&gt;&#39; }).addTo(map); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default // controlLayers.addBaseLayer(light, &#39;Carto Light basemap&#39;); /* Stamen colored terrain basemap tiles with labels */ var terrain = L.tileLayer(&#39;https://stamen-tiles.a.ssl.fastly.net/terrain/{z}/{x}/{y}.png&#39;, { attribution: &#39;Map tiles by &lt;a href=&quot;http://stamen.com&quot;&gt;Stamen Design&lt;/a&gt;, under &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0&quot;&gt;CC BY 3.0&lt;/a&gt;. Data by &lt;a href=&quot;http://openstreetmap.org&quot;&gt;OpenStreetMap&lt;/a&gt;, under &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;ODbL&lt;/a&gt;.&#39; }); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default // controlLayers.addBaseLayer(terrain, &#39;Stamen Terrain basemap&#39;); After you edit the code, it should look like this (scroll to right to see all): /* Carto light-gray basemap tiles with labels */ var light = L.tileLayer(&#39;https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png&#39;, { attribution: &#39;&amp;copy; &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;OpenStreetMap&lt;/a&gt;, &amp;copy; &lt;a href=&quot;https://carto.com/attribution&quot;&gt;CARTO&lt;/a&gt;&#39; }); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default // controlLayers.addBaseLayer(light, &#39;Carto Light basemap&#39;); /* Stamen colored terrain basemap tiles with labels */ var terrain = L.tileLayer(&#39;https://stamen-tiles.a.ssl.fastly.net/terrain/{z}/{x}/{y}.png&#39;, { attribution: &#39;Map tiles by &lt;a href=&quot;http://stamen.com&quot;&gt;Stamen Design&lt;/a&gt;, under &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0&quot;&gt;CC BY 3.0&lt;/a&gt;. Data by &lt;a href=&quot;http://openstreetmap.org&quot;&gt;OpenStreetMap&lt;/a&gt;, under &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;ODbL&lt;/a&gt;.&#39; }).addTo(map); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default // controlLayers.addBaseLayer(terrain, &#39;Stamen Terrain basemap&#39;); To add a control panel that turns on/off map layers, delete the code comment symbols (//) that appear in front of lines 38-41, 47, and 53 to activate these sections. When you remove code comments in GitHub, the color changes from gray text (inactive code) to colored text (active code). After you remove the code comments, your file should look like this (scroll to right to see all): /* Control panel to display map layers */ var controlLayers = L.control.layers( null, null, { position: &quot;topright&quot;, collapsed: false }).addTo(map); /* Carto light-gray basemap tiles with labels */ var light = L.tileLayer(&#39;https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png&#39;, { attribution: &#39;&amp;copy; &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;OpenStreetMap&lt;/a&gt;, &amp;copy; &lt;a href=&quot;https://carto.com/attribution&quot;&gt;CARTO&lt;/a&gt;&#39; }); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default controlLayers.addBaseLayer(light, &#39;Carto Light basemap&#39;); /* Stamen colored terrain basemap tiles with labels */ var terrain = L.tileLayer(&#39;https://stamen-tiles.a.ssl.fastly.net/terrain/{z}/{x}/{y}.png&#39;, { attribution: &#39;Map tiles by &lt;a href=&quot;http://stamen.com&quot;&gt;Stamen Design&lt;/a&gt;, under &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0&quot;&gt;CC BY 3.0&lt;/a&gt;. Data by &lt;a href=&quot;http://openstreetmap.org&quot;&gt;OpenStreetMap&lt;/a&gt;, under &lt;a href=&quot;http://www.openstreetmap.org/copyright&quot;&gt;ODbL&lt;/a&gt;.&#39; }).addTo(map); // EDIT - insert or remove &quot;.addTo(map)&quot; before last semicolon to display by default controlLayers.addBaseLayer(terrain, &#39;Stamen Terrain basemap&#39;); To change one point on the map, you could edit the latitude and longitude coordinates of the single marker in lines 55-57. To find coordinates for any location and to learn more, go to http://www.latlong.net /* Display a blue point marker with pop-up text */ L.marker([41.77, -72.69]).addTo(map) // EDIT latitude, longitude to re-position marker .bindPopup(&quot;Insert pop-up text here&quot;); // EDIT pop-up text message But a better way to display several points is to remove the code comment symbols (//) in front of lines 60-69 to activate this section of code, which pulls map points from the data.csv file in your GitHub repository. After your edits, this section should look like this (scroll right to see all): /* Upload Latitude/Longitude markers from data.csv file, show Title in pop-up, and override initial center and zoom to fit all in map */ var customLayer = L.geoJson(null, { onEachFeature: function(feature, layer) { layer.bindPopup(feature.properties.Title); } }); var runLayer = omnivore.csv(&#39;data.csv&#39;, null, customLayer) .on(&#39;ready&#39;, function() { map.fitBounds(runLayer.getBounds()); }).addTo(map); controlLayers.addOverlay(customLayer, &#39;Markers from data.csv&#39;); D) Geocode addresses in Google Sheet and upload points from data.csv A better way to display multiple points on your map is to prepare and upload a new data.csv file to your GitHub repository. First, right-click to open this Google Sheets template in a new tab: Leaflet Maps Simple data points with Geocoder Since this sheet is view-only, you cannot edit it. Instead, sign in to your Google account in the upper-right corner. Go to File &gt; Make a Copy, which will save a duplicate version to your Google Drive, which you can edit. In your copy of the Google Sheet, select any cells and press Delete on your keyboard to erase contents. Type new titles and addresses into columns A and B. To geocode your new addresses (which means converting them into latitude and longitude coordinates), select all of the contents across 6 columns, from Address (B) to Source (G). Go to the Geocoder menu that appears in this special Google Sheet template, and select any service, such as US Census (for US addresses) or Google Maps. The first time you run the geocoder, the script will ask for permission. After you have geocoded your addresses, go to File &gt; Download As &gt; Comma-separated values (.CSV format) to save the file to your computer. In your computer, right-click the downloaded file to rename it to: data.csv In your GitHub repository, click Upload Files, then drag-and-drop your new data.csv file, and Commit to upload it. Go to your live map browser tab and refresh to view changes. Be patient* during busy periods, when some edits may take up to 1 minute to appear. "],
["leaflet-maps-with-api.html", "Leaflet Maps with Open Data API", " Leaflet Maps with Open Data API TODO: Note this new title and URL, which is more general than the older title and “leaflet-maps-with-socrata” URL Blend in other section below this one Update the example to pull map data from a continuously updated map, since the current example has not been updated since 2018 Decide if there’s anything useful to borrow from the other example repo, such as a non-Socrata endpoint?: https://github.com/HandsOnDataViz/leaflet-data-apis write intro to connect more directly to the Open Data section in ch 3, and describe open data APIs in general, with Socrata API serving as a convenient example. Source: Current Class 1 - Class 4 Food Establishments, City of Hartford Why pair Leaflet maps with Socrata data? Leaflet, a friendly and flexible open-source code library for creating interactive web maps, plays nicely with Socrata, an open data platform used by several government agencies and organizations. Benefits of pairing Leaflet and Socrata: Although the Socrata data platform includes built-in visualization tools for anyone to create charts and maps, Leaflet gives you more control over your map design. Furthermore, Leaflet allows you to create maps that bring together data from both Socrata and non-Socrata sources. Socrata datasets include an API (application program interface) endpoint, in the form of a web address. This endpoint enables other computers to easily access the most recent data online, instead of a static version that was manually downloaded. Newer Socrata datasets that include locations (such as latitude and longitude coordinates) also provide endpoints in GeoJSON format. Since Leaflet maps easily process GeoJSON data, only a few lines of code are required. However, Socrata GeoJSON endpoints do not currently support “real-time” data, such as up-to-the-minute locations of public transportation, etc. In these cases, you may need to access data through a provider other than Socrata, most likely in a different format, which may require more coding skills. About Socrata API endpoints Go to any Socrata open data platform, find a dataset, and click the API tab. As an example, you can use City of Hartford’s Police Incidents dataset. Police Incidents dataset on Hartford Open Data portal Copy the API endpoint. The default version is JSON. If you’re new to APIs, test the endpoint by pasting it into your browser address line. Ideally you would see a formatted JSON view (use Chrome or Firefox for better results). Formatted JSON example in Firefox If your browser does not support JSON view, you will see the raw JSON stream only, like the one shown below. Unformatted JSON example in Firefox Test if this Socrata endpoint supports GeoJSON format by changing the extention in the API dropdown menu from JSON to GeoJSON. GeoJSON format works best with Leaflet because the coding is simpler. If your endpoint supports GeoJSON format, your browser will display a data stream similar to the one below. Formatted GeoJSON example in Firefox If your Socrata endpoint only supports JSON format, but includes data columns with latitude and longitude, see other Leaflet examples further below. Register for Socrata App Token Socrata requires developers to register for a free app token at https://opendata.socrata.com/signup Demonstration Maps GeoJSON endpoint with circle markers and tooltips map https://handsondataviz.github.io/leaflet-socrata/index.html code https://github.com/handsondataviz/leaflet-socrata/index.html data https://data.hartford.gov/Public-Health/Current-Class-1-Class-4-Food-Establishments/xkvv-76v8 note: location data appears as latitude and longitude coordinates in the geom column steps to create your own (MORE TODO HERE) select API button, copy endpoint, and change suffix from .json to .geojson copy this Leaflet map template, which includes this key section of code: paste and explain the code GeoJSON endpoint with simple data filter, default marker styling and pop-up info map https://handsondataviz.github.io/leaflet-socrata/index-geojson-filter code https://github.com/handsondataviz/leaflet-socrata/ data https://data.ct.gov/Environment-and-Natural-Resources/Agricultural-Commoditites-Grown-By-Farmer/y6p2-px98 Multiple Socrata datasets with Leaflet control layers legend map https://handsondataviz.github.io/leaflet-socrata/index-control-layers.html code https://github.com/handsondataviz/leaflet-socrata/index-control-layers.html Older JSON-only endpoint, with separate columns for latitude, longitude map https://handsondataviz.github.io/leaflet-socrata/index-json.html code https://github.com/handsondataviz/leaflet-socrata/index-json.html data https://opendata.demo.socrata.com/Government/Kentucky-Farmers-Market-Map/3bfj-rqn7 Learn more: - https://dev.socrata.com/ - https://github.com/chriswhong/simpleSodaLeaflet Thanks to Chris Metcalf https://github.com/chrismetcalf Tyler Klyeklamp https://data.ct.gov/ TODO: blend this section into the one above Pull Open Data into Leaflet Map with APIs {- #leaflet-maps-open-apis} TODO: Decide whether to keep or not. Up to this point in the book, we’ve built charts and maps using static data that you have downloaded from other sites. But some open data repositories have APIs, or application program interfaces, which means the software that allows computers to communicate with one another. Below is a Leaflet Map template that uses APIs to pull in the most current data from three different open repository platforms: Socrata, Esri ArcGIS Online, and USGS. Try it: Explore the map below or view full-screen version in a new tab How it works Go to the GitHub repo for the map above: https://github.com/handsondataviz/leaflet-data-apis Explore the code to see how different APIs work. For example, see the first map overlay, which pulls Connecticut School Directory data from the CT Open Data repository on a Socrata open data platform: https://data.ct.gov/resource/v4tt-nt9n Inside the open data repo, look for an API button and copy the endpoint. Screenshot: Sample API endpoint in Socrata open data repo Paste the endpoint link into your browser, change the suffix from .json to .geojson and press return. In order to show the endpoint data as points on a map in this simple Leaflet template, the points must already be geocoded inside the open data repo, and the platform must support a GeoJSON endpoint. In your browser, one sign of success is a long stream of GeoJSON data like this: Screenshot: API endpoint with .geojson suffix in Chrome browser In this section of the Leaflet map template, the code includes a jQuery function $.getJSON to call the open data endpoint in GeoJSON format: https://data.ct.gov/resource/v4tt-nt9n.geojson. It also requires a Socrata app token, and you can get your own token for free at: https://dev.socrata.com/register. Each geocoded school in the Socrata data repository is displayed as a blue circle, with data properties (such as: name) in a clickable pop-up. // load open data from Socrata endpoint in GeoJSON format // with simple marker styling: blue circles // register your own Socrata app token at https://dev.socrata.com/register // Connecticut School Directory, CT Open Data, https://data.ct.gov/resource/v4tt-nt9n $.getJSON(&quot;https://data.ct.gov/resource/v4tt-nt9n.geojson?&amp;$$app_token=QVVY3I72SVPbxBYlTM8fA7eet&quot;, function (data){ var geoJsonLayer = L.geoJson(data, { pointToLayer: function( feature, latlng) { var circle = L.circleMarker(latlng, { radius: 6, fillColor: &quot;blue&quot;, color: &quot;blue&quot;, weight: 2, opacity: 1, fillOpacity: 0.7 }); circle.bindPopup(feature.properties.name + &#39;&lt;br&gt;&#39; + feature.properties.district_name); // replace last term with property data labels to display from GeoJSON file return circle; } }).addTo(map); // display by default controlLayers.addOverlay(geoJsonLayer, &#39;Public Schools (CT Open Data-Socrata)&#39;); }); Fork a copy of this repo, play with the code, and try to insert GeoJSON endpoints from other open data repositories. Summary TODO "],
["transform.html", "Chapter 12 Transform Your Map Data", " Chapter 12 Transform Your Map Data All maps, including interactive web maps, are made up of different layers. These are background basemaps, colored or shaded polygons (also known as choropleth layers), lines, and point data that are often represented as markers. In this chapter, we will look at multiple ways to convert and edit geospatial data to create layers (files) that you can use in your favorite mapping tools. We will begin by looking at strategies to geocode large datasets, such as 10,000 addresses, with US Census tools. We will then talk about polygons and why you should normalize your data before creating choropleth maps. These map transformations happen inside spreadsheets, so you won’t directly deal with map data until you are halfway through the chapter. Before you can dive into creating shapes and dealing with boundaries in the map, we will introduce various file formats (most notably GeoJSON) and talk about geospatial data in general. You will learn that map data can be raster and vector, that geospatial data consists of location and attribute components, and how GeoJSON is different from Shapefiles and other geographical data formats. With our tutorials, you will learn how to convert or draw your own layer of map polygons or polylines on top of satellite imagery using the GeoJson.io tool, and also how to edit geospatial data and join it with spreadsheet data using the Mapshaper tool. Both are powerful, web-based open-source geodata tools that for common tasks can substitute for more complex geographic information system tools, such as ArcGIS or QGIS. Finally, you’ll also learn how to georectify a digitized map to display as a background overlay using the MapWarper tool. By the end of this chapter, you should feel much more confident navigating the overwhelming world of geospatial data. "],
["bulk-geocode.html", "Bulk Geocode with the US Census", " Bulk Geocode with the US Census In Chapter 2: Strengthen Your Spreadsheet Skills, you learned how to geocode addresses with a Google Sheets Add-On called Geocoding by SmartMonkey. Geocoding converts street addresses to latitude-longitude coordinates (such as 300 Summit St, Hartford CT, USA to 41.75, -72.69) that can be placed on maps. While the Geocoding by SmartMonkey Add-On for Google Sheets works well for medium-sized batches of addresses, sometimes you need a faster geocoding service for larger jobs. One of the fastest ways to geocode up to 10,000 US addresses at a time is to use the US Census Geocoder. First, create a CSV file with 5 columns. Your file must not contain a header row, and needs to be formatted the following way: | 1 | 300 Summit St | Hartford | CT | 06106 | | 2 | 1012 Broad St | Hartford | CT | 06106 | Column 1: Unique IDs for each address, such as 1, 2, 3, etc. While it does not necessarily have to start at 1 or be in consecutive order, this is the easiest. To quickly create a column of consecutive numbers in most spreadsheets, enter 1, select the bottom-right corner of the cell, hold down the Option or Control key and drag your mouse downward. TODO: See if this method works in Excel for Windows, Chromebook. Column 2: Street address. Column 3: City. Column 4: State. Column 5: Zip Code. Tip: If your original data combines address, city, state, and zip into one cell, then see how to Split Data into Separate Columns in Chapter 4: Clean Up Messy Data. But if your street addresses contain apartment numbers, you can leave them in. Second, upload your CSV file to the US Census Geocoder address batch form. Select Find Locations Using… &gt; Address Batch, then choose your file to upload. Select Public_AR_Current as the benchmark, and click Get Results. Note: In left-side menu, you can switch from Find Locations to Find Geographies if you wish to obtain additional information, such as the GeoID for each address. The US Census assigns a unique 15-digit GeoID to every place, and a sample (such as 090035245022001) consists of the state (09), followed by the county (003), the census tract (524502, or more conventional 5245.02), the census block group (2), and finally the census block (001). In a few moments the tool will return a file named GeocodeResults.csv with geocoded results. It usually takes longer for larger files. Save it, and inspect it in your favorite spreadsheet tool. The resulting file is an eight-column CSV file with the original ID and address, match type (exact, non-exact, tie, or no match), and latitude-longitude coordinates. A tie means there are multiple possible results for your address. To see all possible matches of an address that received a tie, use One Line or Address tools in the left-side menu and search for that address. Tip: If you see some unmatched addresses, use a filtering functionality of your spreadsheet to filter for unmatched addresses, then manually correct them, save as a separate CSV file, and re-upload. You can use the US Census Geocoder as many times as you want, as long as a single file doesn’t exceed 10,000 records. To learn more about this service, read the Overview and Documentation section of the US Census Geocoder. If for some reason you cannot geocode address-level data, but you need to produce some mapping output, you can use pivot tables to get counts of points for specific areas, such as towns or states. In the next section, we will look at hospital addresses in the US and how we can count them by state using pivot tables. "],
["pivot-point-to-polygon.html", "Pivot Address-Level Point Data into Polygon Data", " Pivot Address-Level Point Data into Polygon Data If you deal with geographical data, you may find yourself in a situation where you have a list of addresses which need to be counted (aggregated) by area and displayed as a polygon map. In this case, a simple pivot table in a spreadsheet software can solve the problem. Note: A special case of a polygon map is a choropleth map, which represents polygons that are colored in a particular way to represent underlying values. A lot of polygon maps end up being choropleth maps, so we will be using this term a lot in this book. Let’s take a look at a list of all hospitals that are registered with the Medicare program in the United States. The dataset is stored and displayed by Socrata, a web database popular among government agencies and city administrations. This particular dataset has information on each hospital’s name, location (nicely divided into Address, City, State, and ZIP Code columns), a phone number and some other indicators, such as mortality and patient experience. Now, imagine you are given a task to create a choropleth map of total hospitals by US state. Instead of showing individual hospitals as points (as in Figuere 12.1a ), you want darker shades of blue to represent states with more hospitals (as in Figure 12.1b). (ref:pivot-address) You can count addresses by state (or other area) to produce polygon, or choropleth, maps instead of point maps. Figure 12.1: (ref:pivot-address) First, save the database to your local machine by going to Export &gt; Download &gt; CSV of Socrata interface. Figure 12.2 shows where you can find the Export button. Figure 12.2: In Socrata, you can export the entire dataset as a CSV. Next, open the file in your favorite spreadsheet tool. If you use Google Sheets, use File &gt; Import &gt; Upload to import CSV data. Make sure your address columns are present, and move on to creating a pivot table (in Google Sheets, go to Data &gt; Pivot table, make sure the entire data range is selected, and click Create). In the pivot table, set Rows to State, because we want to get counts by state. Next, set pivot table’s Values to State—or really any other column that has no missing values—and choose Summarize by: COUNTA. Voila! Figure 12.3: Use pivot tables in any spreadsheet software to count addresses per area (such as state, county, of zip code). Your aggregated dataset is ready, so save it as a CSV. If you use Google Sheets, go to File &gt; Download &gt; Comma-separated values (.csv, current sheet). You can now merge this dataset with your polygons manually using editing capabilities of GeoJson.io, or merge it all in one go using powerful Mapshaper. We will introduce both tools in the next few sections. But before we do that, let’s talk about data normalization and why showing counts of hospitals per state doesn’t really tell a good story. "],
["normalize.html", "Normalize Data to Create Meaningful Choropleth Maps", " Normalize Data to Create Meaningful Choropleth Maps Choropleth maps are best when they represent relative, not absolute values. Consider two maps shown in Figure 12.4. They both are about Covid-19 cases in the US states (excluding Alaska and Hawaii) as of June 26, 2020. Figure 12.4a shows total number of recorded cases per state, and Figure 12.4b shows Covid-19 cases adjusted by the state’s population. Darker colors represent higher values. Do you notice any differences in spatial patterns? Figure 12.4: Choropleth maps work best with normalized values. Both maps show Covid-19 data collected by the New York Times and published on GitHub. In the map in Figure 12.4b, we normalized (divided) values by population in each state, according to the 2018 US Census American Community Survey, the most recent data available on the day of writing. We didn’t add legends and other important cartographic elements so that you can better focus on interpreting spatial patterns. In both cases, we used Jenks natural breaks for classification. What are the worst-hit states according to the map showing total Covid-19 counts (shown in Figure 12.4a)? If you are familiar with the US geography, you can quickly tell that these are New York, New Jersey, Massachusetts, Florida, Illinois, Texas, and California. But five of these happen to be some of the most populous states in the US, so it makes sense that they will also have higher Covid-19 cases. Now, how about the map in Figure 12.4b? You can see that New York and its neighbors, including New Jersey and Massachusetts, have by far the highest rates per capita (per person), which we saw in the first map. But you can also see that in fact California, Texas, and Florida were impacted to a lesser extent than the map on the left had suggested. So the map with per-capita values is a much better illustration to the story about New York being the first epicenter of the Covid-19 crisis in the United States. Different ways to normalize data You can normalize data in many ways, and there is not necessarily one acceptable way of doing it. One of the most common ways of normalization is deriving “per capita”, or “per person” values. If values are small, such as rare disease cases or lottery winners, they can be presented as “per 1,000” or “per 100,000” people. Divide your quantity by population in that area to derive per capita values. Choropleth maps work well with percentages. The good news is, humans like percentages too. It is quite natural for us to understand that a 9% unemployment rate means that of 100 people who were willing to work, nine were unable to find a job. To derive a percentage for unemployment, divide the number of unemployed people by labor force size (adult population who are willing and able to work), and multiply by 100. Unlike counts, most measured variables do not need normalization because they belong to a scale. For example, median age (the age of the “middle” person in a population, when sorted from youngest to oldest) can be directly compared among populations. We know that humans live anywhere between 0 and 120 years or so, and we wouldn’t expect median ages to be vastly different from one country to another (maybe twice, but not tenfold). Median incomes, if measured in the same currency, also belong to the same scale and can be compared directly. How not to normalize values Absolute values are very important for context. Saying that “20% of blond men living in in town X won the lottery” may sound like a catchy headline, but in reality the town has 450 residents, of those 200 are men, and of those only 5 have light hair color. One of those five (and here comes the 20%) was lucky to win the lottery, so technically the headline didn’t lie. This is, of course, an extreme and comic example, but exaggerations in this spirit are not uncommon. If you want readers to trust you, make sure you are open about total counts when reporting normalized values (such as percentages or per capita values). Absolute values are important for another reason: behind numbers there are often people, and smaller, normalized values may hide the scale of the problem. Saying that “the unemployment rate is only 5%” is valid, but the 5% of, say, Indian labor force (around 522 million) is about 26 million, which is pretty much the total population of Australia. Exercise your best judgement when you normalize values. Make sure you don’t blow numbers out of proportion by normalizing values in smaller populations. But also don’t hide large counts behind smaller percentages for larger populations. At this point, you should have enough geocoding and spreadsheet skills to aid you with map making. In the following section, we will talk about geographical data in general and will introduce different geospatial file formats to ensure you are ready to create, use, and share map data. "],
["convert-geojson.html", "Convert to GeoJSON format", " Convert to GeoJSON format Geospatial data comes in an overwhelming number of file formats. We will tell you about a few most common ones so that you have a general idea of what tools you can use to work with them. But before we do that, let’s talk about the basics of geospatial (map) data. About geospatial data The first thing to know about geospatial data is that it consists of two components, location and attribute. When you use Google Maps to search for a restaurant, you get a red marker on the screen that points to the latitude and longitude of the physical location of the restaurant in the real world. These latitude and longitude (two numbers) are your location component. The name of the restaurant, its human-friendly address, and guest reviews are the attributes, which bring value to your location data. Second, geospatial data can be raster or vector, as illustrated in Figure 12.5. Raster data, as shown in Figure 12.5a, is a grid of cells (“pixels”) of a certain size (for example, 1 meter by 1 meter). For example, satellite images of the Earth that you see on Google Maps are raster geospatial data. Each pixel contains the color of Earth that satellite cameras were able to capture. People and algorithms can then use raster data (images) to create outlines of buildings, lakes, roads, and other objects. These outlines become vector data. For example, most of OpenStreetMap was built by volunteers tracing outlines of objects from satellite images. Figure 12.5: Geospatial data can be raster or vector. In this book, we will focus on vector data, which is based on points, lines, and polygons, as shown in Figure 12.5b. Vector data can be much more precise than raster data, because points’ coordinates can be expressed with precise decimals. In addition, vector data can contain as much extra attribute information about each object as desired, whereas raster data is generally limited to 1 value per cell, whether it is the Earth color, or temperature, or altitude. Moreover, vector map files are usually much smaller in size than raster ones. Let’s take a look at some of the most common vector file formats. GeoJSON GeoJSON is a newer, popular open format for map data that comes in .geojson or .json files. It was first developed in 2008, and then standardized in 2016 by the Internet Engineering Task Force (IETF). The code snippet below represents a single point (feature) with latitude of 41.76 and longitude of -72.67 in GeoJSON format. That point has a name attribute (property) whose value is Hartford. { &quot;type&quot;: &quot;Feature&quot;, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [-72.67, 41.76] }, &quot;properties&quot;: { &quot;name&quot;: &quot;Hartford&quot; } } The simplicity and readability of GeoJSON allows you to edit it even in the most simple text editor. We strongly recommend you use and share your map data in GeoJSON. Web-based maps, such as those built with Leaflet, Mapbox, Google Maps JS API, and Carto, as well as ArcGIS and QGIS all support GeoJSON. By having your geospatial data stored and shared in GeoJSON, you ensure you can use it on the web with nearly any mapping tool. You can also be confident that other people will be able to use and extract data from the file without bulky and often expensive GIS software installed. Also, your GitHub repository will automatically display any GeoJSON files in a map view, like is shown in Figure 12.6. Figure 12.6: GitHub can show previews of GeoJSON files stored in repositories. Warning: In GeoJSON, coordinates are ordered in longitude-latitude format, the same as X-Y coordinates in mathematics. This is the opposite of Google Maps and some other web map tools, which order values as latitude-longitude. For example, Hartford, Conn. is located at (-72.67, 41.76) according to GeoJSON, but at (41.76, -72.67) in Google Maps. Neither notation is right or wrong, just make sure you know which one you are dealing with. Tom MacWright created a great summary table showing lat/lon order of different geospatial formats and technologies. Shapefiles The shapefile format was created in the 1990s by Esri, the company that develops ArcGIS software. Shapefiles typically appear as a folder of subfiles with suffixes such as .shp, .shx, and .dbf. The folder with shapefiles is often compressed in a .zip file. Although government agencies commonly distribute map data in shapefile format, the standard tools for editing these files—ArcGIS and its free and open-source cousin, QGIS—are not as easy to learn as other tools in this book. For this reason, we recommend converting shapefiles into GeoJSON files if possible. Mapshaper, discussed a bit later in the chapter, can perform such conversion. GPS Exchange Format (GPX) If you ever exported your Strava run or a bike ride from a GPS device, chances are you ended up with a .gpx file. GPX is an open standard and is based on XML markup language. Like GeoJSON, you can inspect a GPX file in any simple text editor to see its contents. Most likely, you will see a collection timestamps and latitude/longitude coordinates of the recording GPS device at that particular time. You should be able to convert GPX to GeoJSON with GeoJson.io utility discussed later in this chapter. Keyhole Markup Language (or KML) The KML format rose in popularity during the late 2000s. It was developed for Google Earth, a free and user-friendly tool that allowed many people to view and edit two- and three-dimensional geographic data. KML files were often used with maps powered by Google Fusion Tables, but that became history in late 2019. GeoJson.io should be able to convert your KML file into a GeoJSON. Sometimes .kml files are distributed in a compressed .kmz format. See Converting from KMZ to KML format section of this book to learn to convert. MapInfo TAB Similar to Esri’s shapefiles, MapInfo’s TAB format comes as a folder with .tab, .dat, .ind, and some other files. It is a proprietary format created and supported by MapInfo, Esri’s competitor, and is designed to work well with MapInfo Pro GIS software. Unfortunately, you will most likely need MapInfo Pro, QGIS, or ArcGIS to re-save these as GeoJSON or a Shapefile. We’ve mentioned only a handful of the most common geospatial file formats. There is a myriad of other, less known formats for both raster and vector data. Remember that GeoJSON is one of the best, most universal formats for your vector data, and we strongly recommend to store and share your map data in GeoJSON. In the next section, we will look at free online tools to create, convert, join, crop, and in other ways manipulate GeoJSON files. "],
["geojsonio.html", "GeoJson.io to Convert, Edit, and Create Map Data", " GeoJson.io to Convert, Edit, and Create Map Data GeoJson.io is a popular open-source web tool to convert, edit, and create GeoJSON files. The tool was originally developed by Tom MacWright in 2013 and quickly became a go-to tool for geospatial practitioners. In this tutorial, we will show you how to convert existing KML, GPX, TopoJSON, and even CSV files with lat/lon data into GeoJSON files. We will also look at editing attribute data and adding new features to GeoJSON files, and creating them from scratch by tracing satellite imagery. Convert KML, GPX, and other formats into GeoJSON Navigate to GeoJson.io. You will see a map on the left, and a Table/JSON attribute view area on the right. At the start, it represents an empty feature collection (features are your points, lines, and polygons). Drag and drop your geospatial data file into the map area on the left. Alternatively, you can also import a file from Open &gt; File menu. If you don’t have a geospatial file, download Hartford parks in KML format. If GeoJson.io was able to recognize and import the file, you will see a green popup message in the upper-left corner saying how many features (in case of Hartford parks, polygons) were imported. Figure 12.7 shows us that 62 features were imported from the sample Hartford parks file. You can see that the polygons appeared on top of the Mapbox world layer. Note: If GeoJson.io couldn’t import your file, you will see a red popup saying it “Could not detect file type”. You will need to use a different tool, such as Mapshaper or QGIS, to convert your file to GeoJSON. Figure 12.7: GeoJson.io successfully imported Hartford parks KML file. You can now save your file to GeoJSON. Go to Save &gt; GeoJSON to download a converted GeoJSON file to your computer. Create GeoJSON from a CSV file GeoJson.io can transform a spreadsheet with latitude (or lat) and longitude (or lon) columns into a GeoJSON file of point features. Each row in the spreadsheet becomes its own point, and all columns other than lat and lon become attributes (or properties) of point features. An example of such spreadsheet is shown in Figure 12.8. You can download it for the exercise. Figure 12.8: A spreadsheet with lat/lon columns can be transformed into a GeoJSON with point features. Save your spreadsheet as a CSV file, and drag-and-drop it to the map area of GeoJson.io. You should see a green popup in the upper-left corner notifying you how many features were imported. Note: If you had some data on the map already, GeoJson.io wouldn’t erase anything but instead would add point features to the existing map. Click on a marker to see a popup with point properties. If you used the sample file with towns around Hartford, you will see town, community_type, and wiki_link features in addition to the tool’s default marker-color, marker-size, and marker-symbol fields. Tip: The popup is interactive, and you can click and edit each property (including property names). You can also add a new property by clicking the Add row button. You can delete the marker by clicking Delete feature button. Click Save to record all marker changes to the GeoJSON. This will close the popup window, and you will see updated markers in the JSON tab to the right of the map. It may be quicker to view all data as a table instead of dealing with individual marker popups. In the Table tab to the right of the map, you can add, rename, and remove columns from all features (markers) at once. Table cells are also modifiable, so you can edit your data there. Once you are happy with your map data, go to Save &gt; GeoJSON to download the result to your computer. You can also log into GeoJson.io with your GitHub account and save directly to your repository. Figure 12.9: A spreadsheet with coordinates columns can be transformed into a GeoJSON with point features. Create a GeoJSON from scratch using drawing tools GeoJson.io lets you create geospatial files from scratch, using simple drawing tools to put markers (points), lines, and polygons to appropriate locations. These are useful when you have no original file to work with. The following steps will show you how to create a new GeoJSON file and add markers, lines, and polygons to it. Open GeoJson.io and in the lower-left corner switch from Mapbox (vector tiles) to Satellite. In the upper-right corner of the map, use the Search tool to find the area you’re interested in mapping. For this exercise, we will use tennis courts at Trinity College, Hartford, as shown in Figure 12.10. Figure 12.10: Use drawing tools to create points, lines, and polygons in GeoJson.io. In the toolbar, you have a choice of four drawing tools: a polyline (which is a series of points connected by lines, but not closed like a polygon), a polygon, a rectangle (which is just an instance of a polygon), and a marker (point). Let’s start by creating a marker. Click on the Draw a marker button, and click anywhere on the map to place it. You will see a gray marker that is now part of your map. You can modify its properties, or delete it in the interactive pop-up. Next, choose Draw a polyline and click on multiple locations in the map to see connected lines appearing. To finish and create a feature, click again on the final point. Polylines are generally used for roads and paths. Drawing a polygon is similar to drawing a polyline, except that you need to complete the feature by making your final point at the same location as your initial point. Polygons are used to define object boundaries, from continents to buildings, cars, and anything that has significant dimensions. Use Edit layers tool (the one above Delete) to move a marker to a better position, or adjust the shapes of your features. Once you are done creating features and their physical boundaries, it is time to add meaningful attribution data. Use the interactive popups or the Table view to give objects names and other qualities. When finished, save the GeoJSON to your computer. Drawing tools can be used to correct your existing GeoJSON files. For example, if you created a GeoJSON from a CSV file, you might decide to move some markers with Edit layers tool instead of modifying their latitude and longitude values. Or you might decide that your polygons (eg those representing Hartford parks) are too “simplified”, and make them more precise with the satellite imagery. In the next section, we will introduce Mapshaper, another free online tool to convert and modify geospatial files. "],
["mapshaper.html", "Mapshaper to Convert, Edit, and Join Data", " Mapshaper to Convert, Edit, and Join Data Like GeoJson.io, Mapshaper is a free, open-source editor that can convert geospatial files, edit attribute data, filter and dissolve features, simplify boundaries to make files smaller, and many more. Unlike GeoJson.io, Mapshaper doesn’t have drawing tools, so you won’t be able to create geospatial files from scratch. Mapshaper is developed and maintained by Matthew Bloch on GitHub. It is written in JavaScript, so we recommend you use a recent version of Firefox or Chrome. This free and easy-to-learn Mapshaper web tool has replaced many of our map preparation tasks that previously required expensive and hard-to-learn ArcGIS software, or its free but still-challenging-to-learn cousin, QGIS. Even advanced GIS users may discover Mapshaper to be a quick alternative for some common but time-consuming tasks. Import, convert, and export map boundary files You can use Mapshaper to convert between geospatial file formats. Unlike GeoJson.io, Mapshaper also supports Esri Shapefiles (which is a folder of individual files with the same name, but different file extensions), so you can easily convert a Shapefile into a web-friendly GeoJSON. In the following steps, we will convert a geospatial file by import it to Mapshaper, and then export it as a different file type. Navigate to Mapshaper.org. The start page is two large drag-and-drop zones which you can use to import your file. The smaller area at the bottom, Quick import, uses default import settings and is a good way to begin. Drag and drop your geospatial file to the Quick import area, or use our sample Shapefile of US state boundaries. This is a .zip archive which contains a folder with all necessary files. Note: If you want to import a folder, you need to either select all files inside that folder and drop them all together to the import area, or create a .zip archive. Each imported file becomes a layer, and is accessible from the dropdown menu in the top-middle of the browser window. There, you can see how many features each layer has, toggle their visibility, or delete them. To export, go to Export in the upper-right corner, and select a desired file format. The choice of export formats is shown in Figure 12.11. As of July 2020, these are Shapefile, GeoJSON, TopoJSON (similar to GeoJSON, but with topographical data), JSON records, CSV, or SVG (Scalable Vector Graphics, for web and print). If you export more than one layer at a time, Mapshaper will archive them first, and you will download an output.zip that contains all exported layers. Figure 12.11: You can use Mapshaper to quickly convert between geospatial file formats. Tip: Mapshaper doesn’t work with KML or KMZ files, but you can use GeoJson.io to convert these. Edit data for specific polygons You can edit attribute data of individual polygons (and also points and lines) in Mapshaper. Figure 12.12 shows you how. Import the file whose polygon attributes you want to edit. Under the cursor tool, select edit attributes. Click on the polygon you want to edit. A pop-up will appear in the upper-left corner listing all attributes and values of the polygon. Click on any value (underlined, in blue) and edit it. When you are done, export your geospatial file by clicking Export and choosing the desired file format. Figure 12.12: Use edit attributes tool (under Cursor tool) to edit attributes of polygons, lines, and points. Simplify map boundaries to reduce file size You may not need precise and detailed map boundaries for data visualization projects where zoomed-out geographies are shown. Detailed boundaries are heavy, and may slow down your web maps. Consider two maps of the contiguous US states (also known as the lower 48, the term Ilya learned in 2018 while travelling in Alaska), shown in Figure 12.13. The map in Figure 12.13a is more detailed and is about 230 kilobytes, but the map in Figure 12.13b is only 37 kilobytes, 6 times smaller! Figure 12.13: Consider simplifying geometries with Mapshaper to make your web maps faster. To simplify map boundaries in Mapshaper, follow the steps below. Import your geo file to Mapshaper. You can use the sample contiguous US states GeoJSON. Click the Simplify button in the upper-right corner. The Simplification menu will appear, where you can choose one of three methods. We recommend checking prevent shape removal, and leaving the default Visvalingam / weighted area. Click Apply. You will see a slider with 100% appear on top (Figure 12.14), replacing the layer selection dropdown. Move the slider to the right and see the map simplify its shape as you go. Stop when you think the map looks appropriate (when the shapes are still recognizable). Mapshaper may suggest to repair line intersections in the upper-left corner. Click Repair. You can now export your file using the Export feature. Figure 12.14: Use Simplify &amp; Repair tools in Mapshaper. Tip: You may find the US shape a bit unusual and vertically “shrunk”. In Console, type -proj EPSG:3857 to change projection to Web Mercator, which is more common. Dissolve internal polygons to create an outline map Mapshaper’s most powerful tools are available through the Console, which allows you to type commands for common map editing tasks. One of such tasks is to create an outline map by removing the internal boundaries. For example, you can dissolve state boundaries of the US map in the previous exercise to get the outline of the country, like is shown in Figure 12.15. Figure 12.15: Mapshaper lets you dissolve boundaries to create an outline shape. Click the Console button, which opens a window to type in commands. Enter the command below, then press return (Enter). -dissolve You will see that internal boundaries became lighter color, and that’s Mapshaper’s way of saying they no longer exist. You can now export your outline shape. Clip a map to match an outline layer The state of Connecticut consists of 8 counties, which in turn are divided into towns. There are a total of 169 towns in Connecticut. Imagine you are given a boundary file of all 169 towns, and the outline of Hartford county. You need to “cut” the original towns map to only include those towns that fall within Hartford county. Mapshaper allows you to do just that using one simple -clip command. Import two boundary files into Mapshaper. One is the larger one that is being clipped (if you use sample files, ct-towns), and one is the desired final shape (hartfordcounty-outline). The latter is what ArcGIS calls the “clip feature”. Make sure your active layer is set to the map you are clipping (ct-towns). In the Console, type -clip followed by the name of your clip layer, like that: -clip hartfordcounty-outline You should see your active layer got clipped. Sometimes you end up with tiny “slivers” of clipped areas that remain alongside the borders. If that is the case, use the -filter-slivers command to remove them, like that: -clip hartfordcounty-outline -filter-slivers Your Mapshaper state should look like pictured in Figure 12.16. You can now save the file on your computer using the Export button. Figure 12.16: When clipping, make sure your active layer is the one being clipped (with many features), not the clipping feature iteslf. Remove unwanted data fields Sometimes map features, such as polygons, lines, and points, contain unwanted attributes (or fields, or columns) that you may want to remove. In the Console, type the -filter-fields editing command to remove unnecessary fields. For example, remove all fields except town: -filter-fields town If you want to leave more than one field, separate them by a comma, but without spaces, like that: -filter-fields town,state Warning: If you leave a space after comma, you will get a Command expects a single value error. Join spreadsheet data with polygon map Combining spreadsheet data with geographical boundaries is a common task for geospatial practitioners. Imagine you have a file with Connecticut town boundaries, and you want to add population data to each of them in order to build a choropleth map. Mapshaper provides a powerful -join command to join such files. Remember that you need some common keys in both datasets (such as town name, or state, or country) in order to join files. Otherwise Mapshaper has no way of knowing which numbers belong to which polygons. Import both geospatial file and a CSV dataset into Mapshaper using Quick import box. Make sure both files appear in the drop-down list of layers. Your CSV data will be shown as something that resembles a table. Use the Cursor &gt; inspect attributes tool to make sure the data is imported correctly. If you use the sample CT files, note that the ct-towns layer has name attribute with the name of the town, and ct-towns-popdensity has town names in the town column. Make your geospatial layer (ct-towns) is the one active. Open the Console, and use the -join command, like this: -join ct-towns-popdensity keys=name,town where ct-towns-popdensity is the CSV layer you are merging with, and keys are the attributes that contain values to join by. In case with our sample files, these would be town names which are stored in name attribute of the map file, and town column of the CSV file. You will see a message in the console notifying you if join was performed successfully, or if Mapshaper encountered any errors. Use the Cursor &gt; inspect attributes tool to make sure you see CSV columns as fields of your polygons, like is shown in Figure 12.17. You can now save the file to your computer by clicking the Export button. Figure 12.17: Mapshaper lets you join spatial and CSV files using common keys (for example, town names). Tip: To avoid confusion, it may be useful to re-name your CSV column that contains key values to match the key attribute name of your map. In our example, you would rename town column to name column in the CSV, and your command would end with keys=name,name. Do you remember aggregating address-level point records of hospitals into hospital counts per state discussed earlier in this chapter? Now is a good time to find that .CSV file and practice your merging skills. Count points in polygons with Mapshaper Mapshaper lets you count points in polygons, and record that number in polygon attributes using -join command. Import two geospatial files, one containing polygon boundaries (for example, US state boundaries), and another containing points that you want to aggregate (for example, hospitals in the US). Make sure your polygons (not points) layer is active by selecting it from the dropdown menu. In the Console, perform -join using a count() function, like this: -join hospitals-points calc=&#39;hospitals = count()&#39; fields= This command tells Mapshaper to count points inside hospitals-points layer and record them as hospitals attribute of the polygons. The fields= part tells Mapshaper to not copy any fields from the points, because we are performing many-to-one matching (many hospitals per state, in our case). Use the Cursor &gt; inspect attributes tool to make sure polygons obtained a new field with the recorded count of points, like is shown in Figure 12.18. Save the new file using Export button and choosing the desired output format. Figure 12.18: Mapshaper’s -join can count points in polygons. More about joins From the “Count points in polygons with Mapshaper” section of this chapter, you should recall that you do not need to specify keys if you want to perform join based on geographical locations between two geospatial layers (one being points, the other is polygons). If one of your files is a CSV, you need keys. If you don’t have a CSV table that matches the columns in your boundary map data, you can easily create one. Upload the boundary map to Mapshaper, and export in CSV format. Open the downloaded file in any spreadsheet tool. To match data columns in the CSV spreadsheet, use the VLOOKUP function. In real life, you will rarely have perfect files with one-to-one matches, so you might want to have more information about which features didn’t get matched so that you can fix your data. Mapshaper helps you keep track of data that is not properly joined or matched. For example, if the polygon map contains 169 features (one for each town in Connecticut), but the CSV table contains only 168 rows of data, Mapshaper will join all of those with matching keys, and then display this message: [join] Joined data from 168 source records to 168 target records [join] 1/169 target records received no data [join] 1/169 source records could not be joined To get more details on which values were not joined, add unjoined unmatched -info flags to your join command, like this: -join ct-towns-popdensity keys=name,town unjoined unmatched -info The unjoined flag saves a copy of each unjoined record from the source table into another layer named unjoined. The unmatched flag saves a copy of each unmatched record from the target table to a new layer named unmatched. And the -info flag outputs some additional information about the joining procedure to the console. Merge selected polygons with join and dissolve commands In Mapshaper, you can merge selected polygons into larger “clusters” using -join and -dissolve commands. Imagine that you are employed by the CT Department of Public Health, and your task is to divide 169 towns into 20 so-called Health Districts and produce a new geospatial file. By the way, health districts are a real thing in Connecticut. You should begin by creating a crosswalk of towns and their health districts. Computer scientists and those working with data often use the term crosswalk to describe some kind of matching between two sets of data, such as zipcodes and towns where they are located. In our case, the crosswalk can be as simple as a two-column CSV list of a town and its district, each on a new line. Because your boss didn’t give you a list of towns in a spreadsheet format, but instead a GeoJSON file with town boundaries, let’s extract a list of towns from it. Import ct-towns.geojson to Mapshaper using Quick import box. You can use the Cursor &gt; inspect attributes tool to see that each polygon has a name attribute with the name of the town. Save attribute data as a CSV file using Export button. Open the file in any spreadsheet tool. You will see that your data is a one-column file with a *name&amp; column that lists 169 towns. Create a second column titled merged and copy-paste values from the first, name column. At this point your spreadsheet contains two columns with the same values. Pick a few towns, for example West Hartford and Bloomfield, and assign “Bloomfield-West Hartford” to their merged column, like is shown in Figure 12.19. You may stop right here and move to the next step, or keep assigning district names to a few other neighboring towns. Figure 12.19: Create a two-column crosswalk of towns and which districts they should be merged to. Save this new file as ct-towns-merged.csv, and drag-and-drop it to Mapshaper on top of your ct-towns layer. Click Import. This new CSV layer will be added as ct-towns-merged and will appear as a series of table cells. From the dropdown menu, select ct-towns to get back to your map. Now you are ready to merge certain towns into districts according to your uploaded CSV file. Open the Console, and type: -join ct-towns-merged keys=name,name to join the CSV layer with the boundaries layer that you see on the screen, followed by -dissolve merged to dissolve polygons of towns according to the merged column of the CSV file. In our example, only Bloomfield and West Hartford are dissolved into a combined “Bloomfield-West Hartford” regional health district (with the shared boundary between towns becoming grayed out), and all of the other polygons remain the same. Figure 12.20 shows the final result. Figure 12.20: Merge polygons based on a predefined crosswalk. You can inspect attribute data of polygons using Cursor &gt; inspect attributes tool, and save the resulting file using the Export button. Learn more advanced MapShaper methods There are many more commands within Mapshaper that are worth exploring if you are serious about GIS, such as changing projections, filtering features using JavaScript expressions, assigning colors to polygons based on values, and many more. Explore the Wiki of Mapshaper project on GitHub for more commands and examples. "],
["mapwarper.html", "Georectify a Digitized Map with MapWarper", " Georectify a Digitized Map with MapWarper TODO: write this section about using MapWarper, a tool created and hosted by Tim Waters, to upload and georectify a scanned map. This means to properly position a scanned map based on standard coordinates, so that you can place it as an overlay on an interactive map, such as Leaflet Storymaps with Google Sheets. Anyone can upload and georectify a map on the developer’s public site at http://mapwarper.net, and also see how it’s used by organizations such as the New York Public Library at http://maps.nypl.org. Warning: MapWarper is a wonderful open-source tool and platform, but service may be interrupted. As of July 2020, the site warns: “Ran out of disk space. Maps older than 2 years will need re-warping to work. Downtime will happen again.” "],
["convert-kmz.html", "Convert a Compressed KMZ file to KML format", " Convert a Compressed KMZ file to KML format In the previous sections, we looked at using Geojson.io and Mapshaper to convert geospatial files. However, not all file types can be converted with these tools. This chapter shows a particular example of a commonly requested .kmz &lt;-&gt; .kml pair conversion with Google Earth Pro. KMZ is a compressed version of a KML file, and the easiest way to convert between the two is to use free Google Earth Pro (if you remember from Convert to GeoJSON format section, KML is a native format of Google Earth). Download and install Google Earth Pro for desktop. Double-click on any .kmz file to open it in Google Earth Pro. Alternatively, open Google Earth Pro first, and go to File &gt; Open and choose your KMZ file. Right-click (or control-click) on the KMZ layer under Places menu, and select Save Place As…, like is shown in Figure 12.21. Figure 12.21: In Google Earth Pro, right-click the KMZ layer and choose Save Place As. In the dropdown menu of Save file… window, choose KML format, like is shown in Figure 12.22. Figure 12.22: Save as KML, not KMZ. Alternatively, you can use any zip-utility to extract a KML file from KMZ. KMZ is simply a ‘zipped’ version of a KML file! Summary In this chapter, you learned to use pivot tables to count addresses (points) by geographical area, such as states or cities (polygons). You lerned that geospatial data can be vector or raster. The best file format to store, share, and use vector data is GeoJSON. You can use GeoJson.io to create, edit, or convert geospatial files inside your browser. Mapshaper is another online tool to convert, simplify, join or crop geospatial data. In the following chapter, we will talk detecting bias in charts and maps. so that you become a better storyteller and a more critical reader. "],
["detect.html", "Chapter 13 Detect Bias in Data Stories", " Chapter 13 Detect Bias in Data Stories TODO: Rewrite chapter While we like to believe data visualizations simply “tell the truth,” when you dig further into this topic, you realize that there are multiple ways to represent reality. In this chapter, you will learn how visualizations display the biases of the people and the software that create them. Although we cannot stop bias, we can teach people to look for and detect it, and be aware of our own. Sections in this chapter: How to Lie with Charts, inspired by Darrell Huff (1954) How to Lie with Maps, inspired by Mark Monmonier (1996) Enroll in our free online course TO DO add link, which introduces these topics in the brief video below, and offers more exercises and opportunities to interact with instructors and other learners. TODO: convert all to code-chunk iframes Learn more: - Darrell Huff, How to Lie with Statistics (W. W. Norton &amp; Company, 1954), http://books.google.com/books?isbn=0393070875 - Mark S. Monmonier, How to Lie with Maps, 2nd ed. (University of Chicago Press, 1996), http://books.google.com/books?isbn=0226534219 - Nathan Yau, “How to Spot Visualization Lies,” FlowingData, February 9, 2017, http://flowingdata.com/2017/02/09/how-to-spot-visualization-lies/ "],
["how-to-lie-with-charts.html", "How to Lie with Charts", " How to Lie with Charts One of the best ways to learn how to detect bias in data visualization is to intentionally manipulate a chart, and tell two (or more) opposing stories with the same data. You’ll learn what to watch out for when viewing other people’s charts, and think more carefully about the ethical issues when you design your own. This exercise was inspired by a classic book published more than fifty years ago: Darrell Huff, How to Lie with Statistics (W. W. Norton &amp; Company, 1954), http://books.google.com/books?isbn=0393070875 Right-click this link and Save to download this sample data in CSV format to your computer: us-gross-domestic-product-per-capita. This historical data on economic productivity comes from the World Bank, World Development Indicators, http://data.worldbank.org/data-catalog/world-development-indicators Upload the CSV file to your Google Drive (with Settings to Convert to Google format) to create a Google Sheet. Select the data cells and Insert &gt; Chart &gt; Line chart, similar to the default version shown below: In your Google Sheet chart, double-click the vertical y-axis to edit the Minimum and Maximum values. Screenshot: Edit the Min and Max values of the Y-axis Make the line look “flatter” (slower economic growth) by lowering the minimum to $36,000, and increasing the maximum to $100,000, as shown below: Make the line look like a “sharper increase” (faster economic growth) by increasing the minimum to $38,000, and lowering maximum to $52,000, as shown below: ** TO DO – add conclusion ** "],
["how-to-lie-with-maps.html", "How to Lie with Maps", " How to Lie with Maps One of the best ways to learn how to detect bias in data visualization is to intentionally manipulate a map, and tell two (or more) opposing stories with the same data. You’ll learn what to watch out for when viewing other people’s maps, and think more carefully about the ethical issues when you design your own. This exercise was inspired by Mark S. Monmonier, How to Lie with Maps, 2nd ed. (University of Chicago Press, 1996), http://books.google.com/books?isbn=0226534219 First, scroll through this data on Median Household Income for Hartford-area towns, 2011-15, from American Community Survey 5-year estimates. Or right-click to open this Google Sheet in a new tab. Next, explore two different polygon maps of the same data. Use the drop-down menu to compare “Extreme Differences” versus “Uniform Equality” Why are these two maps portray the same data so differently? To see the answer, look at the data ranges. . .. ** TO DO ** Create your own version… TODO: Add section on how interactive maps such as Google Maps change borders and data depending on the internet address of the user Summary TODO "],
["story.html", "Chapter 14 Tell Your Data Story", " Chapter 14 Tell Your Data Story TODO: Write this chapter: Tell the story about your data, including its most meaningful insights and limitations Write compelling titles, labels, and sentences to accompany your visualization. Call attention to the most meaningful insights in your chart, and explain any data limitations. This chapter draws inspiration from Cole Nussbaumer Knaflic, Storytelling with Data: A Data Visualization Guide for Business Professionals (Wiley, 2015), http://www.storytellingwithdata.com/book/ Beginning, Middle, and End Draw Attention to Meaning Integrate Story with Your Data Write Clearly about What You Visualize Acknowledge Limitations of the Data Credit Data Sources and Collaborators Credit sources and collaborators on dataviz products and readme files Under US law, you cannot copyright data, such as the raw information in the rows and columns of a spreadsheet. But you can copy, but representations of data can be protected by copyright. … explain… In the spirit of openness, we encourage you to share your data visualizations under a Creative Commons license… explain… in fact, this book is copyrighted, and the source text is publicly available under a Creative Commons TODO: TYPE license… Summary TODO "],
["fix.html", "A Fix Common Mistakes", " A Fix Common Mistakes TODO: Rewrite appendix to focus more broadly on “common mistakes” not just “code errors” Creating your data visualizations through code templates hosted on GitHub has multiple advantages over drag-and-drop tools. Coding gives you more power to customize their appearance and interactive features, and to control where your data and products reside online. But there’s also a trade-off. Code can “break” and leave you staring at a blank screen. Sometimes problems happens through no fault of your own, such as when a “code dependency” to an online background map or code library is unexpectedly interrupted. But more often it seems that problems arise because we make simple mistakes that break our own code. Whatever the cause, one big drawback of working with code is that you’re also responsible for fixing it. We designed this section as a guide to help new coders diagnose and solve common errors when working with code templates on GitHub. We understand the feeling you experience when a simple typo—such as a misplaced semicolon (;)—makes your data visualization disappear from the screen. Finding the source of the problem can be very frustrating. But breaking your code—and figuring out how to fix it—also can be a great way to learn, because trial-and-error on a computer often provides immediate feedback that supports the learning process and develops our thinking. TODO: Reorganize contents, perhaps using this outline? Problems with Mac computers Problems with data tables Problems with iframes (since this chapter appears before code templates) Problems with GitHub forking and hosting Problems with code templates Problems with Mac computers: cannot see filename extension Several tools in this book will not work properly if your computer does not display the filename extensions, meaning the abbreviated file format that appears after the period, such as data.csv or map.geojson. The Mac computer operating system hides these by default, so you need to turn them on by going to Finder &gt; Preferences &gt; Advanced, and check the box to Show all filename extensions, as shown in Figure A.1. Figure A.1: On a Mac, go to Finder then Preferences then Advanced and check the box to Show all filename extensions. Problems with data tables Avoid typing blank spaces after column headers—or any spreadsheet entries—since some data visualization tools will not match them with headers lacking a blank character. Problems with iframes My iframe does not appear in my web page Go back to the Embed tutorials in this book to double-check the directions Items listed in your iframe (such as the URL, width, or height) should be enclosed inside straight quotation marks (single or double) BROKEN iframe (missing quotation marks for width and height) &lt;iframe src=\"https://handsondataviz.github.io/leaflet-map-simple\" width=90% height=350&gt;&lt;/iframe&gt; FIXED iframe (with correct quotation marks) &lt;iframe src=\"https://handsondataviz.github.io/leaflet-map-simple\" width=\"90%\" height=\"350\"&gt;&lt;/iframe&gt; Use only https (the extra ‘s’ means ‘secure’), not http. Some web browsers will block content if it mixes http and https resources, and some code templates in this book require https. Screenshot: Replace http with https Use only straight quotes, not curly quotes. Avoid pasting text from a word-processor into GitHub, which can accidentally carry over curly quotes. Typing directly into the GitHub editor will create straight quotes. Screenshot: Curly quotes versus straight quotes TODO: Test one way to fix GitHub errors by going into the commits and going back to a previous version of the code. Is this possible in the web version? Safely Delete your GitHub Repo and Start Over If you need to delete your GitHub repo and start over, here’s a simple way to safely save your work: Go to the top-level of your GitHub repository, similar to https://github.com/USERNAME/REPOSITORY Click the green “Clone or Download” button, and select Download Zip to receive a compressed folder of your repo contents on your computer. In your GitHub repo, click on Settings (upper-right area) and scroll down to Delete This Repository. To prevent accidental deletions, GitHub requires you to type in the REPOSITORY name. Now you can start over in one of these ways: If you wish to Create a Simple Web Page with GitHub Pages, follow that tutorial again. OR Fork another copy of the original GitHub repository to your account. After you create your copy, if you wish to add selected files that you previously downloaded to your computer, follow directions to Upload Code with GitHub in the second half of this tutorial in this book Problems with Creating a Simple Web Page with GitHub Pages If you followed the Create a Simple Web Page with GitHub Pages tutorial, it should have created two web links (or URLs): your code repository, in this format: https://github.com/USERNAME/REPOSITORY your published web page, in this format: https://USERNAME.github.io/REPOSITORY Be sure to insert your GitHub username, and your GitHub repository name, in the general formats above. These URLs are NOT case-sensitive, which means that https://github.com/USERNAME and https://gitub.com/username point to the same location. My simple GitHub web page does not appear Make sure that you are pointing to the correct URL for your published web page, in the format shown above. Be patient. During busy periods on GitHub, it may take up to 1 minute for new content to appear in your browser. MOVE UP If your map does not appear right away, wait up to 30 seconds for GitHub Pages to finish processing your edits. Then give your browser a “hard refresh” to bypass any saved content in your cache and re-download the entire web page from the server, using one of these key combinations: Ctrl + F5 (most browsers for Windows or Linux) Command + Shift + R (Chrome or Firefox for Mac) Shift + Reload button toolbar (Safari for Mac) Ctrl + Shift + Backspace (on Chromebook) Test the link to your published web page in a different browser. If you normally use Chrome, try Firefox. On rare occasions, the GitHub service or GitHub Pages feature may be down. Check https://status.github.com. My simple GitHub web page does not display my iframe If you followed the Create a Simple Web Page with GitHub Pages tutorial and inserted an iframe in the README.md file, it will appear in your published web page, under these conditions: Ideally, your README.md should be the ONLY file in this GitHub repository Any other files in your repo (such as index.html, default.html, or index.md) will block the iframe HTML code in your README.md from being published on the web. If you accidentally selected a GitHub Pages Theme, you need to delete any extra files it created: click each file, select trash can to delete it, and commit changes. Screenshot: Extra files in GitHub repo will block iframe in your README Problems with Leaflet Maps with Google Sheets template My map does not appear Confirm that you have completed all of the key steps in the Leaflet Maps with Google Sheets tutorial in this book, especially these: Sign in to Google and File &gt; Make a Copy of the Google Sheet to your Google Drive. File &gt; Publish your Google Sheet (Jack often forgets this key step!) Copy your Google Sheet web address from top of your browser (usually ends with ...XYZ/edit#gid=0) and paste into your google-doc-url.js file in your GitHub repo. Do NOT copy the Published web address (which usually ends with ...XYZ/pubhtml) When you paste your Google Sheet web address into google-doc-url.js, be careful not to erase single-quote marks or semicolon Go to your live map link, which should follow this format: https://USERNAME.github.io/REPOSITORY, refresh the browser, and wait at least 30 seconds. Check your Google Sheet for errors: Do NOT rename column headers (in row 1) of any sheet, because the Leaflet Map code looks for these exact words. Screenshot: User accidentally renamed column headers in the Points tab Do NOT rename row labels (in column A) of any sheet, due to the same reason above. Screenshot: Do not rename or delete In your Points tab, DO NOT leave any blank rows Confirm on GitHub Status (https://status.github.com/) that all systems are operational. If you cannot find the problem, go to the top of this page to Safely Delete Your GitHub Repo and Start Over. Also, make a new copy of the Google Sheet template, give it a new name, and copy data from your old sheet using File &gt; Paste Special &gt; Values Only. Problems with Chart.js code templates Chart displays old data If you upload new data to your Chart.js code template on GitHub Pages, and it does not appear in your browser after refreshing and waiting up to one minute, then GitHub Pages is probably not the cause of the problem. Instead, some browsers continue to show “old” Chart.js in the web cache. The simplest solution is to File &gt; Quit your browser and re-open the link to your Chart.js TODO: Our Chart.js templates appear blank (just text, no chart) when viewed in the local browser. But Leaflet maps appear mostly or partially complete. Why is this, and how should we inform readers about this? Discuss with Ilya Solve Problems with Browser Developer Tools Peek inside any website and view the web code under the hood with the browser developer tools. In Chrome for Mac, go to View &gt; Developer &gt; Developer Tools In Firefox for Mac, go to Tools &gt; Web Developer &gt; Inspector "],
["ct.html", "B Find Connecticut Data", " B Find Connecticut Data TODO: Rewrite and update this appendix Since this book was created in Hartford, Connecticut, we include state and municipal open data repositories and boundary files. Connecticut Open Data (http://data.ct.gov), the official portal for state government agencies, is hosted on the Socrata platform, which offers built-in data visualization tools and APIs. See also how to create a filtered point map with Socrata in this book. See also separate repositories for individual state agencies: Office of the State Comptroller (http://www.osc.ct.gov/openCT.html) CT State Department of Education (http://www.sde.ct.gov/sde/cwp/view.asp?a=2758&amp;q=334520) Office of Policy and Management (http://ct.gov/opm/cwp/view.asp?a=3006&amp;Q=383258&amp;opmNav_GID=1386) link to all CT state government agencies (http://portal.ct.gov/Department-and-Agencies/) Connecticut State Data Center (http://ctsdc.uconn.edu/), part of the U.S. Census Data Center Network, is the lead agency for US Census data and other socioeconomic data for Connecticut, and is based at the University of Connecticut Libraries. The site also features data visualizations created on the Tableau platform and provides population projections for the state of Connecticut. MAGIC: The Map and Geographic Information Center (http://magic.lib.uconn.edu), based at the University of Connecticut Libraries, specializes in providing geographic, aerial photography, and map images for the state, past and present. The site also features interactive maps. DataHaven (http://ctdatahaven.org/), a non-profit organization, collects and interprets information about Connecticut neighborhoods, such as its Community Wellbeing Survey. Data resources feature neighborhood profiles for densely-populated areas (New Haven and Hartford-West Hartford), and town profiles for other areas across the state. Connecticut Data Collaborative (http://ctdata.org) is a public-private partnership that advocates for open data access to drive planning, policy, budgeting and decision making in Connecticut at the state, regional and local levels. We democratize public data through custom data exploration tools and a dynamic town profile tool, hosted on the open-source CKAN platform. Users can find state and federal data on topics such as public health, education, crime, municipal data, and racial profiling data. Hartford Data (http://data.hartford.gov), the official portal of the City of Hartford municipal government, is hosted on the Socrata platform, which features built-in visualizations and APIs. See also how to create a filtered point map with Socrata in this book. Also, the Hartford Data site links to the City’s ArcGIS Online geographic data (http://gisdata.hartford.gov/) and the City’s financial data (http://checkbook.hartford.gov/) and budget (http://budget.hartford.gov/). In addition to the official repositories above, Connecticut news organizations that create data visualizations often include links to download data files. Connecticut Mirror / Trend CT (http://ctmirror.org/) and (http://trendct.org/) are publications of the Connecticut News Project, an independent, nonpartisan, nonprofit organization that focuses on state policy issues. Most of their data visualizations are built with open-source code, with publicly accessible data files. See also their GitHub repository (https://github.com/trendct). Hartford Courant Data Desk (http://www.courant.com/data-desk) produces digital visualizations for the Hartford Courant, the largest daily newspaper in Connecticut, owned by Tribune Publishing. Many of these data visualizations are published on the Tableau platform, which allows readers to download the underlying data. Census areas in the Hartford region The U.S. Census Bureau collects and shares population, housing, and economic data on its open repositories. The Decennial Census is a full count of the population every ten years, most recently in 2010 and the upcoming one in 2020. Because decennial data are counts and not estimates, they represent “true” values and hence come without margins of errors. The American Community Survey (ACS) (https://www.census.gov/programs-surveys/acs/) is annual sample count, which produces: 1-year estimates for areas with populations of 65,000+ 5-year estimates for all census areas ACS used to release 3-year estimates for geographies with population of 20,000+, but discontinued after the 2011-2013 release. Because ACS produces estimates and not “true” counts, data comes with margins of errors. Generally, margins of errors are higher for smaller geographies (eg census blocks) and smaller values (eg the number of Asian females aged 60+ who live in Union, CT). Hence, one needs to be critical when using ACS or other survey data. Data.census.gov Data.census.gov (https://data.census.gov) is the main platform to access US Census data. It provides an easy search across census and survey tables. There is an interface to view tables for various years and geographies, and a download button to save data as CSV or PDF. It replaced American FactFinder (https://factfinder.census.gov) in July 2019. Social Explorer Social Explorer (https://www.socialexplorer.com/) is a popular tool to view and download census and related demographic data, past and present. The platform allows users to create data maps that may be exported as static images or presentation slides. Social Explorer requires subscription, but many academic institutions provide access. TODO: create tutorial on how to cleanly download census data from Social Explorer and Census.gov to join with geography, especially census tract numbers Census areas are geographic divisions in this general format: State County County subdivisions (equivalent to Connecticut towns and cities) Census tracts (designated areas, roughly 2,500 to 8,000 people) Block groups (sub-unit of tract, roughly 600 to 3,000 people) Census blocks (sub-unit of block group, but not always a city block) ADD individual data from Census Manuscript available 70+ years later – link to national archives The interactive map below illustrates hierarchical relations among geographical census entities for the Hartford region, from state to census block level. TODO: convert all to code-chunk iframes Learn more: Explore the standard hierarchy of US Census geographic entities and definitions (https://www2.census.gov/geo/pdfs/reference/geodiagram.pdf) See also Bulk Geocode with the US Census Geocoder and find GeoIDs (such as the census tract) for each address. National Center for Education Statistics National Center for Education Statistics (NCES) (https://nces.ed.gov/) is the primary federal agency for collecting and reporting education data. Elementary/Secondary Information System (ELSi) (https://nces.ed.gov/ccd/elsi) - create custom tables and charts from the Common Core of Data (CCD) and Private School Survey. Boundaries Converted from shapefile WGS84 to GeoJSON format To download a GeoJSON file, right-click the link and Save to your computer If you accidentally open the GeoJSON code in your browser, select File &gt; Save Web Page to download it To view or edit, drag files into http://geojson.io or http://mapshaper.org Learn more in the Transform Your Map Data chapter of this book Geography Year-Source-Size Right-click + Save to download GeoJSON CT outline 2010 Census UConn MAGIC WGS84 1:100,000 ct-outline.geojson CT counties 2010 Census UConn MAGIC WGS84 1:100,000 ct-counties.geojson CT towns 2010 Census UConn MAGIC WGS84 simplified to 224k ct-towns.geojson CT census tracts 2010 Census UConn MAGIC WGS84 1:100,000 ct-tracts-2010.geojson Hartford County outline 2010 Census UConn MAGIC WGS84 1:100,000 hartfordcounty-outline.geojson Hartford County towns 2010 Census UConn MAGIC WGS84 1:100,000 hartfordcounty-towns.geojson Hartford County tracts 2010 Census UConn MAGIC WGS84 1:100,000 hartfordcounty-tracts-2010.geojson Hartford outline 2010 Census UConn MAGIC WGS84 1:100,000 hartford-outline.geojson Hartford census tracts 2010 Census UConn MAGIC WGS84 1:100,000 hartford-tracts-2010.geojson Hartford neighborhoods 2015 Hartford Open Data 1:50,000 hartford-neighborhoods.geojson TODO: - add Capitol Region Council of Governments (CRCOG) http://www.crcog.org/ - add school districts (and clarify elementary-secondary) - add Capitol Region Education Council (CREC) http://www.crec.org/ - add school attendance areas from federal site - describe Freedom of Information Act (FOIA) data requests in Connecticut "],
["peer.html", "C Peer Review Samples", " C Peer Review Samples ONLY FOR WEB EDITION: The next pages include partial-credit and full-credit samples for peer review in the Data Visualization for All edX course. "],
["peer-2-chart-1.html", "Section 2 Chart 1 Peer Review Sample", " Section 2 Chart 1 Peer Review Sample Students in the Data Visualization for All course come from several different countries, including Australia, Bangladesh, and Belgium. Evaluate Story: Did the author clearly tell a meaningful story about the data, with text and visuals? Chart Type: Did the author choose a chart type that best matches their data story? Embed: Did the author embed an interactive chart into the web page? Good Design: Did the author follow principles of good chart design? "],
["peer-2-chart-1-notes.html", "Section 2 Chart 1 Peer Review Sample with Notes", " Section 2 Chart 1 Peer Review Sample with Notes Students in the Data Visualization for All course come from several different countries, including Australia, Bangladesh, and Belgium. Evaluate Story: Did the author clearly tell a meaningful story about the data, with text and visuals? No, this simple statement that students come from “several different countries” is not a very meaningful story. Chart Type: Did the author choose a chart type that best matches their data story? No. Although a vertical column chart is a good start, a horizontal bar chart would be a better match for these long labels. Embed: Did the author embed an interactive chart into the web page? No, when you try to float your cursor over the chart, it is a static image, not an interactive visualization. Good Design: Did the author follow principles of good chart design? No, the chart ignores several design principles, such as: - Failure to sort data into a meaningful order - Failure to declutter the chart by removing the unnecessary legend "],
["peer-2-chart-2.html", "Section 2 Chart 2 Peer Review Sample", " Section 2 Chart 2 Peer Review Sample Nations with the highest percentage of female students enrolled in Data Visualization for All are the Ukraine (51 percent) and Turkey (47 percent), based on preliminary data for those with high enrollment levels (25 or more students). TODO: convert all to code-chunk iframes View the preliminary data for 21 Feb 2017 from http://handsondataviz.org Evaluate Story: Did the author clearly tell a meaningful story about the data, with text and visuals? Chart Type: Did the author choose a chart type that best matches their data story? Embed: Did the author embed an interactive chart into the web page? Good Design: Did the author follow principles of good chart design? "],
["peer-2-chart-2-notes.html", "Section 2 Chart 2 Peer Review Sample with Notes", " Section 2 Chart 2 Peer Review Sample with Notes Nations with the highest percentage of female students enrolled in Data Visualization for All are the Ukraine (51 percent) and Turkey (47 percent), based on preliminary data for those with high enrollment levels (25 or more students). View the preliminary data for 21 Feb 2017 from http://handsondataviz.org Evaluate Story: Did the author clearly tell a meaningful story about the data, with text and visuals? Yes, this insight on gender differences in student enrollments across nations is a meaningful story. Chart Type: Did the author choose a chart type that best matches their data story? Yes, this stacked horizontal bar chart is a good match for showing part-to-whole relationships (gender by percentage) between different nations. Embed: Did the author embed an interactive chart into the web page? Yes, when you float your cursor over it, the interactive chart tooltip shows data labels and values. Good Design: Did the author follow principles of good chart design? Yes, the chart demonstrates good design principles, such as: Sorting data into a meaningful order Using color contrast (blue vs grays) to highlight percentages of female students "],
["peer-3-sample-1.html", "Section 3 Peer Review Sample 1", " Section 3 Peer Review Sample 1 My Leaflet map My Highcharts scatter chart Evaluate Leaflet map and title: Did the author embed an interactive Leaflet map with a new title? Leaflet map layers: Did the author add controls that toggle on/off different map layers? Leaflet point markers: Did the author upload a new set of markers, with pop-ups that show titles for each point? Highcharts scatter chart: Did the author embed an interactive Highcharts scatter chart with a new title and axis labels? Highcharts data tooltips: Did the author upload a new set of data, with tooltips that show labels and details for each point? Additional comments for the author. What works well? What could be improved? "],
["peer-3-sample-1-notes.html", "Section 3 Peer Review Sample 1 with Notes", " Section 3 Peer Review Sample 1 with Notes My Leaflet map My Highcharts scatter chart Evaluate Leaflet map and title: Did the author embed an interactive Leaflet map with a new title? No, the map title is the same as the original template, and is not new. Leaflet map layers: Did the author add controls that toggle on/off different map layers? No, the map does not contain layer controls. Leaflet point markers: Did the author upload a new set of markers, with pop-ups that show titles for each point? No, the map only contains one point, and the author did not upload a new set of points. Highcharts scatter chart: Did the author embed an interactive Highcharts scatter chart with a new title and axis labels? No, the chart title and axis labels are the same as the original template, and are not new. Highcharts data tooltips: Did the author upload a new set of data, with tooltips that show labels and details for each point? No, the author did not upload a new set of data points. Additional comments for the author. What works well? What could be improved? "],
["peer-3-sample-2.html", "Section 3 Peer Review Sample 2", " Section 3 Peer Review Sample 2 My Leaflet map My Highcharts scatter chart Evaluate Leaflet map and title: Did the author embed an interactive Leaflet map with a new title? Leaflet map layers: Did the author add controls that toggle on/off different map layers? Leaflet point markers: Did the author upload a new set of markers, with pop-ups that show titles for each point? Highcharts scatter chart: Did the author embed an interactive Highcharts scatter chart with a new title and axis labels? Highcharts data tooltips: Did the author upload a new set of data, with tooltips that show labels and details for each point? Additional comments for the author. What works well? What could be improved? "],
["peer-3-sample-2-notes.html", "Section 3 Peer Review Sample 2 with Notes", " Section 3 Peer Review Sample 2 with Notes My Leaflet map My Highcharts scatter chart Evaluate Leaflet map and title: Did the author embed an interactive Leaflet map with a new title? Yes, the title in this map has changed from the original template Leaflet map layers: Did the author add controls that toggle on/off different map layers? Yes, this map contains map layer controls. Leaflet point markers: Did the author upload a new set of markers, with pop-ups that show titles for each point? Yes, this map contains new points that were added to the original template. Highcharts scatter chart: Did the author embed an interactive Highcharts scatter chart with a new title and axis labels? Yes, this chart contains a new title and axis labels. Highcharts data tooltips: Did the author upload a new set of data, with tooltips that show labels and details for each point? Yes, this chart contains a new set of data points that were uploaded to the original. Additional comments for the author. What works well? What could be improved? "],
["bookdown.html", "D Publishing with Bookdown", " D Publishing with Bookdown This open-access book is built with free-to-use, open-source tools—primarily Bookdown, GitHub, and Zotero—and this chapter explains how, so that readers may do it themselves and share their knowledge to improve the process. In addition to our notes below, see also Yihui Xie’s more comprehensive Bookdown guide.8 Our broad goal is an efficient workflow to compose one document in the easy-to-write Markdown format that Bookdown generates into multiple book products: an HTML web edition to read online, a PDF print edition for traditional book publishing, a Microsoft Word edition for editors who request it for copyediting, and option for other formats as desired. Since Bookdown is an R code package, we composed the book manuscript in R-flavored Markdown, with one file (.Rmd) for each chapter. We use Bookdown to build these files in its GitBook style as a set of static HTML pages, which we upload to our GitHub repository. Readers can view the open-access web edition of the book at our custom domain: https://HandsOnDataViz. Also, we use Bookdown to build additional book outputs (PDF, MS Word, Markdown) and upload these to the docs folder of our GitHub repository, so that our O’Reilly Media editor may download and comment on the manuscript as we revise. Finally, we have arranged with the O’Reilly production team to convert our modified version of the full-book Markdown file into their O’Reilly Atlas platform. See some caveats and workarounds below. File Organization and Headers We organized the GitHub repository for this book as a set of .Rmd files, one for each chapter. As co-authors, we are careful to work on different chapters of the book, and to regularly push our commits to the repo. Only one of us regularly builds the book with Bookdown to avoid code merge conflicts. Bookdown assigns a default ID to each header, which can be used for cross-references. The default ID for # Topic is {#topic}, and the default ID for ## Section Name is {#section-name}, where spaces are replaced by dashes. But we do not rely on default IDs because they might change due to editing or contain duplicates across the book. Instead, we manually assign a unique ID to each first- and second-level header in the following way. Note that the {-} symbol, used alone or in combination with a space and a unique ID, prevents auto-numbering in the second- thru fourth-level headers: # Top-level chapter title {#unique-name} ## Second-level section title {- #unique-name} ### Third-level subhead {-} #### Fourth-level subhead {-} Also, we match the unique ID keyword to the file name for top-level chapters this way: 01-keyword.Rmd to keep our work organized. Unique names should contain only alphanumeric characters (a-z, A-Z, 0-9) or dashes (-). Subheaders must have unique names or IDs to avoid Bookdown errors about duplicated references. To avoid this issue for repeated subheaders (such as “Summary”), at the end of each chapter insert a third-level summary subhead, but insert a unique ID that matches each chapter number, like this: ### Summary {- #summary17} A special header in this book is the unnumbered header beginning with (APPENDIX), which indicates that all chapters appearing afterwards are appendices. According to Bookdown, the numbering style will appear correctly in HTML and LaTeX/PDF output, but not in Word or ebooks. # Chapter One # Chapter Two # (APPENDIX) Appendix {-} # Appendix A # Appendix B In the Bookdown index.Rmd for the HTML book output and the PDF output, the toc_depth: 2 setting displays chapter and section headers down to the second level in the Table of Contents. The split_by: section setting divides the HTML pages at the second-level header, which creates shorter web pages with reduced scrolling for readers. For each web page, the unique ID becomes the file name, and is stored in the docs subfolder. The number_sections setting is true for the HTML and PDF editions, and given the toc_depth: 2, this means that they will display two-level chapter-section numbering (1.1, 1.2, etc.) in the Table of Contents. Note that number_sections must be true to display Figure and Table numbers in x.x format, which is desired for this book. See relevant settings in this excerpt from index.Rmd: output: bookdown::gitbook: ... toc_depth: 2 split_by: section number_sections: true split_bib: true ... bookdown::pdf_book: toc_depth: 2 number_sections: true Note that chapter and section numbering do not appear automatically in the MS Word output unless you supply a reference.docx file, as described below: https://bookdown.org/yihui/rmarkdown/word-document.html https://stackoverflow.com/questions/52924766/numbering-and-referring-sections-in-bookdown https://stackoverflow.com/questions/50609212/caption-styles-for-word-document2-in-bookdown In the _bookdown.yml settings, all book outputs are built into the docs subfolder of our GitHub repo, as shown in this excerpt: output_dir: &quot;docs&quot; book_filename: &quot;HandsOnDataViz&quot; language: label: fig: &quot;Figure &quot; chapter_name: &quot;Chapter &quot; In our GitHub repo, we set GitHub Pages to publish to the web using master/docs, which means that visitors can browse the source files at the root level, and view the HTML web pages hosted in the docs subfolder. We use the GitHub Pages custom domain setting so that the HTML edition is available at https://HandsOnDataViz.org. The docs subfolder also may contain the following items, which are not generated by Bookdown and need to be manually created: CNAME file for the custom domain, generated by GitHub Pages. .nojekyll invisible empty file to ensure speedy processing of HTML files by GitHub Pages. 404.html custom file to redirects any mistaken web addresses under the domain back to the index.html page. One more option is to copy the Google Analytics code for the web book, paste it into an HTML file in the book repo, and include this reference in the index.Rmd code: output: bookdown::gitbook: ... includes: in_header: google-analytics.html Yihui Xie, Bookdown: Authoring Books and Technical Documents with R Markdown, 2018, https://bookdown.org/yihui/bookdown/↩︎ "],
["style-guide.html", "Style Guide for Hands-On Data Visualization", " Style Guide for Hands-On Data Visualization View the underlying source code to understand how this page was composed at: https://github.com/HandsOnDataViz/book/blob/master/18-bookdown.Rmd This book is composed in R-flavored Markdown (.Rmd), and each paragraph begins on a separate line. O’Reilly style guide prefers italics rather than bold. Use single back tics to display a monospaced code word. O’Reilly guidelines recommend making your writing as conversational as possible. Imagine you’re speaking to someone one on one, not giving a formal lecture to a large group. Refer to the reader as “you” and to yourself as “I” for a single-author book, and refer to yourselves as “we” for a co-authored book. Use active voice, not passive voice. More from O’Reilly about chapter structure: Each chapter should begin with a paragraph or two that summarizes what the chapter is about and why that information is important to the overall topic of your book. Subsequent sections should walk readers through the information you’re presenting. Keep readers oriented by including signposts like “As you learned in Chapter 3” and “I’ll discuss this topic in more detail later in this chapter.” More from O’Reilly about transitions: End section X by saying something like, “Now that you understand X, you’re ready to dig into topic Y,” and start section Y by explaining how it relates to topic X. Daisy-chaining helps readers understand how concepts are connected and why you’re covering them in this order. Finally, at the end of each chapter, summarize what you discussed in that chapter, and mention what the following chapter is going to cover. O’Reilly encourages the use of tips, notes, and warnings, and assigns each of them an animal icon in their books (lemur, crow, and scorpion, respectively). In this book manuscript, simply start each with a paragraph beginning with the keyword, followed by a colon, to simplify find-and-replace at a later date: Tip: A couple of sentences that convey a helpful bit of information, a quick way to do things better. Note: A couple of sentences of supplemental information. It describes something you want readers to keep in mind as they work, so you use a note to set it apart and make sure they see it. Warning: Similar to a note or tip, but specifically focused on a way to help readers avoid making a mistake or getting into trouble. Also: Sidebar: Use this to note where the editor has requested a boxed sidebar. If longer than one paragraph, add “End Sidebar” to close it. Insert an embedded external link to O’Reilly. This appears as a colored clickable link in HTML and Word editions, and a non-colored but clickable link in the PDF edition. According to O’Reilly Atlas documentation, the AsciiDoc version should automatically unfurl for the printed edition. Insert an embedded internal link to the book, using the short pathname, such as download this sample CSV file, to ensure that Bookdown copies the file from the data subfolder over to the docs subfolder. Embed links directly in the sentence, such as download this sample PDF. Avoid linking words such as “here” or “this web page.” Also, avoid writing “Click on this…” in the main text, such as when downloading a sample file, since readers cannot click on the print edition. However, it is acceptable to write “click on” or “right-click on” in a tutorial on interacting with software. When instructions refer to software menu items, use italics. Example: Select File &gt; Make a Copy to save your own version to your Google Drive. For lists, always insert a blank line before the items, unless they appear directly after hashtag header. unordered list ordered list Dashes: Use a hyphen (1 dash) for hyphenated words, such as two-thirds or dog-friendly hotel. Use an en-dash (2 dashes) for ranges, such as the May–September magazine issue. Use an em-dash (3 dashes) to insert an additional thought—like this—in a sentence. Insert TODO to note items to finish or review with co-author or editor. Use single back tics to designate code. Insert three back tics to insert a code block, limited to 81 character line length for Animal style book body in O’Reilly style guide. TODO: Check to see if triple back tics render correctly in the Markdown full-book output. &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/leaflet@1.6.0/dist/leaflet.css&quot; /&gt; &lt;script src=&quot;https://unpkg.com/leaflet@1.6.0/dist/leaflet.js&quot;&gt;&lt;/script&gt; Conditional Formatting Conditional formatting offers the option to display text or images in some editions, but not other editions. Options: Insert a HTML code comment &lt;!-- Comment --&gt; in the .Rmd file to hide a few lines of text. This appears as commented-out text in the HTML and .md formats, is not displayed in the HTML browser, and does not appear in any way in the PDF or MS Word formats. Demo: R package function is_[html/latex]_output allows conditional output for different book products, such as text that should appear in the HTML edition but not the PDF edition, or vice versa. Demos: This line appears in the HTML, Word, Markdown versions, and is commented-out in the PDF version. TODO: Create conditional formatting that displays only in the HTML edition, and allows the inclusion of R code-chunks to conditionally display images. See links for more complex conditional formatting: https://stackoverflow.com/questions/56808355/how-to-conditionally-process-sections-in-rmarkdown https://bookdown.org/yihui/rmarkdown-cookbook/latex-html.html https://blog.earo.me/2019/10/26/reduce-frictions-rmd/ https://stackoverflow.com/questions/53861244/html-specific-section-in-bookdown https://stackoverflow.com/questions/41084020/add-a-html-block-above-each-chapter-header https://stackoverflow.com/questions/45360998/code-folding-in-bookdown Option to customize the style.css code for the HTML book. Option to add headers, footers, preambles to the HTML or LaTeX versions. Build different versions of the HTML and LaTeX (PDF) books using different chapters by listing them in order in the _bookdown.yml file: rmd_files: html: [&quot;index.Rmd&quot;, &quot;abstract.Rmd&quot;, &quot;intro.Rmd&quot;] latex: [&quot;abstract.Rmd&quot;, &quot;intro.Rmd&quot;] Cross-references In order to cross-reference in Bookdown, assign a unique name or R code-chunk label to each chapter, section, figure, and table. Unique names and labels should contain only alphanumeric characters (a-z, A-Z, 0-9) or dashes (-). To cross-reference any chapter or section, and allow readers to jump there, use a HTML link with the unique name, such as index.html or style-guide.html. Demos: See Introduction See “Style Guide” in Chapter x. Contrary to the Bookdown manual, avoid using Bookdown unique ID links to cross-reference chapters or sections, because these create extraneous and imprecise URLs, such as this bad example. To cross-reference figures and tables, and display their auto-number and allow readers to jump there, write a call-out with a Bookdown reference to a code-chunk label, such as See Figure \\@ref(fig:sample-map) or See Table \\@ref(tab:left-table). Demos: See Figure D.1. See Table D.1. Cross-reference interactivity varies by output: In HTML, all cross-refs are clickable. In PDF, all cross-refs are clickable (except chapter-level HTML links). In Word, no cross-refs are clickable (unless this varies with reference.docx). When writing cross-references in the text, the O’Reilly Style Guide prefers live cross references (e.g., “see Figure 2-1”), but if not feasible, use “preceding” or “following” because physical placement of elements may vary across print and digital formats. Avoid using “above” or “below.” "],
["images.html", "Images", " Images View the underlying source code to understand how this page was composed at: https://github.com/HandsOnDataViz/book/blob/master/18-bookdown.Rmd Create high-resolution color screenshots and other static images in .png or .jpg format, with tight cropping on a high-resolution Retina monitor, typically at 144 ppi. Save items into the images subfolder by chapter. Make sure that color images include high contrast and/or shading, because they will be converted to grayscale by the publisher for the print book. Write file names in lowercase with dashes (not spaces) and begin with keyword of relevant section to keep related images grouped together. Despite being in separate folders, avoid duplicate image file names across the book. Avoid numbering images since they may not match the final sequence. If a screenshot requires additional artwork or text for the HTML edition, make a copy of the original and add -ann to note that this version is annotated, save into the same folder with the same root file name, and use in the code-chunk image pathnames. The publisher will use the original image and add their own artwork for their editions. If an image is larger than approximately 300px on either side, one more option is to reduce the image size in the PDF version. Use Photoshop (not Preview) to reduce the image size, and save a copy with the same file name with the .pdf extension into the folder. In some cases (such as images inside Markdown tables, or static screenshots to accompany iframes), it may make sense to save a full-size version, with -original in the file name, for the publisher to use when creating the print book. Overall, sometimes the folder will contain only one version of a simple image, but in other cases it may contain up to 3-4 versions of an image: images/05-chart/design-setup.png images/05-chart/design-setup-ann.png images/05-chart/design-setup-ann.pdf images/05-chart/design-setup-original.png If creating images to appear as the same size in sequence, add a code-comment with the image width, height, and resolution as a reminder to make others match up, like this: &lt;!-- Images below are 200x200 at 300 resolution --&gt; In this book, use Markdown formatting only for images that appear inside tables or do not require captions or figure numbering, and leave the caption field blank, like this example: Co-Authors About Us About Jack Dougherty About Ilya Ilyankou Although Markdown formatting offers a simple syntax that easily converts into other formats with Bookdown/Pandoc, there is no auto-numbering in the HTML edition, while auto-numbering appears in the PDF edition, and numbered figures are required by the publisher. Furthermore, Markdown formatting does not allow conditional output. Images using R code-chunks For these reasons, this book primarily uses R code-chunk formatting for images. The syntax is more complex but supports auto-numbering in HTML and PDF, and conditional output for interactive and static images. Note that static R code-chunk images convert to Markdown, but interactive images do NOT convert and need to be manually edited in the modified file, described further below. Auto-numbering appears in Figure x.x format in HTML and PDF, but Figure x format in MS Word and Markdown. Note that Word formatting can be changed with reference.docx. Note that images in PDF output will “float” by design and may appear before or after the desired page, so always add a cross-reference call-out. Write R code-chunk labels that follow the image file name, and avoid duplicate labels across the book: ref:design-setup images/05-chart/design-setup.png Do not insert spaces inside the ref:chunk-label for the caption, but add a blank line to separate it from the code-chunk. After the code-chunk, add another blank line to avoid “undefined reference” Bookdown errors. Inside the R code-chunk ref caption, do NOT use mischievous characters (such as &lt; or &gt; or \") that will throw HTML errors into the Markdown output images. Instead, use safe characters such as (* and -) to designate computer instructions, such as File - Make a Copy. For each figure, manually add a cross-reference call-out and insert fig.pos='h' to place the image “here” on the page in the PDF output, to attempt to avoid PDF floating. Ignore the Bookdown LaTeX warning message “h float specifier changed to ht.” See more at https://bookdown.org/yihui/bookdown/figures.html and https://bookdown.org/yihui/rmarkdown-cookbook/figure-placement.html This Bookdown index.Rmd file includes two global R code-chunk settings immediately after the first header. One setting displays each code-chunk image without a code echo. The other setting automatically inserts the PDF version of an PNG/JPG image, whenever it exists, in the PDF output, which allows us to manually reduce the image sizes for the PDF book. Read more about these options in this Bookdown chapter: https://bookdown.org/yihui/bookdown/figures.html. {r setup, include=FALSE} knitr::opts_chunk$set(echo = FALSE) options(knitr.graphics.auto_pdf = TRUE) Demo: R code-chunk for small static image for HTML and PDF editions Small is defined as each side less than 300px, as shown in Figure D.1. Figure D.1: Caption here. Markdown embedded links are acceptable. R code-chunk for larger static image using out.width and PDF img For larger images, where one side is greater than 300px, set the out.width to a pixel number for ideal display in the HTML edition. Also optional to reduce float in PDF: fig.pos='h',. If necessary, copy the image, use Photoshop to create a smaller image size, and save with same file name and a .pdf extension for auto-substitution in the PDF output …as shown in Figure D.2. Figure D.2: Using out.width=200 and smaller PDF image size. R code-chunks allow more complex conditional formatting, where an interactive map or animated GIF or YouTube video clip appears in the web version, and a static image with an embedded link appears in the PDF and MS Word outputs. To change the height of the default 400px iframe, add the new height to include_url as shown in the examples. However, to change the width of the default 675px iframe to less than 100 percent, add a line in a custom-scripts.html file. Demo: R code-chunk for iframe in HTML and static image in PDF …as shown in Figure D.3. Figure D.3: Caption here, and add embedded link to explore the full-screen interactive map. Demo: R code-chunk for animated GIF in HTML and static image in PDF When appropriate, create animated GIF files using Camtasia, and add fade-to-black to mark the end-point in the looped version. Add …as shown in Figure D.4. Figure D.4: Caption here, with embedded link to the animated GIF. Demo: R code-chunk for Youtube video in HTML and static image in PDF Be sure to use the embed link from the YouTube share button. …as shown in the video D.5. Figure D.5: Caption here, with embedded link to the YouTube video. Demo: R code-chunk for YouTube video in HTML, with NO static image in PDF This option may be relevant when you wish to display a video only in the html edition, with no screenshot of it in the PDF edition. Note that this will alter figure-numbering between the HTML and PDF editions. Figure D.6: Caption only for HTML version, with embedded link to the YouTube video. "],
["tables.html", "Tables", " Tables View the underlying source code to understand how this page was composed at: https://github.com/HandsOnDataViz/book/blob/master/18-bookdown.Rmd Create tables in Markdown format, since it produces good output for HTML, PDF, Word, and Markdown. Use a tool such as Tables Generator to import significant table data in CSV format, format the column alignment as desired, and press Generate button to create table in Markdown format. For significant table data, save the CSV version in a GitHub repo for potential later use. TODO: Check if any un-numbered Markdown tables in the chapter affect table auto-numbering. Add the Markdown table code shown below to auto-number (Table x) in HTML, PDF, Word. …as shown in Table D.1. Table D.1: Left-justify content, remember blank Line Much Much Longer Header Short Header Short Header Left-justify text content with left-colons Less Here Use more hyphens to grant more space to some columns Less Here Table D.2: Right-justify content, remember blank line Header1 Header2 Header3 123 456 789 Right-justify numerical content with right-colons Use equal hyphens to make equal space for all columns Currently, Bookdown creates the Markdown file with tables in HTML format, not Markdown format. Our workaround is to paste the individual Markdown-formatted tables directly from the .Rmd into the modified full-book .md file. "],
["notes.html", "Notes and Bibliography", " Notes and Bibliography This book displays endnotes for each chapter in the HTML book, and footnotes at the bottom of pages for the PDF and MS Word books, followed by an alphabetized bibliography of all references cited on the last page. The notes and bibliography also appear in the full-book Markdown file. To create notes, insert citation keys in the text, such as @huffHowLieStatistics1954, which are generated by Zotero bibliographic database with the Better BibTex extension, and export these in the Better BibLaTeX format into the dataviz.bib in the book repo. The repo also contains .csl file to generate the notes and bibliography in a specific Chicago-style format, downloaded from the Zotero Styles Repository. These instructions are referenced in the index.Rmd file for both the HTML and PDF formats, as shown in these excerpts: bibliography: dataviz.bib citation-style: chicago-fullnote-bibliography.csl ... output: bookdown::gitbook: ... pandoc_args: [ &quot;--csl&quot;, &quot;chicago-fullnote-bibliography.csl&quot; ] bookdown::pdf_book: ... citation_package: none pandoc_args: [ &quot;--csl&quot;, &quot;chicago-fullnote-bibliography.csl&quot; ] Here’s a text-only note, with no Zotero citation.9 To create a note with citations only, separate Zotero/BibTeX citation keys with semi-colons:10 Since notes also may include text and punctuation in Markdown syntax, always insert a caret symbol prior to the brackets to demarcate a note:11 Note that the chicago-fullnote-bibliography.csl format automatically shortens the note after it its first reference. This is a note, with no bibliographic reference.↩︎ Darrell Huff, How to Lie with Statistics (W. W. Norton &amp; Company, 1954), http://books.google.com/books?isbn=0393070875; Mark S. Monmonier, How to Lie with Maps, 2nd ed. (University of Chicago Press, 1996), http://books.google.com/books?isbn=0226534219↩︎ Compare how “lying” is justified by Huff, How to Lie with Statistics, pp. 10-11 and Monmonier, How to Lie with Maps, pp. 11-12.↩︎ "],
["modify-markdown.html", "Manually Modify Markdown Output", " Manually Modify Markdown Output The O’Reilly production team has agreed to accept our full-book Markdown file into their workflow, which is easier for them to work with than the full-book MSWord file. Note that our Bookdown index.Rmd file includes code to generate a full-book Markdown: bookdown::markdown_document2: default See this not-fully-documented Bookdown solution about generating Markdown output: https://stackoverflow.com/questions/58164239/compile-bookdown-to-markdown. We experimented to see if “strict” Markdown would produce cleaner output, following this RMarkdown guide https://bookdown.org/yihui/rmarkdown/markdown-document.html, but saw no difference when compared to the default settings. We need to do a bit of manual cleanup before ORM production team can convert the full-book Markdown file into AsciiDoc format for their Atlas platform, unless we find a way to automate these steps. See workaround notes in the Images and Tables sections above. Remember to avoid mischievous characters in R code-chunk image captions (such as &lt; or &gt; or \") that will throw HTML errors into the Markdown output images. Build the book with Bookdown, including one large Markdown file (docs folder, suffix .md) Manually rename it as HandsOnDataViz-modified.md Manually paste in these Markdown tables to replace HTML tables (unless ORM can handle this part) from index.Rmd, table of authors from 05-chart.Rmd, Table 1: Chart types covered in this book Manually replace any &lt;iframe... HTML or GIF elements with their PNG substitutes, and new ALT text (unless authors come up with a better way to automate this) Manually delete any remaining &lt;iframe... elements (unless they are non-executable code snippets) Save and push the modified Markdown file up to GitHub repo TODO: Check to see if triple back tics render correctly in the Markdown full-book output. Note: Previously, we tried to use Pandoc to convert the modified.md file to asciidoc, but encountered many errors. OLD Pandoc conversion steps (for reference only): Use command line to navigate to subfolder with pwd and cd. Convert with: pandoc handsondataviz-modified.md --from markdown --to asciidoc --standalone --output handsondataviz-modified.asciidoc "],
["references.html", "References", " References D’Ignazio, Catherine, and Lauren F. Klein. Data Feminism. MIT Press, 2020. https://data-feminism.mitpress.mit.edu/. Dougherty, Jack, Jeffrey Harrelson, Laura Maloney, Drew Murphy, Russell Smith, Michael Snow, and Diane Zannoni. “School Choice in Suburbia: Test Scores, Race, and Housing Markets.” American Journal of Education 115, no. 4 (August 2009): 523–48. http://digitalrepository.trincoll.edu/cssp_papers/1. Huff, Darrell. How to Lie with Statistics. W. W. Norton &amp; Company, 1954. http://books.google.com/books?isbn=0393070875. Monmonier, Mark S. How to Lie with Maps. 2nd ed. University of Chicago Press, 1996. http://books.google.com/books?isbn=0226534219. Rost, Lisa Charlotte. “How to Prepare Your Data for Analysis and Charting in Excel &amp; Google Sheets.” Chartable: A Blog by Datawrapper. Accessed August 28, 2020. https://blog.datawrapper.de/prepare-and-clean-up-data-for-data-visualization/index.html. ———. “Your Friendly Guide to Colors in Data Visualisation.” Chartable: A Blog by Datawrapper, July 31, 2018. https://blog.datawrapper.de/colorguide/. Schwabish, Jon. “Thread Summarizing ’Ten Guidelines for Better Tables’.” Twitter, August 3, 2020. https://twitter.com/jschwabish/status/1290323581881266177. Schwabish, Jonathan. Better Data Visualizations: A Guide for Scholars, Researchers, and Wonks. Columbia University Press, 2021. https://cup.columbia.edu/book/better-data-visualizations/9780231193115. Schwabish, Jonathan A. “Ten Guidelines for Better Tables.” Journal of Benefit-Cost Analysis 11, no. 2: 151–78. Accessed August 25, 2020. https://doi.org/10.1017/bca.2020.11. Xie, Yihui. Bookdown: Authoring Books and Technical Documents with R Markdown, 2018. https://bookdown.org/yihui/bookdown/. Zuboff, Shoshana. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. PublicAffairs, 2019. https://www.google.com/books/edition/The_Age_of_Surveillance_Capitalism/lRqrDQAAQBAJ. "]
]
