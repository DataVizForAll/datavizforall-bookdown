# Make Meaningful Comparisons {#comparisons}

Now that you've [reflected on your data story](choose.html), [found and questioned your data](find.html), and [cleaned up any messy parts](clean.html), this chapter focuses on the key question to ask while analyzing your evidence: "Compared to what?" That's how statistician Edward Tufte defined the "heart of quantitative reasoning."^[@tufteEnvisioningInformation1990, p. 67]. We search for insightful findings in our data by judging their significance against each other, to identify those that truly stand out. Sometimes we need to adjust our scales to ensure that we're weighing data fairly, or as the saying goes, comparing apples to apples, not apples to oranges. Before you communicate your findings in any format---text, tables, charts, or maps---be sure that you're making meaningful comparisons, because without this, your work may become meaningless.

This book does not intend to cover statistical data analysis, since many excellent resources already address this expansive field of study.[TODO: cite open-access resources]. Instead, this chapter offers several common-sense strategies to make meaningful comparisons while you analyze your data, in order to help you design true and insightful visualizations that tell your story. You will learn to [precisely use comparison words](comparison-words.html), why and how [to normalize your data](normalize.html), and watch out for [biased comparisons](biased-comparisons.html).

## Precisely Use Comparison Words {- #comparison-words}
TODO: Consider alternative section name: "Precisely Describe Comparisons" or "Describe Comparisons with Precision" or "Use Comparison Words Precisely"

Sometimes we make poor comparisons because we fail to clarify our meaning of commonly-used words that can have different definitions. Three troublesome words are *average*, *percent*, and *causes*. We use them loosely in everyday conversation, but they require more precision when working with data.

Imagine a series of numbers: 1, 2, 3, 4, 5. When calculating the *average*, by hand or [with a built-in spreadsheet formula as described in chapter 3](calculate.html), we add up the sum and divide by the count of numbers. A more precise term is the *mean*, which in this case equals 3. A different term is the *median*, which refers to the number in the middle of the ordered series, also known as the *50th percentile*, which in this case is also 3.

When working with data, the terms *median* and *percentile* are more useful terms when making comparisons because they resist the influence of *outliers* at the extreme ends of the series. For example, imagine the same umbers as above, but replace the 5 with 100 to serve as an outlier. Suddenly the mean jumps up to 22, but the median remains the same at 3, as shown in Figure \@ref(fig:mean-vs-median). There's an old joke that when a billionaire walks into a room, everyone becomes a millionaire---on average---but the median remains the same. Since we ordinary people don't actually become richer by the presence of the billionaire outlier among us, the median is a better term to make meaningful comparisons about the overall distribution of the data.

(ref:mean-vs-median) The *median* is a more useful comparative term than *average* or *mean* because it resists the influence of outliers.

```{r mean-vs-median, fig.cap="(ref:mean-vs-median)"}
knitr::include_graphics("images/06-comparisons/mean-vs-median.png")
```

*Percent* is another common term that becomes more useful for comparisons when we use it more precisely. Nearly everyone understands how *percentage* refers to a *ratio*, such as [the 1960s commercial](https://en.wikipedia.org/wiki/Trident_gum) that curiously claimed how 4 out of 5 dentists (or 80 percent) recommend sugarless gum for their patients who chew gum. Even if we never saw the survey data, nor understood how the fifth dentist resisted such intense peer pressure, we intuitively grasp the concept of percentage. [TODO: Discuss if anyone gets my gum reference here, or if it just shows my age!]

But troubles sometimes arise when using the word to compare numbers, and here's where more precision helps. One term is *percent change* (or percent increase or decrease), which works best when comparing *old versus new values*. For example, if 4 dentists recommended sugarless gum in 1960, but peer pressure finally prevailed and 5 dentists recommend it in 2020, we calculate the percent change as `(New value - Old value) / Old value`, or `(5-4)/4 = 1/4 = 0.25 = 25%`.

A different term is *percentage points*, which works best when comparing *old versus new percentages*. For example, if 80 percent of dentists recommended sugarless gum in 1960, but 100 percent recommended it in 2020, we can compare the two figures by calculating the difference as `New percentage - Old percentage = 100% - 80%  = a difference of 20 percentage points`.

When we use each term accurately, there are two correct ways to compare these figures. One way is to state that "The number of dentists who recommended sugarless gum increased 25 percent over time." Another way is to state that "The percentage of dentists who recommended sugarless gum increased 20 percentage points over time." Both statements are accurate.

Avoid loosely using the word "percent" without being precise about its meaning, since you're likely to confuse people, or worse, mislead them about the facts. Imagine a politician who proposes to raise the sales tax on products and services you purchase from 5 to 6 percent. If that politician says, "it's only a 1 percent increase," they're wrong. Instead, there are two truthful ways describe this change. One way is to state that tax "will increase 20 percent" because `(6-5)/5 = 0.20`. Another way is to state that the tax "will increase by 1 percentage point" because `6% - 5% = a difference of 1 percentage point`. See why the politician preferred to say it their way, rather than the correct way? Don't let anyone fool you with percentages, and make sure you use these terms precisely in your own work to avoid misleading others.

TODO above: Decide if the text and examples are clear. I like the sugarless gum example, but can replace it if it's too obscure, or if the change from 4 to 5 out of 5 isn't useful. Also, I simplified the politician's example from reading this real-life example, but I think the hypothetical increase from 5% to 6% is clearer: "Why This Can Be Tricky...For instance, when President George W. Bush proposed partially privatizing Social Security in 2004, some commentators said that only '2 percent' of the average American's Social Security taxes would be funneled into private accounts. That was a misleading statement, said another commentator, John Allen Paulos on ABC News. He looked at the numbers and said the writers meant that the average person's income taxes directed toward Social Security would drop from 6.2 to 4.2 percent, which is a change of 2 percentage points. The actual percent change, he said, was 32 percent." https://sciencing.com/difference-between-percent-percentage-point-8409115.html

A final recommendation about using more precise language is to be cautious with words that suggest a *cause-and-effect relationship* in your data. In everyday conversation, there are many ways that we loosely imply that a causal relationship, where an action directly results in a reaction. For example, when we say one thing "leads to" another, or "promotes" growth, or "sparks" change, those words suggest causality. While that's fine in daily conversation, we need to choose our words more carefully when discussing data, using these three concepts. The first step is to describe any *correlation* between two variables, which means to show how they are associated or related interdependently. But as the saying goes, correlation is not causation. Second, in order to show causation, we need to prove both correlation and offer a *persuasive theory* for how one factor (sometimes called the independent variable) creates a change in another factor (called the dependent variable). Third, we need to identify and isolate any *confounding variables* that we have not considered that may also influence the cause-and-effect relationship. While the details are beyond the scope of this book, be mindful of the concepts---and choose your words carefully---when working with data.

## Normalize Your Data {- #normalize}

When we discover raw data, often it does not make sense to compare it until we *normalize* it. This means to adjust data that has been collected using different scales into a common scale, in order to make meaningful comparisons. Often we normalize *absolute numbers* into *relative numbers*, or in other words, convert *raw data* into *rates* to compare them more easily. Even if you've never heard the term, perhaps you already *normalize* data without realizing it.

Here's an example about motor vehicle safety that was inspired by visualization expert Alberto Cairo, with [updated 2018 data](https://www.iihs.org/topics/fatality-statistics/detail/state-by-state) from the Insurance Institute for Highway Safety (IIHS) and the US Department of Transportation.^[@cairoTruthfulArtData2016, pp. 71-74.] Over 36,000 people died in motor vehicle crashes in 2018, including car and truck drivers and occupants, motorcyclists, pedestrians, and bicyclists. Although only a small fraction of this data appears in the tables below, you can [view all of the data in Google Sheets format](https://docs.google.com/spreadsheets/d/1N7_pHdmXdE3Y4ECnnDyBTSXkklv-u1hLULSO-YaotpA/edit#gid=0), and save an editable copy to your Google Drive, to follow along in this exercise.

Let's start with what appears to be a simple question, and see where our search for more meaningful comparisons takes us.

1. *Which US states had the lowest number of motor vehicle crash deaths?* When we sort the data by the numbers of deaths, the District of Columbia rises to the top of the list with only 31 deaths, as shown in Table \@ref(tab:deaths), and *appears* to have been the safest state (even though Washington DC is not recognized as a state).

Table: (\#tab:left-deaths) US States with lowest number of motor vehicle crash deaths, 2018

| State                | Deaths |
|----------------------|--------|
| District of Columbia | 31     |
| Rhode Island         | 59     |
| Vermont              | 68     |
| Alaska               | 80     |
| North Dakota         | 105    |

But wait---this isn't a fair comparison. Take another look at the top five states and you'll may notice that all of them have smaller populations than larger ones such as California and Texas, which appear at the very bottom of the full dataset. To paint a more accurate picture, let's rephrase the question to adjust for population differences.

2. *Which US states had the lowest number of motor vehicle crash deaths when adjusted for population?* Now let's *normalize* the death data by taking into account the total population of each state. In our spreadsheet, we calculate it as `Deaths / Population * 100,000`. While it's also accurate to divide deaths by population to find a *per capita* rate, those very small decimals would be difficult for most people to compare, so we multiply by 100,000 to present the results more clearly. When we sort the data, Washington DC rises to the top of the list, with only 4.4 motor vehicle crash deaths per 100,000 residents, as shown in Table \@ref(tab:deaths-population) and *appears* to have been the safest once again.

Table: (\#tab:deaths-population) US States with lowest number of motor vehicle crash deaths per population, 2018

| State                | Deaths | Population | Deaths per 100,000 population |
|----------------------|--------|------------|-------------------------------|
| District of Columbia | 31     | 702455     | 4.4                           |
| New York             | 943    | 19542209   | 4.8                           |
| Massachusetts        | 360    | 6902149    | 5.2                           |
| Rhode Island         | 59     | 1057315    | 5.6                           |
| New Jersey           | 564    | 8908520    | 6.3                           |

But wait---this still isn't a fair comparison. Look at the top five states again and you'll notice that all of them are located along the Northeastern US corridor, which has a high concentration of public transit, such as trains and subways. If people in urban areas like New York and Boston are less likely to drive motor vehicles, or take shorter trips than people in rural states where homes are more distantly spread out, that also could affect our data. Let's strive for a better comparison and rephrase the question again, this time to adjust for differences in mileage, not population.

3. *Which US states had the lowest number of motor vehicle crash deaths when adjusted for total miles traveled?* Once again, we *normalize* the death data by adjusting it to account for a different factor: the estimated total number of miles driven (in millions) by people in all cars, trucks, and motorcycles that traveled in each state, including both in-state and out-of-state drivers, in 2018. In our spreadsheet, we calculate it as `Deaths / Vehicle Miles * 100`, with the multiplier to present the results more clearly. This time Massachusetts rises to the top of the list, with only 0.54 motor vehicle crash deaths per 100 million miles traveled, as shown in as shown in Table \@ref(tab:deaths-miles). Also, note that the District of Columbia has fallen out of the top 5, while Minnesota now appears on the list.

Table: (\#tab:deaths-miles) US States with lowest number of motor vehicle crash deaths per miles traveled, 2018

| State         | Deaths | Vehicle miles traveled (millions) | Deaths per 100 million vehicle miles traveled |
|---------------|--------|-----------------------------------|-----------------------------------------------|
| Massachusetts | 360    | 66772                             | 0.54                                          |
| Minnesota     | 381    | 60438                             | 0.63                                          |
| New Jersey    | 564    | 77539                             | 0.73                                          |
| Rhode Island  | 59     | 8009                              | 0.74                                          |
| New York      | 943    | 123510                            | 0.76                                          |

TODO above: Ilya please confirm how "vehicle miles traveled" is calculated by the US DOT. I presume it is simply miles per vehicle, rather than miles per vehicle per number of occupants. Also, please confirm that this estimate is based on miles traveled in the state, not necessarily by vehicles registered in the state.

Have we finally found the *safest* state as judged by motor vehicle crash deaths? Not necessarily. While we normalized the raw data relative to the population and amount of driving, the IIHS reminds us that several other factors may influence these numbers, such as vehicle types, average speed, traffic laws, weather, and so forth. But as Alberto Cairo reminds us, every time we refine our model to make a more meaningful comparison, our interpretation becomes a closer representation of the truth.^[@cairoTruthfulArtData2016, p. 71]  TODO: Look for a closing quote by Cairo on this point.

As we demonstrated above, the most common way to normalize data is to adjust *absolute numbers* into *relative numbers*, such as percentages or per capita rates. But there are many other ways to normalize data, so make sure you're familiar with different methods when you [find and question your data, as described in chapter 4](find.html). When working with historical data (also called time-series or longitudinal data), you may need to *adjust for change over time*. For example, it's not fair to directly compare median household income in 1970 versus 2020, because $10,000 US dollars had far more purchasing power a half-century ago than it does today, due to cost of living and related factors. Similarly, economists distinguish between *nominal data* (unadjusted) versus *real data* (adjusted over time), typically by converting figures into "constant dollars" for a particular year that allow better comparisons by accounting for purchasing power.^[@WhatRealWages2018] Also, economic data is often *seasonally adjusted* to improve comparisons for data that regularly varies across the year, such as employment or revenue during the summer tourism season versus the winter holiday shopping season. Another normalization method is to create an *index* to measure how values have risen or fallen in relation to a given reference point over time. Furthermore, statisticians often normalize data collected using different scales by calculating its *standard score*, also known as its *z-score*, to make better comparisons. While these methods are beyond the scope of this book, it's important to be familiar the broader concept: everyone agrees that it's better to compare apples to apples, rather than apples to oranges.

Finally, you do *not* always need to normalize your data, because sometimes its format already does this for you. Unlike *counts* or raw numbers, most *measured variables* do not need normalization because they already appear on a common scale. One example of a measured variable is *median age*, the age of the "middle" person in a population, when sorted from youngest to oldest. Since we know that humans live anywhere between 0 and 120 years or so, we can directly compare the median age among different populations. Similarly, another measured variable is *median income*, if measured in the same currency, because this offers a common scale that allows direct comparisons across different populations.

Now that you have a better sense of why, when, and how to normalize data, the next section will warn you to watch out for biased comparisons in data sampling methods.

## Beware of Biased Comparisons {- #biased-comparisons}
TODO: Rewrite this section

Everyone should avoid cherry-picking data, which means selecting only the evidence that arrives at a pre-determined conclusion.

Also avoid statistically biased processes, such as sampling methods that regularly yields inaccurate results.... example of opinion data about socially inappropriate topics...
Sometimes bias arises due to a combination of human behavior and poor numerical reasoning.

But sometimes we compare different groups of data without realizing that that they are inappropriate comparisons; they seem like random samples, but due to underlying processes they are not random. Selection bias: comparing samples as if they were truly representative of the broader population, but in fact are not: common to mistakenly compare student academic performance in different types of schools, such as public versus private, or traditional public versus charter school, without recognizing how pools of applicants may differ.... how to address: carefully examine the underlying selection processes, and make appropriate comparisons between groups, and clarify problems in text that accompanies visualization

Also be aware of algorithmic biases that we sometimes build into our software...Cairo's example about IP data thru VPN converted to geographic center of US, near Kansas...

We also refer to biases that are baked into the software that humans create.
- Algorithm or machine learning bias: human-written code, or machine-learning that follows inductive reasoning standards set up by humans, can lead to biased results, especially in facial recognition across racial groups, or discrimination in home lending. examples: https://www.nytimes.com/2019/08/20/upshot/housing-discrimination-algorithms-hud.html; https://www.brookings.edu/blog/techtank/2020/04/16/why-a-proposed-hud-rule-could-worsen-algorithm-driven-housing-discrimination/
- Reduce by calling it out, and not simply equating "digital" as "authoritative"...


### Summary {- #summary6}



See books on data analysis to understand the logic and use of statistical tests
