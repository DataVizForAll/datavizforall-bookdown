# Clean Up Messy Data {#clean}

More often than not, datasets will be messy and hard to visualize right away.
They will have missing values, various spelling of the same categories,
dates in different formats, text in numeric-only columns, multiple things in the same columns,
and other unexpected things (see Figure \@ref(fig:clean-up-messy-data) for inspiration).
Don't be surprised if you find yourself spending longer cleaning up data than
actually analyzing and visualizing itâ€”it is often the case for data analysts.

(ref:clean-up-messy-data) More often than not, raw data looks like this.

```{r clean-up-messy-data, fig.cap="(ref:clean-up-messy-data)"}
knitr::include_graphics("images/04-clean/clean-up-messy-data.png")
```

It is important to learn several tools in order to know which one to use
to clean your data efficiently.
We will start by looking at fairly basic data cleanup using Google Sheets.
Keep in mind that the same principles (and in most cases
even the same formulas) can be use in Microsoft Excel, LibreOffice Calc, Mac's Numbers,
or other spreadsheet packages.

We will then show you how to extract table data from PDF documents using a free tool called Tabula.
Tabula is used by data journalists and researchers worldwide
to analyze government spendings, procurement records and all sorts of other datasets
that get trapped in PDFs.

At the end, we will introduce OpenRefine, an extremely powerful and versatile tool
to clean up the messiest spreadsheets, such as those containing dozens of misspelled versions
of universities or town names.

## Clean Data with Spreadsheets {- #clean-spreadsheets}

Let's take a look at some techniques to clean up data directly in your favorite
spreadsheet tool. We will use Google Sheets as an example, but the same principles
will apply to most other software packages, such as Excel, Calc, or Numbers.

#### Find and Replace with a blank {-}

*Find and Replace* tool is one of the most powerful data clean-up tools in spreadsheets.
You can use it to remove thousands separators from numbers (to change `1,234,567` to `1234567`)
or to remove units of measure that sometimes reside in the same cells as numbers
(`321 kg` -> `321`). You can also use it to bulk-change spellings, for example
to shorten, expand, or translate country names (`Republic of India` -> `India`,
`US` -> `United States`, `Italy` -> `Italia`).

Let's look at *Find and Replace* in practice.
A common problem with US census data is that geographic names contain unnecessary words.
For example, your data can look something like that:

```
Hartford town
New Haven town
Stamford town
```

But you want a clean list of towns, either to display in a chart,
or to merge with a different dataset:

```
Hartford
New Haven
Stamford
```

We can use *Find and Replace* tool in a sample US Census file we downloaded with 169 Connecticut town names and their populations, to remove the unwanted "town" label after each place name.

1. Open the [CT Town Geonames file in Google Sheets](https://docs.google.com/spreadsheets/d/1kJI0xFedPUQBRfT9CEMAfIsggOmJv4wz_AdenraFDP4/edit#gid=1055822816), sign in with your account, and go to *File > Make a Copy* to create a version you can edit in your Google Drive.
2. Select the column you want to modify by clicking on the column header. If you don't,
you will be searching and replacing in the entire spreadsheet.
3. From *Edit* menu, choose *Find and replace* item. You will see the window like is shown in Figure \@ref(fig:sheets-find-replace).
4. In the *Find* field, type ` town`, and be sure to *insert a blank space* before the word. If you do not insert a space, you will accidentally remove *town* from places such as *Newtown*, and you'll also end up with trailing spaces that can cause troubles in the future.
5. Leave the *Replace with* field blank.
6. The *Search* field should be set to the range you selected in step 2, or *All sheets* if you didn't select anything.
7. You have the option to *match case*. If checked, `town` and `Town` and `tOwN` will be treated differently. For our purpose, you can leave *match case* unchecked.
8. Press the *Replace all* button. Since this sample file contains 169 towns, the window
will state that 169 instances of "town" have been replaced.
9. Inspect the resulting sheet. Make sure that places that include *town* in their name, such as *Newtown*, remained untouched.

(ref:sheets-find-replace) Find and Replace window in Google Sheets.

```{r sheets-find-replace, fig.cap="(ref:sheets-find-replace)"}
knitr::include_graphics("images/04-clean/sheets-find-replace-annotated.png")
```

#### Split data into two or more columns {-}

Sometimes multiple pieces of data appear in a single cell,
such as names (`John Doe`), coordinate pairs (`40.12,-72.12`),
or addresses (`300 Summit St, Hartford, CT, 06106`). For your analysis,
you might want to split them into separate entities, so that your *FullName*
column (with `John Doe` in it) becomes *FirstName* (`John`) and *LastName* (`Doe`) columns,
coordinates become *Latitude* and *Longitude* columns, and your *FullAddress* column becomes
4 columns, *Street*, *City*, *State*, and *Zip* (postcode).

##### Example 1 {-}

Let's begin with a simple example of splitting pairs of longitude and latitude coordinates, separated by commas, into separate columns.

1. Open the [Split Coordinate Pairs sample data in Google Sheets](https://docs.google.com/spreadsheets/d/1VmY9aS7I7UstXeI2xsJ-Ep2Q0CW8tnFHWTCga4EaJRk/edit#gid=1670822958), sign in with your account, and go to *File > Make a Copy* to create a version you can edit in your Google Drive.
2. Select the data you wish to split, either the full column or just several rows.
Note that you can only split data from one column at a time.
3. Make sure there is no data in the column to the right of the one you're splitting, because
all data there will be written over.
4. Go to *Data* and select *Split text to columns*, as in Figure \@ref(fig:sheets-split).
5. Google Sheets will automatically try to guess your separator. You will see that your coordinates
are now split with the comma, and the Separator is set to *Detect automatically* in the dropdown.
You can manually change it to a comma (`,`), a semicolon (`;`), a period (`.`), a space character,
or any other custom character (or even a sequence of characters, which we'll discuss in Example 2 of this section).
6. You can rename the new columns into *Longitude* (first number) and *Latitude* (second number).

(ref:sheets-split) Select *Data - Split text to columns* to automatically separate data.

```{r sheets-split, out.width=350, fig.cap="(ref:sheets-split)"}
knitr::include_graphics("images/04-clean/sheets-split-annotated.png")
```

##### Example 2 {-}

Now, let's look at a slightly more complicated example. Each cell contains a full address, which you want to split into four columns: street, city, state, and zipcode (postcode). But notice how the separators differ: a comma between street and city, a space between city and state, and two dashes between state and the zipcode. In this case, you'll need to manually add some instructions to properly split the text into four columns.

```
| Location                          |
| --------------------------------- |
| 300 Summit St, Hartford CT--06106 |
| 1012 Broad St, Hartford CT--06106 |
| 37 Alden St, Hartford CT--06114   |
```


1. Open the [Split Complex Address sample file in Google Sheets](https://docs.google.com/spreadsheets/d/1XkWrHBCK5HedAWskkb5lligWoozBVXc6w7_FRuYebPI/edit#gid=0), sign in to your account, and go to *File > Make a Copy* to save a version in your Google Drive that you can edit.
2. Select the column and go to *Data* > *Split text to columns* to start splitting from left to right.
3. Google Sheets will automatically split your cell into two parts, `300 Summit St` and `Hartford CT--06106`, using comma as a separator. (If it didn't, just select *Comma* from the dropdown menu that appeared).
4. Now select only the second column and perform *Split text to columns* again. Google Sheets will automatically separate the city from the state and zip code, because it automatically chose a space as the separator. (If it did not, choose *Space* from the dropdown menu).
4. Finally, select only the third column and perform *Split text to columns* again. Google Sheets won't recognize the two dashes as a separator, so you need to manually select *Custom*, type those two dashes (`--`) in the *Custom separator* field, as shown in Figure \@ref(fig:sheets-split-complex), and press Enter. Now you have successfully split the full address into four columns.

(ref:sheets-split-complex) To split the last column, select a *Custom* separator and manually type in two dashes.

```{r sheets-split-complex, out.width=500, fig.cap="(ref:sheets-split-complex)"}
knitr::include_graphics("images/04-clean/sheets-split-complex.png")
```

Tip: Google Sheets will treat zip codes as numbers and will delete leading zeros (so 06106 will become 6106).
To fix that, select the column, and go to *Format > Number > Plain text*. Now you can manually re-add zeros.
If your dataset is large, consider concatenating 0s using the formula introduced in the [following section](#combine-separate-columns-into-one).

#### Combine separate columns into one {-}
Let's perform the reverse action by combining separate columns into one.
Imagine you receive address data in four separate columns: street address, city, state, and zip code.

```
| Street        | City       | State  | Zip   |
| ------------- | ---------- | ------ | ----- |
| 300 Summit St | Hartford   | CT     | 06106 |
```

But imagine your mapping tool requires you to combine all of these terms into
one location column like this:

```
| Location                          |
| --------------------------------- |
| 300 Summit St, Hartford, CT 06106 |
```

In any spreadsheet tool, you can write a simple formula to combine (or concatenate) terms
using ampersands (`&`) to fuse items together. Also, you can add separators into your formula, such as quoted spaces (`" "`), spaces with commas (`", "`), or any combination of characters.
or a dash with spaces on both sides (`" - "`). Let's try it with some sample data.

1. Open the [Combine Separate Columns sample data in Google Sheets](https://docs.google.com/spreadsheets/d/1DGKYquQ0nKiBCE_KbQk24Zvjrxb0zKk8gC-FpObY7LM/edit#gid=0), sign in with your account, and go to *File > Make a Copy* to create a version you can edit in your Google Drive. The sheet contains addresses that are separated into four columns: street, city, state, and zip.
2. In column E, type a new header named *location*.
3. In cell E2, type in the following formula, which combines the four items using ampersands, and separates them with quoted commas and spaces, as shown in Figure \@ref(fig:sheets-combine), and press *Enter*.
`=A2 & ", " & B2 & ", " & C2 & " " & D2`
4. Click cell E2 and drag the bottom-right corner cross-hair downward to fill in the rest of the column.

(ref:sheets-combine) Use ampersands to combine items, and insert quoted spaces with commas as separators.

```{r sheets-combine, fig.cap="(ref:sheets-combine)"}
 knitr::include_graphics("images/04-clean/sheets-combine.png")
```

Note: Lisa Charlotte Rost from Datawrapper has written a brilliant [blog post](https://blog.datawrapper.de/prepare-and-clean-up-data-for-data-visualization/)
talking about data preparation for charting and analysis in Google Sheets,
which we recommend for further reading.

You are now able to split data to columns using custom separators, and
concatenate values from different cells into one. But what if your table is trapped
inside a PDF? In the next section, we will introduce Tabula and show you how to
convert tables from PDF documents into tables that you can analyze in Google Sheets,
Microsoft Excel, or similar packages.

## Extract Tables from PDFs with Tabula {- #tabula}

It sometimes happens that the dataset you are interested in is only available as a PDF document.
Don't despair, you can *likely* use Tabula to extract tables and save them as CSV files. Keep in mind that PDFs generally come in two flavors: text-based and image-based.
If you can use cursor to select and copy-paste text in your PDF, then it's text-based, which is great because you can process it with Tabula. But if you cannot select and copy-paste items inside a PDF, then it's image-based, meaning it was probably created as a scanned version of the original document. You need to use optical character recognition (OCR) software, such as Adobe Acrobat Pro or another OCR tool, to convert an image-based PDF into a text-based PDF. Furthermore, Tabula can only extract data from tables, not charts or other types of visualizations.

Tabula is a free tool that runs on Java in your browser, and is available for Mac, Windows, and Linux computers. It runs on your local machine and does not send your data to the cloud, so you can also use it for sensitive documents.

To get started, [download the newest version of Tabula](https://tabula.technology/).
You can use download buttons on the left-hand side, or scroll down to the *Download & Install Tabula* section to download a copy for your platform. Unlike most other programs, Tabula does not require installation. Just unzip the downloaded archive,
and double-click the icon. If prompted with a security message (such as
"Tabula is an app downloaded from the internet. Are you sure you want to open it?"),
follow the instruction to proceed (on a Mac, click *Open*; you might have to go to
System Preferences > Security & Privacy, and resolve the issue there).

When you start up Tabula, the default system browser will open, as shown in Figure \@ref(fig:tabula-welcome). Tabula runs on your local computer, not the internet. The URL in the browser will be something like `http://127.0.0.1:8080/`. The first portion is the localhost or hostname for your computer, and `8080` refers to the port number. If you see a different port number, that's fine, and just means that the initial number is already in use by some other program on your computer. If for any reason you decide to use a different browser, just copy-paste the URL.

(ref:tabula-welcome) Tabula welcome page.

```{r tabula-welcome, fig.cap="(ref:tabula-welcome)"}
knitr::include_graphics("images/04-clean/tabula-welcome.png")
```

Now let's upload a sample text-based PDF and detect any tables we wish to extract. In the beginning of the Covid-19 pandemic, the Department of Public Health in Connecticut
issued data on cases and deaths only in PDF document format.
For this demonstration, you can use [our sample text-based PDF](data/ct-dph-covid-2020-05-31.pdf)
from May 31, 2020, or provide your own.

1. Select the PDF you want to extract data from by clicking the blue *Browse...* button.
2. Click *Import*. Tabula will begin analyzing the file.
3. As soon as Tabula finishes loading the PDF, you will see a PDF viewer with individual pages. The interface is fairly clean, with only four buttons in the header.
4. Click the *Autodetect Tables* button to let Tabula look for relevant data. The tool highlights each table it detects in red, as shown in Figure \@ref(fig:tabula-autodetect).

(ref:tabula-autodetect) Click *Autodetect Tables*, which Tabula will highlight in red.

```{r tabula-autodetect, fig.cap="(ref:tabula-autodetect)"}
knitr::include_graphics("images/04-clean/tabula-autodetect.png")
```

Now let's manually adjust our selected tables and export the data.

5. Click *Preview & Export Extracted Data* green button to see how Tabula thinks the data should be exported.
6. If the preview tables don't contain the data you want, try switching between *Stream* and *Lattice* extraction methods in the left-hand-side bar.
7. If the tables still don't look right, or you with to remove some tables that Tabula auto-detected, hit *Revise selection* button.
That will bring you back to the PDF viewer.
8. Now you can *Clear All Selections* and manually select
tables of interest. Use drag-and-drop movements to select tables of interest (or parts of tables).
9. If you want to "copy" selection to some or all pages, you can use *Repeat this Selection* dropdown, which appears
in the lower-right corner of your selections, to propagate changes. This is extremely useful if your PDF consists of
many similarly-formatted pages.
10. Once you are happy with the result, you can export it. If you have only one table, we recommend using CSV as export format.
If you have more than one table, consider switching export format to *zip of CSVs*.
This way each table will be saved as an individual file, rather than all tables inside one CSV file.

Once you exported your data, you can find it in the Downloads folder on your computer (or wherever you chose to save it), where it is ready to open with a spreadsheet tool to analyze and visualize.

In the following section, we are going to look how to clean up messy datasets with OpenRefine.

## Clean Data with OpenRefine {- #open-refine}

Consider a dataset that looks like the one in Figure \@ref(fig:openrefine-dataset).
Can you spot any problems with it?

(ref:openrefine-dataset) First 20 rows of the sample dataset. Can you spot any problems with it?

```{r openrefine-dataset, fig.cap="(ref:openrefine-dataset)"}
knitr::include_graphics("images/04-clean/openrefine-dataset.png")
```

Notice how the funding amounts (last column)
are not standardized. Some amounts have commas as thousands separators,
some have spaces, and some start with a dollar character.
Notice also how the Country column includes various spellings of North and South Korea.
Datasets like this can be an absolute nightmare to analyze. Luckily,
OpenRefine provides powerful tools to clean up and standardize such data.

Note: This data exerpt is from [US Overseas Loans and Grants (Greenbook) dataset](https://catalog.data.gov/dataset/u-s-overseas-loans-and-grants-greenbook),
which shows US economic and military assistance to various countries.
We chose to only include assistance to South Korea and North Korea for the years between 2000 and 2018.
We added deliberate misspellings and formatting issues for demonstration purposes
(although we did not alter values).

Download this [sample dataset](data/us-foreignaid-greenbook-koreas.csv)
or use your own file with messy data.
Inspect the file in any spreadsheet software. You can see that the dataset has four columns:
year (between 2000 and 2018, inclusive), country (North or South Korea),
a US funding agency, and funding amount (in 2018 US dollars).
Let's now use OpenRefine to clean it up.

### Set up OpenRefine {-}

You can download a copy of OpenRefine for Linux, Mac, or Windows from the [official
download page](https://openrefine.org/download.html). Just like Tabula, it runs in your browser and no
data leaves your local machine, which is great for confidentiality.

If you work on a Mac, the downloaded file will be a .dmg file. You will likely encounter
a security message that will prevent OpenRefine from launching. Go to System Preferences -> Security and Privacy, and
hit *Open Anyway* button in the lower half of the window. If prompted with another window, click *Open*.

If you use Windows, unzip the downloaded file. Double-click the .exe file, and OpenRefine should
open in your default browser.

Once launched, you should see OpenRefine in your browser with `127.0.0.1:3333` address (localhost, port 3333),
like shown in Figure \@ref(fig:openrefine-welcome).

(ref:openrefine-welcome) OpenRefine starting page.

```{r openrefine-welcome, fig.cap="(ref:openrefine-welcome)"}
knitr::include_graphics("images/04-clean/openrefine-welcome-annotated.png")
```

### Load Data and Start a New Project {-}

To begin cleaning up your messy dataset, you should load it into a new project.
OpenRefine lets you upload a dataset from your local machine,
or a remote URL on the web (including a Google Spreadsheet), or copy/paste data into a text field.
OpenRefine is able to extract data directly from SQL databases, but this is beyond the scope of this book.
We assume that you downloaded the sample dataset we provided (or you are using your own file),
so let's load it from your computer.

1. Under *Get data from: This computer*, click *Browse...* and select the file. Click *Next*.
2. Before you can start cleaning up data, OpenRefine allows you to make sure data is *parsed* properly.
In our case, parsing means the way the data is split into columns.
Make sure OpenRefine assigned values to the right columns,
or change setting in *Parse data as* block at the bottom of the page until it starts looking meaningful,
like shown in Figure \@ref(fig:openrefine-parse).
3. Hit *Create Project* in the upper-right corner.

(ref:openrefine-parse) OpenRefine parsing options.

```{r openrefine-parse, fig.cap="(ref:openrefine-parse)"}
knitr::include_graphics("images/04-clean/openrefine-parse.png")
```

Now when you've successfully read the data into a new project, let's start
the fun part: converting text into numbers, removing unnecessary characters,
and fixing the spellings for North and South Koreas.

### Convert Dollar Amounts from Text to Numbers {-}

Once your project is created, you will see the first 10 rows of the dataset.
You can change it to 5, 10, 25, or 50
by clicking the appropriate number in the header

Each column header has its own menu (callable by clicking the arrow-down button).
Left-aligned numbers in a column are likely represented as text
(as is the case with FundingAmount column in our example), and they need to be transformed
into numeric format.

1. To transform text into numbers, open the column menu, and go to *Edit cells* > *Common transforms* > *To number*.
2. You will see that some numbers became green and right-aligned (success!), but most did not change.
That is because dollar sign (`$`) and commas (`,`) confuse OpenRefine and prevent values to be converted into numbers.
3. Let's remove `$` and `,` from the FundingAmount column. In the column menu, choose *Edit cells* >
*Transform*. In the Expression window, type `value.replace(',', '')` and notice how commas
disappear in the preview window. When you confirm your formula works, click *OK*.
4. Now, repeat the previous step, but instead of a comma, remove the `$` character.
(Your expression will become `value.replace('$', '')`).
5. In steps 3 and 4, we replaced text (string) values with other string values,
making OpenRefine think this column is no longer numeric. As a result, all values
are once again left-aligned and in black. Perform step 1 again to
see that all but three
cells turning green (successfully converting to numeric).
Now we need to remove spaces and an `a` character at the end of one number.
Fix those manually by hovering over cells, and clicking the `edit` button
(in the new popup window, make sure to change *Data type* to *number*, and hit *Apply*,
like in Figure \@ref(fig:openrefine-manual-edit)).

(ref:openrefine-manual-edit) Manually remove spaces and extra characters, and change data type to number.

```{r openrefine-manual-edit, fig.cap="(ref:openrefine-manual-edit)"}
knitr::include_graphics("images/04-clean/openrefine-manual-edit-annotated.png")
```

At this point, all funding amounts should be clean numbers, right-aligned and colored in green.
We're ready to move on to the Country column and fix different spellings of Koreas.


### Cluster Similar Spellings {-}

When you combine different data sources, or process survey data where respondents
wrote down their answers as opposed to selecting them from a dropdown menu, you might end up
with multiple spellings of the same word (town name, education level â€“ you name it!).
One of the most powerful features of OpenRefine is the ability to cluster similar responses.

If you use our original sample file, take a look at the *Country* column and
all variations of North and South Korea spellings.
From *Country* column's dropdown menu, go to *Facet* > *Text facet*. This will open up a window
in the left-hand side with all spellings (and counts) of column values. 26 choices for a column
that should have just two distinct values, North Korea and South Korea!

1. To begin standardizing spellings, click on the arrow-down button of Country column header,
and choose *Edit cells* > *Cluster and edit*. You will see a window like the one shown in Figure
\@ref(fig:openrefine-cluster).
2. You will have a choice of two clustering methods, *key collision* or *nearest neighbor*. Both
methods can be powered by different functions, but let's leave the default *key collision* with *fingerprint* function.
3. OpenRefine will calculate a list of clusters. *Values in Cluster* column contains grouped spellings
that OpenRefine considers the same. If you agree with a grouping, check the *Merge?* box, and assign
the "true" value to the *New Cell Value* input box (see first cluster in Figure \@ref(fig:openrefine-cluster)).
In our example, this would be either `North Korea` or `South Korea`.
4. You can go through all groupings, or stop after one or two and click *Merge Selected & Re-Cluster* button.
The clusters you chose to merge will be merged, and grouping will be re-calculated
(don't worry, the window won't go anywhere). Keep regrouping until you are happy with the result.

Spend some time playing with *Keying function* parameters, and notice
how they produce clusters of different sizes and accuracy.

(ref:openrefine-cluster) Cluster similar text values.

```{r openrefine-cluster, fig.cap="(ref:openrefine-cluster)"}
knitr::include_graphics("images/04-clean/openrefine-cluster-annotated.png")
```

### Export {-}

Once you are done cleaning up and clustering data, save the clean dataset
by clicking *Export* button in the upper-right corner of OpenRefine window.
You can choose your format (we recommend CSV, or comma-separated value).
Now you have a clean dataset that is ready to be processed and visualized.

### Summary {- #summary4}

In this chapter, we looked at cleaning up tables in Google Sheets,
liberating tabular data trapped in PDFs using Tabula, and using
OpenRefine to clean up very messy datasets.
You will often find yourself using several of these tools on the same dataset
before it becomes good enough for your analysis. We encourage you to
learn more formulas in Google Sheets, and explore extra functionality of OpenRefine
in your spare time. The more clean-up tools and techniques you know, the more able and adaptable
you become to tackle more complex cases.

You now know how to clean up your data, so let's proceed to visualizing it.
In the following chapter, we will introduce you to a range of free data visualization
tools that you can use to build interactive charts and embed them in your website.
